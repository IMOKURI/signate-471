{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "医学論文の自動仕分けチャレンジ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02e04db7c976491a9b25182b636b4bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1111e6380541486aa7b4b873b56a6858",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34de02bfb1af4ae3ab7c0825ea793cd0",
              "IPY_MODEL_054bc836df0b415fadcaf40ea1171aba"
            ]
          }
        },
        "1111e6380541486aa7b4b873b56a6858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34de02bfb1af4ae3ab7c0825ea793cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_eee5f27b4f8e4efeba68db7e0351cb3b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 124.25MB of 124.25MB uploaded (0.17MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_931938bcb7a046239b962c44e3e71eaf"
          }
        },
        "054bc836df0b415fadcaf40ea1171aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc38d965eb4c41a7941312df061662db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff48cef5fc5342a19e65310449984b25"
          }
        },
        "eee5f27b4f8e4efeba68db7e0351cb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "931938bcb7a046239b962c44e3e71eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc38d965eb4c41a7941312df061662db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff48cef5fc5342a19e65310449984b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/signate-471/blob/main/%E5%8C%BB%E5%AD%A6%E8%AB%96%E6%96%87%E3%81%AE%E8%87%AA%E5%8B%95%E4%BB%95%E5%88%86%E3%81%91%E3%83%81%E3%83%A3%E3%83%AC%E3%83%B3%E3%82%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e4660c1"
      },
      "source": [
        "# About this notebook ...\n",
        "\n",
        "competition site: https://signate.jp/competitions/471\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dhs2SIWJzKz"
      },
      "source": [
        "## ToDo\n",
        "\n",
        "- [ ] pre train のモデルの save と load\n",
        "- [ ] preprocess したデータの save と load (wandb)\n",
        "\n",
        "### Idea\n",
        "\n",
        "- [x] [ラベル判定結果の誤りに関するお知らせ](https://signate.jp/competitions/471/discussions/20210816152356-59) をとりこむ \n",
        "- [ ] 分類で推論、回帰で推論\n",
        "- [x] 回帰の場合の境界値の最適化\n",
        "    - [ ] second stage で学習べきかも\n",
        "        - [ ] heamy という stacking のライブラリがある\n",
        "        - [ ] CNN で stacking がいいかもしれない https://tawara.hatenablog.com/entry/2020/12/16/132415\n",
        "            - 縦・横、チャネル数が、クラス数（１）・モデル数（ｎ）・１で、 1xn で畳み込む \n",
        "    - [ ] Nelder-Mead 法 という最適化手法を調べる\n",
        "- [ ] 最適な境界値はモデルによって異なるので、アンサンブルの時は、 vote ensemble がいいかもしれない\n",
        "- [x] アブストで事前学習して、タイトルでメイン学習 https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n",
        "    - 事前学習は、Masked LM\n",
        "- [x] タイトルだけで学習・推論\n",
        "- [ ] タイトル + アブストで学習・推論\n",
        "    - [ ] タイトルだけで推論したのとアンサンブルができる\n",
        "    - [ ] Longformer がいいかもしれない `allenai/longformer-base-4096`\n",
        "    - [ ] large モデルためす\n",
        "- [ ] アブスト + タイトル で学習・推論\n",
        "- [ ] アブストが空 or not でモデルわける\n",
        "- [ ] アブストの max length 調整\n",
        "    - [ ] 途中で切る。デフォルトの 512 はありそう。ほとんどのアブストがその長さで収まる\n",
        "    - [ ] 要約する方法があるかなぁ\n",
        "- [x] dropout を 0 にする\n",
        "- [x] gradient cripping を 0.2 or 0.5 で試す\n",
        "- [ ] re-initialization\n",
        "    - This paper (https://arxiv.org/pdf/2006.05987.pdf) shows that fine-tuning with reinitialization last N layers works well.\n",
        "    - Different models have different optimal N. Almost models set N=4~5, gpt2-models set N=6.\n",
        "    - https://github.com/kurupical/commonlit/blob/8781139c8ed4cc59f7c7ac9d97c72c351ee91377/exp/exp502.py#L497\n",
        "- [ ] Pre trained なレイヤーのfreeze https://raphaelb.org/posts/freezing-bert/\n",
        "- [ ] Recall を伸ばすための loss function は考えられるか。 https://openreview.net/pdf?id=SlprFTIQP3\n",
        "    - [x] f1 score を微分可能にして、 loss 関数に使うアプローチ https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354 https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d\n",
        "    - [ ] epoch ごとに beta の値を増やしていく epoch * 2 とか\n",
        "- [ ] 出現する単語のクラスタリング\n",
        "- [x] TF-IDF して、 リッジ回帰 → ベースライン2 でやった\n",
        "    - IF-IDF の結果もBERTの特徴量にできないだろうか\n",
        "    - https://www.kaggle.com/semyonkoshkarov/tf-idf-linearsvr-baseline も参考になるかも\n",
        "- [ ] 医療用語で事前学習されたモデルを使ってみる\n",
        "    - [x] BioBERT https://github.com/dmis-lab/biobert `dmis-lab/biobert-base-cased-v1.1` 286k downloads\n",
        "        - [ ] large モデル試す\n",
        "    - [ ] Med-BERT https://github.com/ZhiGroup/Med-BERT\n",
        "        - 診断精度に貢献しているかもしれない(いや、一般的な話だったｗ) https://www.nature.com/articles/s41746-021-00455-y\n",
        "    - [x] `microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext` 30.8k downloads https://www.axion.zone/microsoft-researchers-claim-state-of-the-art-biomedical-nlp-model/\n",
        "    - [x] `bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12` 4.3k downloads https://github.com/ncbi-nlp/bluebert\n",
        "        - [ ] large モデル試す\n",
        "    - [x] `emilyalsentzer/Bio_ClinicalBERT` https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n",
        "    - [ ] `emilyalsentzer/Bio_Discharge_Summary_BERT` https://huggingface.co/emilyalsentzer/Bio_Discharge_Summary_BERT\n",
        "    - [x] `lordtt13/COVID-SciBERT` https://huggingface.co/lordtt13/COVID-SciBERT\n",
        "    - [ ] `allenai/scibert_scivocab_uncased` https://huggingface.co/allenai/scibert_scivocab_uncased\n",
        "- [ ] Augmentation https://neptune.ai/blog/data-augmentation-nlp\n",
        "    - [ ] Back translation: 他言語に翻訳して、もう一回翻訳する（英語→フランス語→英語） https://qiita.com/nena0undefined/items/c2926bad07039e5540ab\n",
        "    - [ ] Synonym Replacement: 単語のいくつかを、同じ意味の別の単語に置き換える\n",
        "        - [ ] 自然言語の augmentation ができるライブラリ https://github.com/makcedward/nlpaug\n",
        "- [ ] TTA\n",
        "- [ ] ベースラインのシンプルさを取り戻す。(思ったよりベースラインのスコアが良かったので、それを取り込む・・・）\n",
        "    - [ ] weight decay を調整 0.01 or 0\n",
        "\n",
        "\n",
        "### Experiments\n",
        "\n",
        "- BERT でアブストの　pre train をしてもスコアは上がっていない（学習の方法を工夫した方がよいかも）\n",
        "- BERT Large は title の学習には大きすぎて？ loss が Base モデルに及ばない。\n",
        "- epoch 3 で val loss が下がらないので、 epoch 3 で aug かけるとかありかもしれない\n",
        "- `dmis-lab/biobert-base-cased-v1.1` と `bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12` の成績がよい\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68842c71"
      },
      "source": [
        "## Prepare for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14137a0f",
        "outputId": "ef052f7c-b206-4aeb-cfed-d48521acbd28"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep  2 11:30:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4871daf1",
        "outputId": "d0d8358b-21e8-4545-fea6-7df293a18426"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if os.path.exists('init.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    if 'google.colab' in sys.modules:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/gdrive')\n",
        "\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/train.csv .\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/test.csv .\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/sample_submit.csv .\n",
        "\n",
        "    # for StratifiedGroupKFold\n",
        "    # !pip uninstall -y scikit-learn\n",
        "    # !pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn\n",
        "\n",
        "    # for MultilabelStratifiedKFold\n",
        "    !pip install -q iterative-stratification\n",
        "\n",
        "    # !pip install -qU 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n",
        "\n",
        "    !pip install -q wandb\n",
        "    !pip install -q transformers\n",
        "    !pip install -q textstat\n",
        "\n",
        "    !touch init.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkZ4bEVgUxxa",
        "outputId": "ac974a01-8da1-449f-88e1-35c28d94907e"
      },
      "source": [
        "# Install_LightGBM_with_GPU\n",
        "\n",
        "if os.path.exists('init_lightgbm.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    ! git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "\n",
        "    %cd /content/LightGBM\n",
        "    ! mkdir -p build\n",
        "\n",
        "    %cd build\n",
        "    ! cmake -DUSE_GPU=1 /content/LightGBM\n",
        "    ! make -j$(nproc)\n",
        "    ! sudo apt-get -y install python-pip\n",
        "    ! sudo -H pip install setuptools pandas==1.3.0 numpy scipy scikit-learn -U\n",
        "\n",
        "    %cd /content/LightGBM/python-package\n",
        "    ! sudo python setup.py install --precompile\n",
        "\n",
        "    %cd /content/\n",
        "\n",
        "    !touch init_lightgbm.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c39b7222"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63096cb"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "import textstat\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers as T\n",
        "import wandb\n",
        "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, fbeta_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold  # , StratifiedGroupKFold\n",
        "from torch.optim import SGD, Adam  # , AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c830faec"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16eb8ed5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cZeQJ7Xw7d8",
        "outputId": "4defbdc6-1b18-496e-c6b5-f3f3b97b4b8f"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc53e8c",
        "outputId": "bfd4dcf4-4e23-4259-da52-2132b6e2e685"
      },
      "source": [
        "netrc = \"../input/wandbtoken/.netrc\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    netrc = \"/gdrive/MyDrive/.netrc\"\n",
        "\n",
        "!cp -f {netrc} ~/\n",
        "\n",
        "!wandb login"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB5QkUQJq_6U"
      },
      "source": [
        "wandb_job_type = \"\"\n",
        "wandb_notes = \"\"\n",
        "wandb_tags = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71d9ccbd"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a62a05f"
      },
      "source": [
        "DATA_DIR = \"../input/signate-471/\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_DIR = \"./\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26350797"
      },
      "source": [
        "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
        "sub = pd.read_csv(DATA_DIR + \"sample_submit.csv\", header=None)\n",
        "sub.columns = [\"id\", \"judgement\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7ef06f8"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0177571"
      },
      "source": [
        "class Config:\n",
        "    wandb_entity = \"ponkots\"\n",
        "    wandb_project = \"signate-471\"\n",
        "    print_freq = 100\n",
        "\n",
        "    pre_train = False\n",
        "    train = False\n",
        "    validate = False\n",
        "    inference = False\n",
        "    stack = True\n",
        "\n",
        "    debug = False\n",
        "    multi_gpu = False\n",
        "    apex = False\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a195fe0"
      },
      "source": [
        "if Config.pre_train:\n",
        "    wandb_job_type = \"pre_training\"\n",
        "\n",
        "elif Config.train:\n",
        "    wandb_job_type = \"training\"\n",
        "\n",
        "elif Config.inference:\n",
        "    wandb_job_type = \"inference\"\n",
        "\n",
        "elif Config.validate:\n",
        "    wandb_job_type = \"validation\"\n",
        "\n",
        "elif Config.stack:\n",
        "    wandb_job_type = \"stacking\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccb61787"
      },
      "source": [
        "if Config.apex:\n",
        "    from apex import amp"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWDHvHvNxoD3",
        "outputId": "f86733fa-9aea-499f-be6e-4c0e9b6913ec"
      },
      "source": [
        "# seed = random.randrange(10000)\n",
        "seed = 440\n",
        "\n",
        "print(seed)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daf057a9"
      },
      "source": [
        "config_defaults = {\n",
        "    \"seed\": seed,\n",
        "    \"input\": \"title_abstract\",  # \"abstract_title\",  # \"preprocessed_title_abstract\",  # \"title\", # \"title_abstract\",\n",
        "    \"max_len\": 512,\n",
        "    \"border\": \"minimize\", # \"fixed\", \"minimize\",\n",
        "    \"n_class\": 1,\n",
        "    \"n_fold\": 5,\n",
        "    \"gradient_accumulation_steps\": 2,\n",
        "    \"max_grad_norm\": 1000,\n",
        "    \"num_workers\": 4,\n",
        "    \"batch_size\": 12,\n",
        "    \"epochs\": 3,\n",
        "    \"optimizer\": \"BertAdamW\",\n",
        "    \"scheduler\": \"get_cosine_schedule_with_warmup\",\n",
        "    \"criterion\": \"BCEWithLogitsLoss\",  # \"FBetaLoss\",  # \"BCEWithLogitsLoss\",\n",
        "    \"lr\": 2e-5,\n",
        "    \"min_lr\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"dropout\": 0.1,\n",
        "    \"model_name\": \"\",\n",
        "    \"reinit_layers\": 0,\n",
        "    \"freeze_layers\": 0,\n",
        "    \"best\": \"loss\",  # \"score\",\n",
        "    \"inference_runs\": [\n",
        "        \"1uv8m7j0\", # 56\n",
        "        \"x2rmxctu\", # 59\n",
        "        \"258um1kf\", # 60\n",
        "    ],\n",
        "}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFOA0aiExa5R"
      },
      "source": [
        "if Config.stack:\n",
        "    config_stack = {\n",
        "        \"objective\": \"binary\",\n",
        "        \"criterion\": \"binary_logloss\",\n",
        "        \"lr\": 0.01,\n",
        "        \"max_depth\": 7,\n",
        "        \"num_leaves\": 31,\n",
        "        \"min_data_in_leaf\": 20,\n",
        "        \"dropout\": 0.1,\n",
        "    }\n",
        "    config_defaults.update(config_stack)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUQbknvvbZR5"
      },
      "source": [
        "if not (Config.validate or Config.inference or Config.stack):\n",
        "    config_defaults[\"inference_runs\"] = []"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd440361"
      },
      "source": [
        "if Config.debug:\n",
        "    config_defaults[\"epochs\"] = 1\n",
        "    Config.print_freq = 10"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgjHEBuwETmp"
      },
      "source": [
        "if config_defaults[\"optimizer\"] == \"BertAdamW\":\n",
        "    config_defaults[\"lr_69\"] = 5e-5\n",
        "    config_defaults[\"lr_133\"] = 1e-4"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a710ed",
        "outputId": "78c658ce-6eeb-4bf2-b5cc-876811f60e59"
      },
      "source": [
        "# Update by epoch\n",
        "# num_steps = config_defaults[\"epochs\"]\n",
        "\n",
        "# Update by batch\n",
        "num_data = 1000 if Config.debug else len(train)\n",
        "num_steps = num_data // config_defaults[\"n_fold\"] * (config_defaults[\"n_fold\"] - 1) // config_defaults[\"batch_size\"] // config_defaults[\"gradient_accumulation_steps\"] * config_defaults[\"epochs\"]\n",
        "\n",
        "print(num_steps)\n",
        "\n",
        "if config_defaults[\"scheduler\"] == \"CosineAnnealingWarmRestarts\":\n",
        "    config_defaults[\"T_0\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingLR\":\n",
        "    config_defaults[\"T_max\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
        "    config_defaults[\"factor\"] = 0.2\n",
        "    config_defaults[\"patience\"] = 4\n",
        "    config_defaults[\"eps\"] = 1e-6\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingWarmupRestarts\":\n",
        "    config_defaults[\"first_cycle_steps\"] = num_steps\n",
        "    config_defaults[\"warmup_steps\"] = num_steps // 10\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"get_cosine_schedule_with_warmup\":\n",
        "    config_defaults[\"num_training_steps\"] = num_steps\n",
        "    config_defaults[\"num_warmup_steps\"] = max(50, num_steps // 10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6a78770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d8fc290b-6338-4994-ea18-4b881e0f6c2b"
      },
      "source": [
        "if Config.debug:\n",
        "    run = wandb.init(entity=Config.wandb_entity, project=Config.wandb_project, config=config_defaults, mode=\"disabled\")\n",
        "else:\n",
        "    run = wandb.init(entity=Config.wandb_entity, project=Config.wandb_project, config=config_defaults, notes=wandb_notes, tags=wandb_tags, job_type=wandb_job_type, save_code=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">lemon-dream-62</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ponkots/signate-471\" target=\"_blank\">https://wandb.ai/ponkots/signate-471</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ponkots/signate-471/runs/3iay1r3l\" target=\"_blank\">https://wandb.ai/ponkots/signate-471/runs/3iay1r3l</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210902_113007-3iay1r3l</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2408ee43"
      },
      "source": [
        "config = wandb.config"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezOfV_OKnV2I"
      },
      "source": [
        "## EDA-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1C7cU7ka70h",
        "outputId": "53472c55-e19b-4ca0-a2c7-12bcfa21fce5"
      },
      "source": [
        "# アブストが空っぽのが結構ある\n",
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id              0\n",
            "title           0\n",
            "abstract     4390\n",
            "judgement       0\n",
            "dtype: int64\n",
            "id             0\n",
            "title          0\n",
            "abstract    6546\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4fTaf66DiXj"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuuU17phnFMz"
      },
      "source": [
        "def preprocess(data):\n",
        "    \n",
        "    title_abstract = []\n",
        "    for e in data:\n",
        "\n",
        "        # アルファベット以外は空白に置換します。\n",
        "        e = re.sub(\"[^a-zA-Z]\", \" \", e)\n",
        "\n",
        "        # 小文字に変換します。\n",
        "        e = e.lower()\n",
        "\n",
        "        # token に分割します。\n",
        "        e = nltk.word_tokenize(e)\n",
        "\n",
        "        # stop word を削除します。\n",
        "        e = [word for word in e if not word in set(nltk.corpus.stopwords.words(\"english\"))]\n",
        "\n",
        "        # 見出し語化します。\n",
        "        lemma = nltk.WordNetLemmatizer()\n",
        "        e = [lemma.lemmatize(word) for word in e]\n",
        "        e = \" \".join(e)\n",
        "\n",
        "        title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylcVBT02nIGZ"
      },
      "source": [
        "def get_train_data(train):\n",
        "\n",
        "    # NaN を空白で埋めます。\n",
        "    train = train.fillna(\"\")\n",
        "\n",
        "    # abstract の有無を Stratified KFold で使います。\n",
        "    train[\"nan_abstract\"] = np.where(train[\"abstract\"] == \"\", 1, 0)\n",
        "\n",
        "    # title の単語数\n",
        "    train[\"len_title\"] = train[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # abstract の単語数\n",
        "    train[\"len_abstract\"] = train[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # title と abstract を接続します。\n",
        "    train[\"title_abstract\"] = train[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "    train[\"abstract_title\"] = train[[\"abstract\", \"title\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "    # train[\"preprocessed_title_abstract\"] = preprocess(train[\"title_abstract\"])\n",
        "\n",
        "    # 前処理した文の単語数\n",
        "    # train[\"len_preprocessed_title_abstract\"] = train[\"preprocessed_title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return train"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YskezxynKkm"
      },
      "source": [
        "def get_test_data(test):\n",
        "\n",
        "    # NaN を空白で埋めます。\n",
        "    test = test.fillna(\"\")\n",
        "\n",
        "    # title の単語数\n",
        "    test[\"len_title\"] = test[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # abstract の単語数\n",
        "    test[\"len_abstract\"] = test[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # title と abstract を接続します。\n",
        "    test[\"title_abstract\"] = test[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "    test[\"abstract_title\"] = test[[\"abstract\", \"title\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "    # test[\"preprocessed_title_abstract\"] = preprocess(test[\"title_abstract\"])\n",
        "\n",
        "    # 前処理した文の単語数\n",
        "    # test[\"len_preprocessed_title_abstract\"] = test[\"preprocessed_title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return test"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0CPmvZnQFP"
      },
      "source": [
        "if False:  # os.path.exists(\"/gdrive/MyDrive/Datasets/signate-471/preprocessed_train.csv\"):\n",
        "    !cp -f /gdrive/MyDrive/Datasets/signate-471/preprocessed_train.csv .\n",
        "    train = pd.read_csv(\"preprocessed_train.csv\")\n",
        "\n",
        "    # csv を再読み込みすると NaN に戻ってしまうので、再度変換します。\n",
        "    train = train.fillna(\"\")\n",
        "\n",
        "else:\n",
        "    # 一度、前処理したものは保存しておきます。\n",
        "    train = get_train_data(train)\n",
        "    # train.to_csv(\"preprocessed_train.csv\")\n",
        "\n",
        "    # artifact = wandb.Artifact('preprocessed_train', type='dataset')\n",
        "    # artifact.add_file(\"preprocessed_train.csv\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    # !cp -f preprocessed_train.csv /gdrive/MyDrive/Datasets/signate-471/"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A248D057nSd6"
      },
      "source": [
        "if False:  # os.path.exists(\"/gdrive/MyDrive/Datasets/signate-471/preprocessed_test.csv\"):\n",
        "    !cp -f /gdrive/MyDrive/Datasets/signate-471/preprocessed_test.csv .\n",
        "    test = pd.read_csv(\"preprocessed_test.csv\")\n",
        "\n",
        "    # csv を再読み込みすると NaN に戻ってしまうので、再度変換します。\n",
        "    test = test.fillna(\"\")\n",
        "\n",
        "else:\n",
        "    # 一度、前処理したものは保存しておきます。\n",
        "    test = get_test_data(test)\n",
        "    # test.to_csv(\"preprocessed_test.csv\")\n",
        "\n",
        "    # artifact = wandb.Artifact('preprocessed_test', type='dataset')\n",
        "    # artifact.add_file(\"preprocessed_test.csv\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    # !cp -f preprocessed_test.csv /gdrive/MyDrive/Datasets/signate-471/"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UPOk9WroUmX"
      },
      "source": [
        "## EDA-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BloR0mcceTWK",
        "outputId": "b700819f-7c41-430a-f043-365d14dd64f0"
      },
      "source": [
        "# abstract に改行は含まれていない\n",
        "print(len(train[train[\"abstract\"].str.contains(\"\\n\")]))\n",
        "print(len(test[test[\"abstract\"].str.contains(\"\\n\")]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHfTQdU8Cezv",
        "outputId": "24d8691d-707f-4380-9f2f-a83bad3cce6f"
      },
      "source": [
        "# title の単語数\n",
        "print(train[\"len_title\"].max())\n",
        "print(test[\"len_title\"].max())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n",
            "69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx2M2402NSOU",
        "outputId": "28552e6e-9860-493d-9149-93a999db6e00"
      },
      "source": [
        "# abstract の単語数\n",
        "print(train[\"len_abstract\"].max())\n",
        "print(test[\"len_abstract\"].max())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1535\n",
            "1445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1WviNuCdGec"
      },
      "source": [
        "# 前処理した文の単語数\n",
        "# print(train[\"len_preprocessed_title_abstract\"].max())\n",
        "# print(test[\"len_preprocessed_title_abstract\"].max())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "18097672",
        "outputId": "179efcdb-c80b-4d75-ff01-d09c56dd003b"
      },
      "source": [
        "for ds in [train, test, sub]:\n",
        "    print(f\"=\" * 80)\n",
        "    ds.info()\n",
        "    display(ds.head())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27145 entries, 0 to 27144\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   id              27145 non-null  int64 \n",
            " 1   title           27145 non-null  object\n",
            " 2   abstract        27145 non-null  object\n",
            " 3   judgement       27145 non-null  int64 \n",
            " 4   nan_abstract    27145 non-null  int64 \n",
            " 5   len_title       27145 non-null  int64 \n",
            " 6   len_abstract    27145 non-null  int64 \n",
            " 7   title_abstract  27145 non-null  object\n",
            " 8   abstract_title  27145 non-null  object\n",
            "dtypes: int64(5), object(4)\n",
            "memory usage: 1.9+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>judgement</th>\n",
              "      <th>nan_abstract</th>\n",
              "      <th>len_title</th>\n",
              "      <th>len_abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>abstract_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>Longitudinal studies indicate that declines in...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>193</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>Longitudinal studies indicate that declines in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>The present study was undertaken to validate t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>214</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>The present study was undertaken to validate t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>Objective: To report a case series in which ba...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>133</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>Objective: To report a case series in which ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>374</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                     abstract_title\n",
              "0   0  ...  Longitudinal studies indicate that declines in...\n",
              "1   1  ...  The present study was undertaken to validate t...\n",
              "2   2  ...  Objective: To report a case series in which ba...\n",
              "3   3  ...  The etiology and pathogenesis of idiopathic ch...\n",
              "4   4  ...   Prolonged shedding of SARS-CoV-2 in an elderl...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   id              40834 non-null  int64 \n",
            " 1   title           40834 non-null  object\n",
            " 2   abstract        40834 non-null  object\n",
            " 3   len_title       40834 non-null  int64 \n",
            " 4   len_abstract    40834 non-null  int64 \n",
            " 5   title_abstract  40834 non-null  object\n",
            " 6   abstract_title  40834 non-null  object\n",
            "dtypes: int64(3), object(4)\n",
            "memory usage: 2.2+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>len_title</th>\n",
              "      <th>len_abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>abstract_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27145</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>The objective of the paper is to analyse chang...</td>\n",
              "      <td>16</td>\n",
              "      <td>245</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>The objective of the paper is to analyse chang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27146</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td></td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27147</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
              "      <td>14</td>\n",
              "      <td>315</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27148</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>We present a method that significantly improve...</td>\n",
              "      <td>11</td>\n",
              "      <td>119</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>We present a method that significantly improve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27149</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>The objective of this study is to compare the ...</td>\n",
              "      <td>13</td>\n",
              "      <td>224</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>The objective of this study is to compare the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                     abstract_title\n",
              "0  27145  ...  The objective of the paper is to analyse chang...\n",
              "1  27146  ...   Leukoerythroblastic reaction in a patient wit...\n",
              "2  27147  ...  [15O]-water PET was performed on 12 patients w...\n",
              "3  27148  ...  We present a method that significantly improve...\n",
              "4  27149  ...  The objective of this study is to compare the ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype\n",
            "---  ------     --------------  -----\n",
            " 0   id         40834 non-null  int64\n",
            " 1   judgement  40834 non-null  int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 638.2 KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>judgement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27146</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27147</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  judgement\n",
              "0  27145          0\n",
              "1  27146          1\n",
              "2  27147          1\n",
              "3  27148          0\n",
              "4  27149          1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9L3nMYzDMqJ"
      },
      "source": [
        "### 目的変数 judgement の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "3f5772d0",
        "outputId": "aba49e20-2f4a-4b05-bd14-781ac5694986"
      },
      "source": [
        "sns.distplot(train[\"judgement\"], kde=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3792e51e50>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuZVvlM8Xy91",
        "outputId": "d9fda47d-c4a8-44f9-d002-e30284b4dc9c"
      },
      "source": [
        "train[\"judgement\"].value_counts()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    26515\n",
              "1      630\n",
              "Name: judgement, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E-56356_L3T",
        "outputId": "602c6847-7482-48ea-cadf-a14a22e2b557"
      },
      "source": [
        "border = len(train[train[\"judgement\"] == 1]) / len(train[\"judgement\"])\n",
        "print(border)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0232086940504697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZNrZoksDSMb"
      },
      "source": [
        "### title の単語数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "ixixzShVH80j",
        "outputId": "6a75f723-6ae4-492d-90e5-c786bb48904f"
      },
      "source": [
        "g = sns.FacetGrid(train[[\"judgement\", \"len_title\"]], hue='judgement')\n",
        "g.map(sns.distplot, 'len_title', label='judgement', hist=True, rug=False)\n",
        "g.add_legend()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f37937ccb50>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 278.125x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W_kt9XDpGTm2",
        "outputId": "534de0e0-1170-410a-8795-8197a977a02b"
      },
      "source": [
        "sns.distplot(test[\"len_title\"], hist=True, rug=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f37930e0b10>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6gm9NCpDZ6V"
      },
      "source": [
        "### abstract の単語数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "EqwDn4hUImd6",
        "outputId": "aed50b47-d688-430f-8a50-d61e528db441"
      },
      "source": [
        "g = sns.FacetGrid(train[[\"judgement\", \"len_abstract\"]], hue='judgement')\n",
        "g.map(sns.distplot, 'len_abstract', label='judgement', hist=True, rug=False)\n",
        "g.add_legend()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f379434f510>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAADQCAYAAAAK56SEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZRcd3XnP7fW3nfJkizZkmXZRhiCjTFriNmMIQkOCQR8IGECg5NMSEKW4UBIguGQk2SYGRK2JITNYdgNJA6LjW3MeFi8yPsiyzKSrV29b9Vd23t3/vj9qru6Vd1d1V2t6n66n3Pq9Ov3fu/37murvr73/pYrqophGMZ8Yo02wDCMtYmJg2EYFTFxMAyjIiYOhmFUxMTBMIyKrCtxuOqqqxSwj31W82N41pU4DA4ONtoEwzhjqEocROQqEdknIk+KyHsrXE+LyNf89btEZHvZtff58/tE5NVl57tE5AYReVxE9orIC+vxQoZh1IclxUFE4sAngdcAu4FrRGT3vGbvAEZU9Xzgo8Df+3t3A28GnglcBXzK9wfwj8BNqnoR8AvA3pW/jmEY9aIaz+Fy4ElVPaCqeeCrwNXz2lwNXO+PbwBeISLiz39VVXOqehB4ErhcRDqBlwKfBVDVvKqOrvx1DMOoF9WIw9nA4bLfj/hzFduoahEYA3oXuXcHMAB8XkTuF5HPiEhrpYeLyLUiskdE9gwMDFRhrmEY9aBRCckEcCnwT6p6CZABTsllAKjqp1X1MlW9bMOGDafTRsM4o6lGHI4C28p+3+rPVWwjIgmgExha5N4jwBFVvcufvwEnFoZhrBGqEYd7gF0iskNEUrgE443z2twIvM0fvwH4obrlnjcCb/ajGTuAXcDdqnoCOCwiF/p7XgE8tsJ3Ob3s+fzsxzAiSGKpBqpaFJF3ATcDceBzqvqoiHwI2KOqN+ISi18UkSeBYZyA4Nt9HffFLwJ/oKqB7/oPgS95wTkA/E6d380wjBUg62k/h8suu0z37NnTaDMc5R7DZaZrEUIabcBaYV3NkDQM4/Rh4mAYRkVMHAzDqIiJg2EYFTFxMAyjIiYOhmFUxMTBMIyKLDkJKjLYvATDqAnzHAzDqIiJg2EYFTFxMAyjIiYOhmFU5IwRh7sODnPXweFGm2EY64YzRhwMw6gNEwfDMCpi4mAYRkVMHAzDqEgjK149JSIPi8gDIrJGtncyDKPEktOnyypevQq3a/Q9InKjqpZvCDtT8UpE3oyrePWmeRWvtgC3isgFZftIvkxVrQCmYaxBGlLxqj6mG4axmjSq4hW4cuc/EJF7ReTa2k03DGM1aeSqzJeo6lER2QjcIiKPq+od8xt54bgW4JxzzjndNhrGGUujKl6hqqWf/cC3WSDcsHJ4htEYGlLxSkRaRaQdwBfQvRJ4ZOWvYxhGvWhIxSsROQv4tstZkgC+rKo3rcL7GYaxTKrKOajq94DvzTv312XHWeCNC9z7N8DfzDt3APiFWo1dMzz4Vbjzn+DS34JUW6OtMYxVwWZI1koYwnf+FAb3waE7G22NYawaZ84ekvVgz+dh/BgUMgDkB54kdf4rG2yUYawO5jnUyvgRAO4LzyccnT9oYxjRwcShViZOkifBD4NLaAomuOfJE422yDBWBROHGtGpYY6GvRzSswBIF0YbbJFhrA4mDjVSnBrhqPZxRPsASBXGGmyRYawOJg61Mj3MMe3jmPYCkDZxMCKKiUMtBEWS+XGOah+ZeAdF4uY5GJHFxKEWsi6/cJQ+trfk6ddu0oXxBhtlGKuDiUMt5JwQnNRutjbnGNBOEsVMg40yjNXBxKEW8pMAFBJttMUDBrWDRDDVYKMMY3UwcaiFvPMSmppbSMeVIe0wz8GILJEXB1UlkyvWpzMvDu2tzTTFQobpIBVMgWp9+jeMNUTkxeH2ff088wM3sz/TtOK+NJdhStNsak3SFAsZ1A5iGszkIgwjSkReHJ7sd3mC2wa6VtxXNpthmHa2tQY0xUOGtd1dyNgG2kb0iPyqzO6WFACPTLQuu48v33WIJ05O8Gv9U8S1ja2tAT/PuLACgKkh6N1ZD3MNY80Qec+hELh8wGghvuw+BidzfOGnT6GFLCPazsXdRZpiIUPqxcE8ByOCRN5zKAThivv4+YALTfpknK6ubjY2hTTFlVG8N5K1xVdG9GhYOTx/LS4i94vId1b6IguRL65cHIYm8yRiwub4GDt6mgFoioWMqReH6ZEVP8Mw1hpLikNZObzXALuBa3yZu3JmyuEBH8WVw2NeObyrgE/5/kr8MbB3pS+xGHnvOcgK+hiazLGxNUYizEHKCUI6FjJBC4rAtHkORvRoWDk8EdkK/DLwmZW/xsLUI6wYyuTZ0ZIH4OCEcNfBYZriIUqMrDRZWGFEkkaWw/sH4D3Aot9eEblWRPaIyJ6BgYEqzJ1LSRwCXZ7vEIbKcCbPOU1umnQx3gJAShRBmZIW8xyMSNKQ0QoR+RWgX1XvXartSitelXIOAUK4jImMI1N5iqGyKelmRxYTLucg4kKLDC3mORiRpFHl8F4MvE5EnsKFKS8Xkf+zDPuXpDSUCcvzHvoncgD0xfyiK+85ADTFlEnzHIyI0pByeKr6PlXdqqrbfX8/VNW31uF9TiFflnMoLkMcTo5nAeiVCddHmTik4yETtJrnYESShpTDW6V3qUj5UGawjLCi5Dl0UUEc/IgF00dWZqRhrEEaUg5v3vUfAT+qxo7lUFih5zDgxaFDxynG0mhsdiQ2FVM31yE76lZmykoGTA1jbXEGTJ9eeVjRnIzTUhid4zWA8xzGaIUgD4XpFdtqGGuJyItDeVhRDJeRkBzP0d6UIF0YnRmpKJGOKaNqU6iNaBJ9cShLNCzHczg+Nk1nc5J0fmTOSAVAKhYyor7Kto1YGBEj8uJQKK4srDg6mvXiUDmsGA69OJjnYESM6IvDCnIOuWLA4GSOzpakDyvmi4MyFJYWX5k4GNEi8uKQD0KScScKtYrDiTE3x2FDOiQRTFf0HAZDvxuUeQ5GxIi+OBRDWtNuxLZWcTg26sRhU9Ktqzg156AMlMTBPAcjYkReHApBSEvSzU2odbTiyIgThbMSbur0qWGFnwQF5jkYkSPy4pAPQlq851Dr2oonTk6QSsTYEPOLruJzhzJTMSUkRpjuMM/BiByRF4dCUWlNec+hRnHYd3KS8ze00Vx0X/xCBc8BIEx3mudgRI7oi0NQnnOo7d59J8a5aFM76bzbBq5SQhIgSHWa52BEjsiLQ74Y0pKqPSE5nMlzcjzHRZvbSRdGUaRiWAFQSHWY52BEjuiLQxDSmq49rHjwiPuy94/nSOdHyCc7QOb+uUqeQz5pnoMRPSIvDnPCihpGKx46PIYAZ3c1k86Pkkt1n9Im7T2HXMI8ByN6RFocglAJldmhzBo8h4ePjtLXliadjJMujJJLnlpOr+Q5ZBPt5jlEHBH5aQ1tr1jNcgvLRUTeLSItS7d0RFocSlOnW5YxWnFgIMPGjjQA6fwIudSp4pDy4jAdb4cgZ8u2I4yqvqjRNtSBdwMmDuA8B4CmGsWhGIQcHpmitzXNzkPfoHX6OKn8qZ5BKazIxGxlZtQRkcn5HoGIfEJE/os/vkpEHheR+4BfL2uzQURuEZFHReQzIvK0iPT5a28VkbtF5AER+ZdSTRf/rI/4e24VkctF5EcickBEXufbxH2be0TkIRH5XX/+Ct/2Bm/Pl8TxR8AW4HYRub2ad25IxSsRafJ/lAf9H+CD1dhRK0W/XLsp4cSh2klQx8eyFAKlry0FqiSCqVOGMWE2rJgUW5l5JiMiTcC/Ar8KPBfYVHb5A7g9Up+Jq+lyjr/nGcCbgBer6nOAAHiLv6e17J4J4MPAq4DXAx/ybd4BjKnq84DnAe/0+7QCXILzEnYD5/lnfAw4BrxMVV9WzXstuU1cWcWrV+HqTtwjIjeq6mNlzWYqXonIm3EVr940r+LVFuBWEbkAyAEvV9VJEUkCPxaR76vqndUYXS2F0H15k3EhIWHVCcmDg25GZE9bithEnpgGp0ydhtmhzAkxz+EM5yLgoKruB/A7qV/rr70E96VGVW8SkVLtxFfghOQeV/+JZqDfX8sDN/njh4GcqhZE5GFguz9/JfBsEXmD/70Tt4FzHreJ8xFvywP+nh/X+lLV7CE5U/HKP6xU8apcHK4GrvPHNwCfmF/xCjjoN6C9XFV/Bkz69kn/Wcb2r4tTCivisRhxqT6sODTs1lT0tqZJjlZedAWQ9IVtJqyg7plCkbnedtMK+hLgelV9X4VrBb97O7iiTzkAVQ196YfS/X+oqjfP6VTkilJ7T8AyC2Y3rOKVj5kewKnlLap6V6WHr6TiVSkhmYgLCdGqd5/uH88iAm3pBInAV7qat0Wcs82FFjNbxZnnEHWeBnb7MLoL939/gMeB7SKy0/9+Tdk9PwF+E0BErgRKY+K3AW8QkY3+Wo+InFuDLTcDv+89b0TkAhFpXeKeCaC92gc0LCGpqoGPtbYCl4vIxQu0W3bFq1LOIRkX4qJV5xwGJnP0tqaJx4REcW4ZvPmkY8pIaJ7DGYCq6mHg68Aj/uf9/kIWF0Z81yck+8vu+yBwpYg8gtuh/QQw4cPyvwR+ICIPAbcAm2uw5zM47/0+3/e/sLSH8GngpmoTktW4G7VUvDpSZcWrGVR11Bt7Fe6PXjeKc8IKrTqsGJjIsaHdDWMmAzc8WSmsAL+PZOi9S/McIomI9OLqsaCq78HVeJ2Dqt6Eyz3MZwx4ta//8kLgeT7MRlW/BnytQl9tZcfXVbqmqiHwF/5Tzo8oK/Wgqu8qO/448PEFX3QeDal45Yd3ugBEpBmX7Hy8WqOrpVhKSMaEhFQ/WtE/kWOjF4cZz6FCQhKc5zBdBGxlZiQRkS3Az4D/ucwuzsElHR8EPga8s162rTYNqXglIpuB6/1ISAz4uqrWfUZZKaxIxGM+rKjuvoGJHBec5UKzRDCFIgSxyrmnVCxkOh9As62viCKqegy4YAX378cNLa47GlLxSlUf4jT8wUphRSImVYcVYagMlHkOyWDK7eOwQDWrdEyZLgTQ1GWegxEpIj1Dslg2WlFtQnJ0ukAx1JmcQ6KYoRhfOAmcjoVMF0Jo7jLPwYgUkRaHQlBKSJaGMpcWh1JtzL62Wc9h/j4O5aRiSjZvnoMRPSItDqVJUMm4mwRVjTgMTs4Vh0RxikJiKc8hMM/BiByRFofS9OnZnMPS95TEYUN7CoBkkFlwjgM4cZgyz8FoEEute1oJy5pWuV6YGa0ozXOoYm1FeVghYYFEkD1lY9ly0jElW/Icilm3bDu5cBhiRJPt7/3utUu3qp6n/u6XP71UmyrXPS2bSHsOQVh7QvKOJwaJi/Ddh46TLowBLJmQnMoX0Sa/34OFFsbpY2bdk6rmgdK6p7oQaXEolE2fTlS58GoyV6StKYGIkM4Pu34W8Rya4yGh4vaYBAstjNNJNeuelk2kxSEIlTgBW7772/zX4lcIl76FyVyBNr/nZFNpS/olxAFgOmZl8YxoEWlxKAQhz4/tpeXpH/La4Ha6dOkv7mSuOCMOpXoVhUXCipI4TMZL4jCyYFvDqDPVrHtaNpEWh2KoPE/2zfz+LLcXx6JMZotlnkMVYUUsAGAi5sOKqaHlmmsYtVLNuqdlE3lx2BU7StC6EYCtenLR9mGoZHIBbU1zPYfFhjJLnsMYJXEYXKnZhlEVfu+U0rqnvbg1So/Wq/+ID2WG7JDjhGc9i7GD97KNE4u2H5suEKjOCSsK8eZTitmU01IShyAFiSbImDiciVQz9LgaVFr3VC+i7TkEyhYZQrvO5WRsI9tkcc+hNAGqPKxYzGsAaCrlHHIBtPTB1HAdLDeMxhNpcdBClm6ZRNo3MxDbwLksLg4DJXEoCysWyzcAtJR2oN7/Y7ern4UVRkSItDiks263LunYzGishy6ZhCC/YPvBSXdtNqwYXXQCFJSNVhQFUm0WVhiRIeLi4DakjXdsnh1NyI4v2L40dXomrMgNLbroCiAZU1IxZbLgxcE8ByMiRFocmnOznkPGz0PQRcTh8PAUqUSMllScWFigqTBCIdG2YPsSbQn1nkMrZGwo04gGjap4tU1EbheRx3zFqz+u1wuV0+I9B9o3k/GeQ5idWLD900MZeltTbup0zn3JqxGH1qQyUYg5z6GQsZqZRiRYUhzKVn69Blde6xpfyaqcmYpXwEdxFa+YV/HqKuBTvr8i8Gequht4AfAHFfpcMS25QQoah+buGc8hzC3sOTw9NEVvq1uq3Zxz4UG+CnHoTIaM5X1YAZZ3ME4LIvI5Een3W9PXnUZWvDoOoKoTIrIXt2CkLktNSzQVRxmRDjaKkIu1UtQY4QJhRRAqh0emeNHOPmBWHArJpcWhO6WM5GOQ9vmJqUHo2rb4TUa0uK6zrku2uW6smnkTXwA+AfxbXZ/taVjFqxI+BLkEqHvFq6biGOO+wE88JgzSuWBC8vDwFIVAZzyHppx7VjVhRVc6ZHSO52B5B2P1UdU78PU0VoOGJiRFpA34JvBuVa34rV1Jxavmwhjj4sVBlAHthFzlnMODR9yirC1dbqOWGc8hXo3nEDKSi0Haj4hMLj6fwjDWA9WIQy0Vr6i24pWv8fdN4Euq+q3lGL8UzcH4TAXsuCj92k0sN1ax7f2HRmlOxjmrw9WnaM4Nkk12obH4ks/pSinjBSEoicPEsfq8gGE0kEZVvBJcIZy9qvq/6/EilWgpjs3Mb0iI0q9dxPKVPYcHDo/yrK2dxGNuQ5im/CDZdF9Vz+lKhSjCeJB2e0lOLL6GwzDWA0uKw0Irv0TkQyLyOt/ss0CvTzj+KfBef++juIKjjwE34SteAS8Gfgt4uYg84D+vreubqdIajDPpxSEuMECnE4cwmNM0Vwx47Ng4l2zrmjnXnB1kukpxGB5zgjOSj0HHFhMHIxI0quLVj3ErEVaPfIYExTJxUAa1E0HdngttG2ea/sMt+8kHIRPZ4sy55twAE62XVfWotoQTm5G8QPsmmDhexxcxjMqIyFeAK4A+ETkCfEBVP1uv/qO7ZHvaJXEz8dmwYlA73bXJ/jnicHjEFcvd1uMWWYkGNOf6yTRvqupR7V4cRnMxaN8MA/uWuMOIHNUNPdYVVb1mNfuP7vRpv3R6KjHrOQyoDxsy/XOaHhvN0pZO0NmcBKApO0BMA6aaqhOHDi8Og7mY9xxOnBK6GMZ6I7ri4D2HXMJ5CwlRN88BnOdQxomxaTZ1zlbRbs26nEGmeXNVj+pOunDkxLT3HDSwWZLGuie64uA9h+mkE4RUbF5Y4SkGIScncmzumBWHFi8OU03ViUMyprQnipyYjjtxAMs7GOue6IqD3wU6n3ShRFKUCZoJJDEnrDgwmCEIda7nMO2+2JkqwwqAnmSR/mwMOrw4jNtcB2N9E11x8J5DznsOyZgCQi7RAZOz07D3HncTM8vFoSV7nHyinWIV6ypK9CSLLqzoOtedGH16hS9gGI0luuIwPcIkLSSSviCuuB2bsomOOZ7D3uMTxEXY0J6eObdh+D6K8WZ2HvpG1Y/rThU5OR2Dll63xmLkqfq8h2E0iAiLwzDj0kYy7l7ReQ4wneiYk3PYe3ycjR1pErHZP0W6MDbjcVRLT7LIUC5GIVTo3g4j5jkY65voisPUMKO0k0q4uVYpceIwFZsrDvtPTsyspwBAlXR+hFyqi1roThZQhP6ffBEQOH7/il/BMBpJdMVhephRnfUcEt5zmIh3uP0WwoBsIeDYWJa+ttTMben8MIkwRzbVU9PjelJuONOFFj1u2bZqnV7GME4/0RWHqWFGtI2UF4eUzzlMxDpAQ5ga5ukhNzOyt3U239CRceFANtVb0+N6kiVxiLv6FWHhlPkUhrGeiK44TA8zHLaRTLhXjAsIyriU5jqc5OBgBoDeMs+hvSQO6drEYc5EqBZ/ryUljXVMNMUhDCA7xpC2zoQVIm6uw5j4PRcy/Tw15MShr23Wc2ifeopQYjUnJNsTAUlRTmZj0Oo3pRlaunCvYaxVornwatrt6jSqbfTFZxd/JmPKcMwnGsePc+tjTbSm4jQlZzd06cg8TS7Vs2h9zErEBDY2hy6saO2FWBL69678XQyjQUTTc/DrKka0jVRi9hWTogzgXf7xowxl8vSWeQ3gwopak5EltjQHHJ2KOWFpO8vEwVjXRFMcptwGr6O0z4QVAMlYSCZMOrd/7AhDk7k5IxXxIEtH5iBT6Y2ndFkN29oCDmW8F9K+CQYeX/47GEaDibQ4DOl8cVByoUDH2QSjhxnPFud4Dl0T+4lpQKZ5y7Iee25rwInpONkAJw7jR2dCHMNYbzSk4pU/v3oFObw4DGvHzFAmuIlQuUCgcyuFkSMAM1vRA3SPuzCglgVX5Zzb5vZwOJwpW51p3oOxTmlUxStwBTmuqsM7nIrfS2GY9jk5h0RMyYVA51YS40cAneM59Iw9Ri7ZSb7GkYoS57Q6cTg0GYcOX57j+IPL6sswGk01nsNMxStVzQOlilflXA1c749vAF4xv+KVqh4EnvT9rW5BjqkhwkQzWdJzwooZz6FnJ4lgig2M0lfmOfSMP8ZwxzPcuOcyGB52onT703lo7nLew5E9K3sXw2gQDa94tSpMDVFsciMOyTlDmaETh75dAFycPknaD2MmCxN0je9jqOvZy35seyKkK1HkcNYLztnPhaMmDsb6ZM0nJJdVDm9qiELai8O8ocx8CPRdAMCz0rOVqTYO30uMkBO9L1iRvVubcxyZ9qHK2c+F4QMze0sYxnqiYRWvqmVZ5fCmhiikuwFIVxyt2EKGJi6Mz27ltmnopxRjaQZX4DkAbGvOcSSbJlRm95H80d+uqE/DaAQNqXhVH9MXITNI3i+5nu855AJhMh/wWHgOF4V+erOGbDtxG+Ot29lxdP6r1ca5zTlyYYwDE3FfaVtsbwdjXdKoilelghw/Ay4UkSMi8o66vdXU8Mwsx/KEZHM8ZLIgPDWY4a7wGWzPPUGiOMWGkftoyfUz0vGMFT96V+s0APcNJyHR5JKSIwdX3K9hnG4aUvHKn1+dghzFHOQnyJY2li1LSHYkiowVYjzZP8ld4TN4F//BWUN3c97RfyeX7HAjFStkS1Oe1njA/UNJfnN71iU/n/4pFLKQbFq6A8NYI6z5hGTN+AlQ00mfcygLKzqTbh7CvU+PcGe4m+lUD89/5ANsO3kbT5z7FsJYcsWPjwlc2DbNT/pTbq+Xvl1ub4cj96y4b8M4nURPHHwScMoXsykPKzoTbs+Fuw8O09vRxp7df0GimOF47wt4dOc762bCpZ2THMrEeXIiDj07AYGDd9Stf8M4HURvybavcD0ad6svm1Nly7G957Dv5AS/uKuPw5tfzZFNr0Qlfmo/K+DSzkkAbjmWZtdFgUtMHrwDeH9dn2MYq0n0PAdfaWpQXEKyLT2rfyXPAeDCs9oB6i4MAL2pIhd3FbjtuJ8M1XeBCytsEZaxjoisOAxoNzGB5rKNXEo5B4ALNrWvqhmv3JLjvqGk23B2425XP/Pnt63qMw2jnkRTHFo3MF6A1lQCKVsn0RwLZ46ft315G7pUy3Y5iSJ8/akmV8eiuQeeuHlVn2kY9SSC4nAC2jcxlS/Smp6bUhGBt5zdz/vOP0z/7f9cU0WrWtncVODZHZNc/2QLmSAOu66E/T+AoLj0zYaxBoieOIwfg/YtZHIBrelT8wmv2zTMczozM7/vPPSNmU+9eePmQQZzMT72WAtceJUr7nv4zro/xzBWg+iJw9hh6DybyVxxTjKyEVzQluWaHdN8+okW7k48F5It8PANDbXJMKolWuIwNez+79xzHpncqWFFI7iq8xCb0gWu/erj5C94LTz6bTeL0zDWONESh9Iahp7zmFwj4tAUV9614xjj2QJfmnohZEdh73822izDWJJoicOwF4fuHWTyjQ8rSpzfmuX55/Xy4cfPIte5A372Saujaax5IiYOB9zP7u0LJiQbxSsu2kh7c5ov8qtw7D44cHujTTKMRYmWOJx4GLp3QKrFhRWpteE5ALSkEvzirg185OSlDKW2wPffC0Gh0WYZxoJESxyOPQBbLqEQhOSL4ZrIOZTYeegbXBP/IWe3BPxl5k0wuA++VHGVu2GsCaIjDpkhGDsEWy5hYMKNBvSU7Sy9FogL/NnOo/xULuFb8goXWjy0ehOxDGMlREccDv7I/dx2OQcG3CSn8za0Ns6eBehLFXnP+Uf4UP6t7NEL0W//Ljz67402yzBOITrisPc7rgbm1udxYNAtmd65oa3BRlXm/NYsf3XhUf5c3829wfmE33g7Q//3XxptlmHMoZHl8BbtsyZGD8Pj34HdV0MszoGBDK2pOBvb00vf2yC2Nuf562ec5KsXfpQ7govpvf09fOuDv8Hb//k2/uHWJ7jrwBC5YrB0R4axSiyZsSsrh/cqXFGae0TkRlV9rKzZTDk8EXkzrhzem+aVw9sC3CoiF/h7luqzOvIZ+NY7AYGX/AkABwYz7NjQOmdF5lqkNRHyRu7k+K5f5yfHe/m16dt42Ym7+eqRX+LjP7yYsXgPz9rcykW9cXqTBboTedrTMWJtG4i3byTVsZFUey8tTWlaUnHSidiaf2dj/VBNOn+mHB6AiJTK4ZV/ka8GrvPHNwCfmF8ODzjod6e+3Ldbqs/q6H8cTjwCr/9n6NwKwO/90nlkC+vn/7qbmwM47yXc3Hktz97/SX538Hv8vvpZlP3+swCBCqO0MUKSInFu5kV8KvFbAKifaLXQdKuSjCgQhooqxONCIiYkYjFiFXSm1qlbAjOCVdKtcv0S5l2rsf/lcsPvv4i+trXrWa4FqhGHSiXtnr9QG1Utikh5Obw7591bKoe3VJ+Aq3gFXOt/nRSRfRWtfP9vLPUefcDgUo0azDJtHCs7/jnwxTqZsyDr4W8Ji9i54T0L3nOTqq5Oged1xtqZCLAAqvpp4NMr7UdE9qjqZXUwadVYDzaC2Xmm0KhyeCsuk2cYxurSqHJ41fRpGEYDWTKs8DmEUjm8OPC5Ujk8YI+q3ogrh/dFn3Acxn3Z8e1K5fCKzC2Hd0qf9X+9Oaw4NDkNrAcbwew8IxC1pcOGYVQgOjMkDcOoKyYOhnif5O0AAAUHSURBVGFUJPLiUNdp2vWx5ykReVhEHhCRPf5cj4jcIiL7/c9uf15E5GPe9odE5NJVtOtzItIvIo+UnavZLhF5m2+/X0TeVulZdbbxOhE56v+eD4jIa8uurf7U/SijqpH94JKdPwfOA1LAg8DuBtv0FNA379z/AN7rj98L/L0/fi3wfdzEwRcAd62iXS8FLgUeWa5dQA9wwP/s9sfdq2zjdcCfV2i72//3TgM7/L+D+Fr8N7FWP1H3HGamfqtqHihN015rXA1c74+vB36t7Py/qeNOoEtENq+GAap6B26kaSV2vRq4RVWHVXUEuAWo22zDBWxciJmp+6p6EChN3V8v/yYaTtTFodLU77MXaHu6UOAHInKvnxoOcJaqHvfHJ4Cz/HGj7a/VrkbZ+y4f3nyuFPqsQRvXHVEXh7XIS1T1UuA1wB+IyEvLL6rzidfc+PJatQv4J2An8BzgOPC/GmtOdIi6OKy5adqqetT/7Ae+jXNzT5bCBf+ztA6z0fbXatdpt1dVT6pqoKoh8K/MrvpdMzauV6IuDmtqmraItIpIe+kYuBJ4hLnTz98G/Ic/vhH4bT868AJgrMzNPx3UatfNwJUi0u3d+yv9uVVjXg7m9bi/Z8lGm7q/EhqdEV3tDy6z/gQuQ/3+BttyHi47/iDwaMke3PL224D9wK1Ajz8vuE1xfg48DFy2irZ9BeeWF3Bx+DuWYxfwdlzy70ngd06DjV/0NjyE+5JvLmv/fm/jPuA1a/HfxFr+2PRpwzAqEvWwwjCMZWLiYBhGRUwcDMOoiImDYRgVMXEwDKMiJg6GYVTExOE0ISKTp+k5XxCRN1TZtktE/lsdn32FiLyoXv0ZjcXE4cymC6goDn4X8Vq5AjBxiAgmDg1ARP67iNzjVxJ+0J/bLiJ7ReRfReRREfmBiDQv0sc7fR8Pisg3RaSl7PIrRWSPiDwhIr/i2z9TRO72G6I8JCK7gL8DdvpzH/H/5/9/InIjvvqYiPy7X0H6aNkq0tKGKff5598mrj7q7wF/4vv7xXr/3YzTTKOnaJ4pH2DS/7wStyuy4MT5O7hNTLbjduh+jm/3deCti/TXW3b8YeAP/fEXgJt837tw04ybgI8Db/FtUkCzf2b5xilXABlgR9m50pTpZty6hV5gA27Z8455ba6jwsYr9lmfnzVf8SqCXOk/9/vf23Bf4kPAQVV9wJ+/F/flXYiLReTDuNCgjbkLnL6ubpXifhE5AFwE/Ax4v4hsBb6lqvulctHdu9VtjlLij0Tk9f54m7d1A3BHqZ2qVrsBi7GOsLDi9CPA36rqc/znfFX9rL+WK2sXsHhdkS8A71LVZwEfxHkHJeYvmFFV/TLwOmAa+J6IvHyBfjMzhopcAbwSeKGq/gJO0JoWuM+IGCYOp5+bgbeLSBuAiJwtIhuX0U87cFxEksBb5l17o4jERGQnbiXoPhE5Dzigqh/DLb1+NjDh+1mITmBEVadE5CLcfpHgiiO/1C+FRkR6/Pml+jPWESYOpxlV/QHwZeBnIvIwcAPL+0L9FXAX8BPg8XnXDuH2Lvg+8HuqmgV+E3hERB4ALsbtATkE/EREHhGRj1R4xk1AQkT24pKXd/p3GMBVPv+WiDwIfM23/0/g9ZaQjAa2ZNswjIqY52AYRkVstGKNIyKfBF487/Q/qurnG2GPceZgYYVhGBWxsMIwjIqYOBiGURETB8MwKmLiYBhGRf4/NVX0p94cZ8kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 278.125x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "xHnKSMahIqI7",
        "outputId": "3e4b090a-f6e7-4e54-fca0-61da5989b8e6"
      },
      "source": [
        "sns.distplot(test[\"len_abstract\"], hist=True, rug=False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3792f3b590>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeZesLBHnfl5"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOdN4h2grTzx"
      },
      "source": [
        "if Config.validate:\n",
        "    api = wandb.Api()\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        try:\n",
        "            run.file(\"oof_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        oof = pd.read_csv(f\"{run_id}/oof_df.csv\")[[\"id\", \"preds\"]]\n",
        "        oof.columns = [\"id\", f\"preds{n}\"]\n",
        "        train = pd.merge(train, oof, on=\"id\")\n",
        "    \n",
        "    print(train.columns)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM2fDBrNi2_K"
      },
      "source": [
        "if Config.inference:\n",
        "    api = wandb.Api()\n",
        "    inference_models = []\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        inference_model = {}\n",
        "        inference_model[\"run_id\"] = run_id\n",
        "        inference_model[\"model_name\"] = run.config[\"model_name\"]\n",
        "\n",
        "        for fold in range(config.n_fold):\n",
        "            try:\n",
        "                run.file(f\"{inference_model['model_name'].replace('/', '-')}_fold{fold}_best.pth\").download(run_id)\n",
        "            except wandb.CommError:\n",
        "                # Already downloaded.\n",
        "                pass\n",
        "\n",
        "            model_preds = torch.load(f\"{run_id}/{inference_model['model_name'].replace('/', '-')}_fold{fold}_best.pth\")\n",
        "            inference_model[f\"state_fold{fold}\"] = model_preds[\"model\"]\n",
        "            inference_model[f\"preds_fold{fold}\"] = model_preds[\"preds\"]\n",
        "\n",
        "        inference_models.append(inference_model)\n",
        "    \n",
        "    print({m['run_id']: m['model_name'] for m in inference_models})"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXmpjcJxQhBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c602ca-dcd6-4392-efd6-50882a732e25"
      },
      "source": [
        "if Config.stack:\n",
        "    api = wandb.Api()\n",
        "\n",
        "    feat_id = 0\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        try:\n",
        "            run.file(\"validation_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            run.file(\"prediction_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        val = pd.read_csv(f\"{run_id}/validation_df.csv\")\n",
        "        pred = pd.read_csv(f\"{run_id}/prediction_df.csv\")\n",
        "\n",
        "        cols = [c for c in val.columns if c.startswith(\"preds\")]\n",
        "        val = val[[\"id\"] + cols]\n",
        "        pred = pred[[\"id\"] + cols]\n",
        "\n",
        "        adjust_cols = [\"id\"] + [f\"preds{n}\" for n in range(feat_id, feat_id + len(cols))]\n",
        "        val.columns = adjust_cols\n",
        "        pred.columns = adjust_cols\n",
        "\n",
        "        feat_id += len(cols)\n",
        "\n",
        "        train = pd.merge(train, val, on=\"id\")\n",
        "        test = pd.merge(test, pred, on=\"id\")\n",
        "    \n",
        "    print(f\"train: {train.columns}\")\n",
        "    print(f\"test: {test.columns}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: Index(['id', 'title', 'abstract', 'judgement', 'nan_abstract', 'len_title',\n",
            "       'len_abstract', 'title_abstract', 'abstract_title', 'preds0', 'preds1',\n",
            "       'preds2', 'preds3', 'preds4', 'preds5', 'preds6', 'preds7', 'preds8'],\n",
            "      dtype='object')\n",
            "test: Index(['id', 'title', 'abstract', 'len_title', 'len_abstract',\n",
            "       'title_abstract', 'abstract_title', 'preds0', 'preds1', 'preds2',\n",
            "       'preds3', 'preds4', 'preds5', 'preds6', 'preds7', 'preds8'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba31d893"
      },
      "source": [
        "if Config.debug and not Config.stack:\n",
        "    train = train.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    test = test.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    sub = sub.sample(n=1000, random_state=config.seed).reset_index(drop=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQ7fKQ2IC6i"
      },
      "source": [
        "## CV Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Lt-ZLtIHCG",
        "outputId": "00fe07c7-a193-40dc-e426-fbce251cfe50"
      },
      "source": [
        "Fold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train[[\"judgement\", \"nan_abstract\"]])):\n",
        "    train.loc[val_index, \"fold\"] = int(n)\n",
        "train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n",
        "print(train.groupby([\"fold\", \"judgement\", \"nan_abstract\"]).size())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold  judgement  nan_abstract\n",
            "0     0          0               4446\n",
            "                 1                857\n",
            "      1          0                105\n",
            "                 1                 21\n",
            "1     0          0               4448\n",
            "                 1                855\n",
            "      1          0                103\n",
            "                 1                 23\n",
            "2     0          0               4448\n",
            "                 1                855\n",
            "      1          0                103\n",
            "                 1                 23\n",
            "3     0          0               4448\n",
            "                 1                855\n",
            "      1          0                103\n",
            "                 1                 23\n",
            "4     0          0               4455\n",
            "                 1                848\n",
            "      1          0                 96\n",
            "                 1                 30\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d423ea8"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5985d91d"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=config.seed)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596efb85"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2721636"
      },
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, df, model_name, include_labels=True):\n",
        "        tokenizer = T.AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        self.df = df\n",
        "        self.include_labels = include_labels\n",
        "\n",
        "        self.title = df[config.input].tolist()\n",
        "        self.encoded = tokenizer.batch_encode_plus(\n",
        "            self.title,\n",
        "            padding = 'max_length',            \n",
        "            max_length = config.max_len,\n",
        "            truncation = True,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        \n",
        "        if self.include_labels:\n",
        "            self.labels = df[\"judgement\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = torch.tensor(self.encoded['input_ids'][idx])\n",
        "        attention_mask = torch.tensor(self.encoded['attention_mask'][idx])\n",
        "\n",
        "        if self.include_labels:\n",
        "            label = torch.tensor(self.labels[idx]).float()\n",
        "            return input_ids, attention_mask, label\n",
        "\n",
        "        return input_ids, attention_mask\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e56a1c49"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "\n",
        "    train_ds = BaseDataset(train, config.model_name)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_ids, attention_mask, label = train_ds[i]\n",
        "        print(input_ids)\n",
        "        print(attention_mask)\n",
        "        print(f\"label: {label}\")\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d681dabf"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Y5LnDCMPcC"
      },
      "source": [
        "### BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHPwf3JzPmjI"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    print(T.AutoConfig.from_pretrained(config.model_name))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "229d18e7"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "\n",
        "        if \"base\" in model_name or \"L-12\" in model_name or \"COVID-SciBERT\" in model_name:\n",
        "            out_dim = 768\n",
        "        elif \"large\" in model_name or \"L-24\" in model_name:\n",
        "            out_dim = 1024\n",
        "\n",
        "        auto_config = T.AutoConfig.from_pretrained(model_name)\n",
        "        auto_config.update({\n",
        "            \"output_hidden_states\": True,\n",
        "            \"hidden_dropout_prob\": config.dropout,\n",
        "            # \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "        \n",
        "        self.auto_model = T.AutoModel.from_pretrained(model_name, config=auto_config)  \n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(out_dim, 512),            \n",
        "            nn.Tanh(),                       \n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )        \n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(out_dim, 1)                        \n",
        "        )\n",
        "\n",
        "        if config.reinit_layers > 0:\n",
        "            self.re_init()\n",
        "\n",
        "        if config.freeze_layers > 0:\n",
        "            self.freeze()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.auto_model(input_ids=input_ids, attention_mask=attention_mask)        \n",
        "\n",
        "        # There are a total of 13 layers of hidden states.\n",
        "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
        "        # We take the hidden states from the last Roberta layer.\n",
        "        last_layer_hidden_states = bert_output.hidden_states[-1]\n",
        "\n",
        "        # The number of cells is config.max_len.\n",
        "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
        "        # In order to condense hidden states of all cells to a context vector,\n",
        "        # we compute a weighted average of the hidden states of all cells.\n",
        "        # We compute the weight of each cell, using the attention neural network.\n",
        "        weights = self.attention(last_layer_hidden_states)\n",
        "                \n",
        "        # weights.shape is config.batch_size x config.max_len x 1\n",
        "        # last_layer_hidden_states.shape is config.batch_size x config.max_len x 768        \n",
        "        # Now we compute context_vector as the weighted average.\n",
        "        # context_vector.shape is config.batch_size x 768\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
        "        \n",
        "        # Now we reduce the context vector to the prediction score.\n",
        "        out = self.regressor(context_vector).squeeze()\n",
        "\n",
        "        return out\n",
        "\n",
        "    def re_init(self):\n",
        "        # re-init pooler\n",
        "        self.auto_model.pooler.dense.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "        self.auto_model.pooler.dense.bias.data.zero_()\n",
        "        for p in self.auto_model.pooler.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        # re-init encoder\n",
        "        layers = self.auto_model.encoder.layer[-config.reinit_layers:]\n",
        "        for layer in layers:\n",
        "            for module in layer.modules():\n",
        "                if isinstance(module, nn.Linear):\n",
        "                    # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "                    # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.bias is not None:\n",
        "                        module.bias.data.zero_()\n",
        "                elif isinstance(module, nn.Embedding):\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.padding_idx is not None:\n",
        "                        module.weight.data[module.padding_idx].zero_()\n",
        "                elif isinstance(module, nn.LayerNorm):\n",
        "                    module.bias.data.zero_()\n",
        "                    module.weight.data.fill_(1.0)\n",
        "\n",
        "    def freeze(self):\n",
        "        # freeze embedding\n",
        "        for param in self.auto_model.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # freeze encoder\n",
        "        layers = self.auto_model.encoder.layer[:config.freeze_layers]\n",
        "        for layer in layers:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a3978b1"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "\n",
        "    model = BaseModel(config.model_name)\n",
        "    print(model)\n",
        "\n",
        "    train_dataset = BaseDataset(train, config.model_name)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "    for input_ids, attention_mask, labels in train_loader:\n",
        "        output = model(input_ids, attention_mask)\n",
        "        print(output)\n",
        "        break\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlpHUm-SrcLV"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
        "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYPJSbAxMTN7"
      },
      "source": [
        "### StackingModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am2WTaLaMVRQ"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PcTNCYuDeuC"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzoJMxr3DeVG"
      },
      "source": [
        "def bert_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "    \n",
        "    if \"albert-base\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:23]    \n",
        "        attention_parameters = named_parameters[25:29]\n",
        "        regressor_parameters = named_parameters[29:]\n",
        "        second_block = 999\n",
        "        third_block = 999\n",
        "\n",
        "    elif \"base\" in config.model_name or \"L-12\" in config.model_name or \"COVID-SciBERT\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:197]    \n",
        "        attention_parameters = named_parameters[199:203]\n",
        "        regressor_parameters = named_parameters[203:]\n",
        "        second_block = 69\n",
        "        third_block = 133\n",
        "\n",
        "    elif \"large\" in config.model_name or \"L-24\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:388]    \n",
        "        attention_parameters = named_parameters[391:395]\n",
        "        regressor_parameters = named_parameters[395:]\n",
        "        second_block = 133\n",
        "        third_block = 261\n",
        "        \n",
        "    attention_group = [params for (name, params) in attention_parameters]\n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": attention_group})\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(bert_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else config.weight_decay\n",
        "\n",
        "        lr = config.lr\n",
        "\n",
        "        if layer_num >= second_block:        \n",
        "            lr = config.lr_69\n",
        "\n",
        "        if layer_num >= third_block:\n",
        "            lr = config.lr_133\n",
        "\n",
        "        parameters.append({\"params\": params, \"weight_decay\": weight_decay, \"lr\": lr})\n",
        "\n",
        "    return T.AdamW(parameters)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de50761e"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47fcae06"
      },
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-7):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self, yhat, y):\n",
        "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
        "        return loss"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjpp5Rh-4jKW"
      },
      "source": [
        "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
        "class FBetaLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, beta=1.0, epsilon=1e-7):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
        "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
        "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "\n",
        "        beta_squared = self.beta ** 2\n",
        "        fbeta = (1 + beta_squared) * precision * recall / (beta_squared * precision + recall + self.epsilon)\n",
        "        fbeta = fbeta.clamp(min=self.epsilon, max=1-self.epsilon)\n",
        "        return 1 - fbeta.mean()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93661540"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19d9d03c"
      },
      "source": [
        "def get_score(y_true, y_pred, b=border):\n",
        "    y_pred = np.where(y_pred < b, 0, 1)\n",
        "    return fbeta_score(y_true, y_pred, beta=7.0)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1b92d4f"
      },
      "source": [
        "def get_result(result_df, fold=config.n_fold):\n",
        "    preds = result_df[\"preds\"].values\n",
        "    labels = result_df[\"judgement\"].values\n",
        "    score = get_score(labels, preds)\n",
        "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "    # wandb.log({\"fold\": fold, \"CV\": score})\n",
        "    if fold == config.n_fold:\n",
        "        wandb.run.summary[f\"CV\"] = score\n",
        "    else:\n",
        "        wandb.run.summary[f\"CV_fold{fold}\"] = score\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJUo-Mjlv_2"
      },
      "source": [
        "def determine_border(b, y_true, y_pred):\n",
        "    return -1 * get_score(y_true, y_pred, b)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf498df"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5b0e152"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNxJNSgwg-0E"
      },
      "source": [
        "def pre_train_fn():\n",
        "    tokenizer = T.AutoTokenizer.from_pretrained(config.model_name)\n",
        "    model = T.AutoModelForMaskedLM.from_pretrained(config.model_name)\n",
        "\n",
        "    tokenizer.save_pretrained(f\"./pretrained_{config.model_name}\")\n",
        "\n",
        "    train_dataset = T.LineByLineTextDataset(tokenizer=tokenizer, file_path=\"abstracts.txt\", block_size=512)\n",
        "    valid_dataset = T.LineByLineTextDataset(tokenizer=tokenizer, file_path=\"abstracts.txt\", block_size=512)\n",
        "\n",
        "    data_collator = T.DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        "    )\n",
        "\n",
        "    training_args = T.TrainingArguments(\n",
        "        output_dir = f\"./pretrained_{config.model_name}_chk\",\n",
        "        overwrite_output_dir = True,\n",
        "        num_train_epochs = 5,\n",
        "        per_device_train_batch_size = 4,\n",
        "        per_device_eval_batch_size = 4,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        evaluation_strategy = 'steps',\n",
        "        save_total_limit = 2,\n",
        "        eval_steps = 105,\n",
        "        save_steps = 105,\n",
        "        metric_for_best_model = 'eval_loss',\n",
        "        greater_is_better = False,\n",
        "        load_best_model_at_end = True,\n",
        "        prediction_loss_only = True,\n",
        "        report_to = \"wandb\",\n",
        "    )\n",
        "\n",
        "    trainer = T.Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=valid_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    trainer.save_model(f\"./pretrained_{config.model_name}\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99a3bfb5"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "        if Config.apex:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "\n",
        "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(scheduler, ReduceLROnPlateau):\n",
        "                scheduler.step(avg_val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "            \n",
        "            global_step += 1\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                # f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
        "                f\"LR: {scheduler.get_lr()[0]:.6f}  \"\n",
        "            )\n",
        "\n",
        "    return losses.avg"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "186c441d"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # record score\n",
        "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        preds.append(y_preds.to(\"cpu\").numpy())\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "            )\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7cdfc9"
      },
      "source": [
        "def inference():\n",
        "    predictions = sub.copy()\n",
        "\n",
        "    for n, model_item in enumerate(inference_models):\n",
        "        test_dataset = BaseDataset(test, model_item['model_name'], include_labels=False)\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True\n",
        "        )\n",
        "\n",
        "        preds = []\n",
        "        for fold in range(config.n_fold):\n",
        "            LOGGER.info(f\"========== ID: {model_item['run_id']} model: {model_item['model_name']} fold: {fold} inference ==========\")\n",
        "            model = BaseModel(model_item['model_name'])\n",
        "            model.to(device)\n",
        "            model.load_state_dict(model_item[f\"state_fold{fold}\"])\n",
        "            model.eval()\n",
        "            fold_preds = []\n",
        "            for i, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                with torch.no_grad():\n",
        "                    y_preds = model(input_ids, attention_mask)\n",
        "                # avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "                fold_preds.append(y_preds.to(\"cpu\").numpy())\n",
        "            preds.append(np.concatenate(fold_preds))\n",
        "\n",
        "        preds = np.mean(preds, axis=0)\n",
        "\n",
        "        if config.criterion == \"BCEWithLogitsLoss\":\n",
        "            preds = 1 / (1 + np.exp(-preds))\n",
        "\n",
        "        predictions[f\"preds{n}\"] = preds\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuZncamGqu8I"
      },
      "source": [
        "def stacking_inference():\n",
        "    feature_cols = [col for col in test.columns if col.startswith(\"preds\")]\n",
        "    predictions = sub.copy()\n",
        "\n",
        "    preds = []\n",
        "    for fold in range(config.n_fold):\n",
        "        LOGGER.info(f\"========== fold: {fold} inference ==========\")\n",
        "        bst = lgb.Booster(model_file=OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\")\n",
        "        fold_preds = bst.predict(test[feature_cols])\n",
        "        preds.append(fold_preds)\n",
        "\n",
        "    preds = np.mean(preds, axis=0)\n",
        "    predictions[f\"preds\"] = preds\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9663c1"
      },
      "source": [
        "## Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357969e6"
      },
      "source": [
        "def train_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BaseDataset(train_folds, config.model_name)\n",
        "    valid_dataset = BaseDataset(valid_folds, config.model_name)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Optimizer\n",
        "    # ====================================================\n",
        "    def get_optimizer(model):\n",
        "        if config.optimizer == \"Adam\":\n",
        "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay, amsgrad=False)\n",
        "        elif config.optimizer == \"AdamW\":\n",
        "            optimizer = T.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "        elif config.optimizer == \"BertAdamW\":\n",
        "            optimizer = bert_optimizer(model)\n",
        "        return optimizer\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        if config.scheduler == \"ReduceLROnPlateau\":\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=config.factor, patience=config.patience, verbose=True, eps=config.eps\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=config.T_max, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(\n",
        "                optimizer, T_0=config.T_0, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
        "            scheduler = CosineAnnealingWarmupRestarts(\n",
        "                optimizer, first_cycle_steps=config.first_cycle_steps, max_lr=config.lr, min_lr=config.min_lr, warmup_steps=config.warmup_steps\n",
        "            )\n",
        "        elif config.scheduler == \"get_cosine_schedule_with_warmup\":\n",
        "            scheduler = T.get_cosine_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_training_steps=config.num_training_steps, \n",
        "                num_warmup_steps=config.num_warmup_steps\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # Model\n",
        "    # ====================================================\n",
        "    model = BaseModel(config.model_name)\n",
        "    model.to(device)\n",
        "\n",
        "    # Use multi GPU\n",
        "    if device == torch.device(\"cuda\") and not Config.apex and Config.multi_gpu:\n",
        "        model = torch.nn.DataParallel(model)  # make parallel\n",
        "        # torch.backends.cudnn.benchmark=True\n",
        "\n",
        "    optimizer = get_optimizer(model)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # Apex\n",
        "    # ====================================================\n",
        "    if Config.apex:\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "        elif config.criterion == \"MSELoss\":\n",
        "            criterion = nn.MSELoss()\n",
        "        elif config.criterion == \"RMSELoss\":\n",
        "            criterion = RMSELoss()\n",
        "        elif config.criterion == \"FBetaLoss\":\n",
        "            criterion = FBetaLoss(7.0)\n",
        "\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "    best_score = -1\n",
        "    best_loss = np.inf\n",
        "\n",
        "    # if not Config.multi_gpu:\n",
        "    #     wandb.watch(model, log_freq=Config.print_freq)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
        "        valid_labels = valid_folds[\"judgement\"].values\n",
        "\n",
        "        # if isinstance(scheduler, ReduceLROnPlateau):\n",
        "        #     scheduler.step(avg_val_loss)\n",
        "        # else:\n",
        "        #     scheduler.step()\n",
        "\n",
        "        if config.criterion == \"BCEWithLogitsLoss\":\n",
        "            preds = 1 / (1 + np.exp(-preds))\n",
        "\n",
        "        # scoring\n",
        "        # score = get_score(valid_labels, preds.argmax(1))\n",
        "        score = get_score(valid_labels, preds)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(\n",
        "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
        "        )\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
        "\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                f\"loss/train_fold{fold}\": avg_loss,\n",
        "                f\"loss/val_fold{fold}\": avg_val_loss,\n",
        "                f\"score/fold{fold}\": score,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if (\n",
        "            (config.best == \"score\" and score > best_score)\n",
        "            or (config.best == \"loss\" and avg_val_loss < best_loss)\n",
        "        ):\n",
        "            best_score = score\n",
        "            best_loss = avg_val_loss\n",
        "\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model (Loss: {best_loss:.4f})\")\n",
        "            wandb.run.summary[f\"loss_fold{fold}\"] = score\n",
        "\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\"\n",
        "            )\n",
        "            wandb.save(OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "        # if epoch == config.epochs - 1:\n",
        "        #     LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
        "        #     torch.save(\n",
        "        #         {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name}_fold{fold}_final.pth\"\n",
        "        #     )\n",
        "\n",
        "    check_point = torch.load(OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "    valid_folds[[str(c) for c in range(config.n_class)]] = check_point[\"preds\"]\n",
        "    valid_folds[\"preds\"] = check_point[\"preds\"]  # .argmax(1)\n",
        "\n",
        "    return valid_folds"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8mXDD4u0G3R"
      },
      "source": [
        "## Stack loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VejK7F2hzIsK"
      },
      "source": [
        "def stack_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # ====================================================\n",
        "    # Dataset\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    feature_cols = [col for col in df.columns if col.startswith(\"preds\")]\n",
        "    label_cols = [\"judgement\"]\n",
        "\n",
        "    train_dataset = lgb.Dataset(data=train_folds[feature_cols], label=train_folds[label_cols], free_raw_data=False)\n",
        "    valid_dataset = lgb.Dataset(data=valid_folds[feature_cols], label=valid_folds[label_cols], free_raw_data=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # Parameters\n",
        "    # ====================================================\n",
        "\n",
        "    lgb_params = {\n",
        "        \"objective\": config.objective,\n",
        "        \"metric\": config.criterion,\n",
        "        \"learning_rate\": config.lr,\n",
        "        \"max_depth\": config.max_depth,\n",
        "        \"num_leaves\": config.num_leaves,\n",
        "        \"min_data_in_leaf\": config.min_data_in_leaf,\n",
        "        \"drop_rate\": config.dropout,\n",
        "        \"device_type\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "        \"seed\": seed + fold,\n",
        "    }\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "    evaluation_results = {}\n",
        "\n",
        "    clf = lgb.train(\n",
        "        params=lgb_params,\n",
        "        train_set=train_dataset,\n",
        "        num_boost_round=10000,\n",
        "        valid_sets=[train_dataset, valid_dataset], \n",
        "        valid_names=['train', 'eval'],\n",
        "        early_stopping_rounds=100,\n",
        "        evals_result=evaluation_results,\n",
        "        verbose_eval=100,\n",
        "    )\n",
        "\n",
        "    importances = pd.DataFrame({\n",
        "        'features': clf.feature_name(),\n",
        "        'importance': clf.feature_importance()\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    preds = clf.predict(valid_folds[feature_cols], num_iteration=clf.best_iteration)\n",
        "    valid_labels = valid_folds[\"judgement\"].values\n",
        "\n",
        "    # scoring\n",
        "    # score = get_score(valid_labels, preds.argmax(1))\n",
        "    score = get_score(valid_labels, preds)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    LOGGER.info(f\"Result {fold} - Score: {score}, time: {elapsed:.0f}s\")\n",
        "\n",
        "    LOGGER.info(f\"Result {fold} - Save Best Model\")\n",
        "    # wandb.run.summary[f\"loss_fold{fold}\"] = score\n",
        "\n",
        "    clf.save_model(OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\", clf.best_iteration)\n",
        "    wandb.save(OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\")\n",
        "\n",
        "    #valid_folds[[str(c) for c in range(config.n_class)]] = preds\n",
        "    valid_folds[\"preds\"] = preds  # .argmax(1)\n",
        "\n",
        "    return valid_folds"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97b42fa3"
      },
      "source": [
        "## Main\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5baf150d"
      },
      "source": [
        "def main():\n",
        "    if Config.pre_train:\n",
        "        abstract_df = pd.concat([train[\"abstract\"], test[\"abstract\"]])\n",
        "        abstracts  = '\\n'.join(abstract_df.tolist())\n",
        "        with open(\"abstracts.txt\", \"w\") as f:\n",
        "            f.write(abstracts)\n",
        "\n",
        "        pre_train_fn()\n",
        "\n",
        "    if Config.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df = train_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "            \n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        \n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
        "\n",
        "    if Config.validate:\n",
        "        probs = []\n",
        "        for n in range(len(config.inference_runs)):\n",
        "            probs.append(train[f\"preds{n}\"].values)\n",
        "        preds = np.mean(probs, axis=0)\n",
        "        train[\"predictions\"] = preds\n",
        "\n",
        "        # Post process\n",
        "        if config.border == \"minimize\":\n",
        "            res = sp.optimize.minimize_scalar(determine_border, method='bounded', bounds=(0, 1), args=(train[\"judgement\"].values, preds))\n",
        "            LOGGER.info(f\"========== Border Optimization ==========\")\n",
        "            LOGGER.info(f\"Border: {res.x:<.5f}, Score: {-res.fun:<.5f}\")\n",
        "            wandb.run.summary[f\"CV\"] = -res.fun\n",
        "\n",
        "        elif config.border == \"fixed\":\n",
        "            # CV result\n",
        "            LOGGER.info(f\"========== CV ==========\")\n",
        "            get_result(train)\n",
        "\n",
        "        # save result\n",
        "        train.to_csv(OUTPUT_DIR + \"validation_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"validation_df.csv\")\n",
        "\n",
        "    if Config.inference:\n",
        "        prediction_df = inference()\n",
        "\n",
        "        probs = []\n",
        "        for n in range(len(config.inference_runs)):\n",
        "            probs.append(prediction_df[f\"preds{n}\"].values)\n",
        "        preds = np.mean(probs, axis=0)\n",
        "        prediction_df[\"predictions\"] = preds\n",
        "\n",
        "        # Post process\n",
        "        try:\n",
        "            b = res.x\n",
        "        except Exception:\n",
        "            b = border\n",
        "        wandb.run.summary[f\"border\"] = b\n",
        "\n",
        "        predictions = np.where(preds < b, 0, 1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = predictions  # .argmax(1)\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n",
        "\n",
        "        prediction_df.to_csv(OUTPUT_DIR + \"prediction_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"prediction_df.csv\")\n",
        "        \n",
        "    if Config.stack:\n",
        "        # Training\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df = stack_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "\n",
        "        # CV result\n",
        "        if config.border == \"minimize\":\n",
        "            res = sp.optimize.minimize_scalar(determine_border, method='bounded', bounds=(0, 1), args=(oof_df[\"judgement\"].values, oof_df[\"preds\"].values))\n",
        "            LOGGER.info(f\"========== CV: Border Optimization ==========\")\n",
        "            LOGGER.info(f\"Border: {res.x:<.5f}, Score: {-res.fun:<.5f}\")\n",
        "            wandb.run.summary[f\"CV\"] = -res.fun\n",
        "            b = res.x\n",
        "\n",
        "        elif config.border == \"fixed\":\n",
        "            # CV result\n",
        "            LOGGER.info(f\"========== CV ==========\")\n",
        "            get_result(oof_df)\n",
        "            b = border\n",
        "        \n",
        "        wandb.run.summary[f\"border\"] = b\n",
        "\n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"stacking_oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"stacking_oof_df.csv\")\n",
        "\n",
        "        # Inference\n",
        "        prediction_df = stacking_inference()\n",
        "\n",
        "        predictions = np.where(prediction_df[\"preds\"].values < b, 0, 1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = predictions  # .argmax(1)\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n",
        "\n",
        "        prediction_df.to_csv(OUTPUT_DIR + \"stacking_prediction_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"stacking_prediction_df.csv\")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "726e744f",
        "outputId": "446dcc19-6733-43cf-b5de-96cf493d7193"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 0 training ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 504, number of negative: 21212\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 21716, number of used features: 9\n",
            "[LightGBM] [Info] Using GPU Device: Tesla V100-SXM2-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 9 dense feature groups (0.25 MB) transferred to GPU in 0.000956 secs. 0 sparse feature groups\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023209 -> initscore=-3.739746\n",
            "[LightGBM] [Info] Start training from score -3.739746\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's binary_logloss: 0.0359665\teval's binary_logloss: 0.0467455\n",
            "[200]\ttrain's binary_logloss: 0.0250186\teval's binary_logloss: 0.0400768\n",
            "[300]\ttrain's binary_logloss: 0.0211137\teval's binary_logloss: 0.0387549\n",
            "[400]\ttrain's binary_logloss: 0.0194072\teval's binary_logloss: 0.0387826\n",
            "Early stopping, best iteration is:\n",
            "[347]\ttrain's binary_logloss: 0.0201416\teval's binary_logloss: 0.0386433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Result 0 - Score: 0.8816314014106102, time: 2s\n",
            "Result 0 - Save Best Model\n",
            "========== fold: 0 result ==========\n",
            "Score: 0.88163\n",
            "========== fold: 1 training ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 504, number of negative: 21212\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 21716, number of used features: 9\n",
            "[LightGBM] [Info] Using GPU Device: Tesla V100-SXM2-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 9 dense feature groups (0.25 MB) transferred to GPU in 0.000934 secs. 0 sparse feature groups\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023209 -> initscore=-3.739746\n",
            "[LightGBM] [Info] Start training from score -3.739746\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's binary_logloss: 0.0360204\teval's binary_logloss: 0.0447108\n",
            "[200]\ttrain's binary_logloss: 0.0248421\teval's binary_logloss: 0.0373068\n",
            "[300]\ttrain's binary_logloss: 0.0206267\teval's binary_logloss: 0.0354462\n",
            "[400]\ttrain's binary_logloss: 0.0189666\teval's binary_logloss: 0.0350439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Result 1 - Score: 0.9160305343511449, time: 2s\n",
            "Result 1 - Save Best Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[500]\ttrain's binary_logloss: 0.0180781\teval's binary_logloss: 0.035061\n",
            "Early stopping, best iteration is:\n",
            "[428]\ttrain's binary_logloss: 0.0186838\teval's binary_logloss: 0.0350036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 1 result ==========\n",
            "Score: 0.91603\n",
            "========== fold: 2 training ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 504, number of negative: 21212\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 21716, number of used features: 9\n",
            "[LightGBM] [Info] Using GPU Device: Tesla V100-SXM2-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 9 dense feature groups (0.25 MB) transferred to GPU in 0.000965 secs. 0 sparse feature groups\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023209 -> initscore=-3.739746\n",
            "[LightGBM] [Info] Start training from score -3.739746\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's binary_logloss: 0.0368955\teval's binary_logloss: 0.0416323\n",
            "[200]\ttrain's binary_logloss: 0.025837\teval's binary_logloss: 0.0340531\n",
            "[300]\ttrain's binary_logloss: 0.0216289\teval's binary_logloss: 0.0323447\n",
            "[400]\ttrain's binary_logloss: 0.0196254\teval's binary_logloss: 0.0322503\n",
            "Early stopping, best iteration is:\n",
            "[354]\ttrain's binary_logloss: 0.0202917\teval's binary_logloss: 0.0321724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Result 2 - Score: 0.9153846153846155, time: 2s\n",
            "Result 2 - Save Best Model\n",
            "========== fold: 2 result ==========\n",
            "Score: 0.91538\n",
            "========== fold: 3 training ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 504, number of negative: 21212\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 21716, number of used features: 9\n",
            "[LightGBM] [Info] Using GPU Device: Tesla V100-SXM2-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 9 dense feature groups (0.25 MB) transferred to GPU in 0.001008 secs. 0 sparse feature groups\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023209 -> initscore=-3.739746\n",
            "[LightGBM] [Info] Start training from score -3.739746\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's binary_logloss: 0.0361485\teval's binary_logloss: 0.0449434\n",
            "[200]\ttrain's binary_logloss: 0.0248225\teval's binary_logloss: 0.0376666\n",
            "[300]\ttrain's binary_logloss: 0.0204271\teval's binary_logloss: 0.0354858\n",
            "[400]\ttrain's binary_logloss: 0.0188312\teval's binary_logloss: 0.0349105\n",
            "[500]\ttrain's binary_logloss: 0.0178896\teval's binary_logloss: 0.034839\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Result 3 - Score: 0.9111791730474732, time: 2s\n",
            "Result 3 - Save Best Model\n",
            "========== fold: 3 result ==========\n",
            "Score: 0.91118\n",
            "========== fold: 4 training ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Early stopping, best iteration is:\n",
            "[491]\ttrain's binary_logloss: 0.0179763\teval's binary_logloss: 0.0348012\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 504, number of negative: 21212\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 21716, number of used features: 9\n",
            "[LightGBM] [Info] Using GPU Device: Tesla V100-SXM2-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 9 dense feature groups (0.25 MB) transferred to GPU in 0.000969 secs. 0 sparse feature groups\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023209 -> initscore=-3.739746\n",
            "[LightGBM] [Info] Start training from score -3.739746\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's binary_logloss: 0.035982\teval's binary_logloss: 0.047598\n",
            "[200]\ttrain's binary_logloss: 0.0249817\teval's binary_logloss: 0.0398989\n",
            "[300]\ttrain's binary_logloss: 0.0212124\teval's binary_logloss: 0.0379417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Result 4 - Score: 0.9038936959208901, time: 2s\n",
            "Result 4 - Save Best Model\n",
            "========== fold: 4 result ==========\n",
            "Score: 0.90389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[400]\ttrain's binary_logloss: 0.0194327\teval's binary_logloss: 0.0378843\n",
            "Early stopping, best iteration is:\n",
            "[322]\ttrain's binary_logloss: 0.0207034\teval's binary_logloss: 0.0378553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== CV: Border Optimization ==========\n",
            "Border: 0.01843, Score: 0.90695\n",
            "========== fold: 0 inference ==========\n",
            "========== fold: 1 inference ==========\n",
            "========== fold: 2 inference ==========\n",
            "========== fold: 3 inference ==========\n",
            "========== fold: 4 inference ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    38244\n",
            "1     2590\n",
            "Name: judgement, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPHezhr_NHYR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "02e04db7c976491a9b25182b636b4bac",
            "1111e6380541486aa7b4b873b56a6858",
            "34de02bfb1af4ae3ab7c0825ea793cd0",
            "054bc836df0b415fadcaf40ea1171aba",
            "eee5f27b4f8e4efeba68db7e0351cb3b",
            "931938bcb7a046239b962c44e3e71eaf",
            "fc38d965eb4c41a7941312df061662db",
            "ff48cef5fc5342a19e65310449984b25"
          ]
        },
        "outputId": "d128ad3f-642d-4316-9375-8fffd6679935"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2931<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02e04db7c976491a9b25182b636b4bac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 124.09MB of 124.09MB uploaded (0.17MB deduped)\\r'), FloatProgress(value=1.0, max=…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210902_113007-3iay1r3l/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210902_113007-3iay1r3l/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>CV_fold0</td><td>0.88163</td></tr><tr><td>CV_fold1</td><td>0.91603</td></tr><tr><td>CV_fold2</td><td>0.91538</td></tr><tr><td>CV_fold3</td><td>0.91118</td></tr><tr><td>CV_fold4</td><td>0.90389</td></tr><tr><td>CV</td><td>0.90695</td></tr><tr><td>border</td><td>0.01843</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 48 artifact file(s) and 9 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">lemon-dream-62</strong>: <a href=\"https://wandb.ai/ponkots/signate-471/runs/3iay1r3l\" target=\"_blank\">https://wandb.ai/ponkots/signate-471/runs/3iay1r3l</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-scfhV4ueW4K"
      },
      "source": [
        "## Public LB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNsH2CvA1He"
      },
      "source": [
        "RUN_PATH = \"\"\n",
        "LB_SCORE = None"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS7aRYF_eh7z"
      },
      "source": [
        "if LB_SCORE is not None:\n",
        "    import wandb\n",
        "    api = wandb.Api()\n",
        "\n",
        "    run = api.run(RUN_PATH)\n",
        "    run.summary[\"LB\"] = LB_SCORE\n",
        "    run.summary.update()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANpuUeypNmLF"
      },
      "source": [
        ""
      ],
      "execution_count": 72,
      "outputs": []
    }
  ]
}