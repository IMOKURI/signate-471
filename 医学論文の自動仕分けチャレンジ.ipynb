{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "医学論文の自動仕分けチャレンジ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43e865fc6c3146399251db6e4fbf78bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3da8586149994392ae99542643573d39",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_243d167efa3541cdbd46478ec4a3a796",
              "IPY_MODEL_e340bccf48dc425cb99999bf48352a9c"
            ]
          }
        },
        "3da8586149994392ae99542643573d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "243d167efa3541cdbd46478ec4a3a796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_20d61c909cc04aa883e5792c2d5faf3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 113.04MB of 113.04MB uploaded (0.18MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb69290873404305a9c3c8f3fc1cef65"
          }
        },
        "e340bccf48dc425cb99999bf48352a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f0a9cb69c594f5ba3eac74efb6c2f0c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6722884bac74a6d881962f27bcc2f9a"
          }
        },
        "20d61c909cc04aa883e5792c2d5faf3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb69290873404305a9c3c8f3fc1cef65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f0a9cb69c594f5ba3eac74efb6c2f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6722884bac74a6d881962f27bcc2f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/signate-471/blob/main/%E5%8C%BB%E5%AD%A6%E8%AB%96%E6%96%87%E3%81%AE%E8%87%AA%E5%8B%95%E4%BB%95%E5%88%86%E3%81%91%E3%83%81%E3%83%A3%E3%83%AC%E3%83%B3%E3%82%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e4660c1"
      },
      "source": [
        "# About this notebook ...\n",
        "\n",
        "competition site: https://signate.jp/competitions/471\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dhs2SIWJzKz"
      },
      "source": [
        "## ToDo\n",
        "\n",
        "- [ ] pre train のモデルの save と load\n",
        "- [ ] preprocess したデータの save と load (wandb)\n",
        "- [ ] optuna の seed 固定 https://book-read-yoshi.hatenablog.com/entry/2021/03/22/lightgbm_optuna_deterministic\n",
        "\n",
        "### Idea\n",
        "\n",
        "- [x] [ラベル判定結果の誤りに関するお知らせ](https://signate.jp/competitions/471/discussions/20210816152356-59) をとりこむ \n",
        "- [x] 分類で推論、回帰で推論\n",
        "- [x] 回帰の場合の境界値の最適化\n",
        "    - [x] second stage で学習べきかも\n",
        "        - [ ] heamy という stacking のライブラリがある\n",
        "        - [ ] CNN で stacking がいいかもしれない https://tawara.hatenablog.com/entry/2020/12/16/132415\n",
        "            - 縦・横、チャネル数が、クラス数（１）・モデル数（ｎ）・１で、 1xn で畳み込む \n",
        "        - [x] lightGBM\n",
        "    - [x] Nelder-Mead 法 という最適化手法を調べる\n",
        "- [x] 最適な境界値はモデルによって異なるので、アンサンブルの時は、 vote ensemble がいいかもしれない\n",
        "- [x] アブストで事前学習して、タイトルでメイン学習 https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n",
        "    - 事前学習は、Masked LM\n",
        "- [x] タイトルだけで学習・推論\n",
        "- [x] タイトル + アブストで学習・推論\n",
        "    - [ ] タイトルだけで推論したのとアンサンブルができる\n",
        "    - [ ] Longformer がいいかもしれない `allenai/longformer-base-4096`\n",
        "    - [x] large モデルためす\n",
        "- [ ] アブスト + タイトル で学習・推論\n",
        "- [ ] アブストが空 or not でモデルわける\n",
        "- [ ] アブストの max length 調整\n",
        "    - [ ] 途中で切る。デフォルトの 512 はありそう。ほとんどのアブストがその長さで収まる\n",
        "    - [ ] 要約する方法があるかなぁ\n",
        "- [x] dropout を 0 にする\n",
        "- [x] gradient cripping を 0.2 or 0.5 で試す\n",
        "- [ ] re-initialization\n",
        "    - This paper (https://arxiv.org/pdf/2006.05987.pdf) shows that fine-tuning with reinitialization last N layers works well.\n",
        "    - Different models have different optimal N. Almost models set N=4~5, gpt2-models set N=6.\n",
        "    - https://github.com/kurupical/commonlit/blob/8781139c8ed4cc59f7c7ac9d97c72c351ee91377/exp/exp502.py#L497\n",
        "- [ ] Pre trained なレイヤーのfreeze https://raphaelb.org/posts/freezing-bert/\n",
        "    - データ数が 数百 しかないような環境での話かな。\n",
        "- [ ] Recall を伸ばすための loss function は考えられるか。 https://openreview.net/pdf?id=SlprFTIQP3\n",
        "    - [x] f1 score を微分可能にして、 loss 関数に使うアプローチ https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354 https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d\n",
        "    - [ ] epoch ごとに beta の値を増やしていく epoch * 2 とか\n",
        "- [ ] 出現する単語のクラスタリング\n",
        "- [x] TF-IDF して、 リッジ回帰 → ベースライン2 でやった\n",
        "    - IF-IDF の結果もBERTの特徴量にできないだろうか\n",
        "    - https://www.kaggle.com/semyonkoshkarov/tf-idf-linearsvr-baseline も参考になるかも\n",
        "- [ ] 医療用語で事前学習されたモデルを使ってみる\n",
        "    - [x] BioBERT https://github.com/dmis-lab/biobert `dmis-lab/biobert-base-cased-v1.1` 286k downloads\n",
        "        - [ ] large モデル試す\n",
        "    - [ ] Med-BERT https://github.com/ZhiGroup/Med-BERT\n",
        "        - 診断精度に貢献しているかもしれない(いや、一般的な話だったｗ) https://www.nature.com/articles/s41746-021-00455-y\n",
        "    - [x] `microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext` 30.8k downloads https://www.axion.zone/microsoft-researchers-claim-state-of-the-art-biomedical-nlp-model/\n",
        "    - [x] `bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12` 4.3k downloads https://github.com/ncbi-nlp/bluebert\n",
        "        - [ ] large モデル試す\n",
        "    - [x] `emilyalsentzer/Bio_ClinicalBERT` https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n",
        "    - [ ] `emilyalsentzer/Bio_Discharge_Summary_BERT` https://huggingface.co/emilyalsentzer/Bio_Discharge_Summary_BERT\n",
        "    - [x] `lordtt13/COVID-SciBERT` https://huggingface.co/lordtt13/COVID-SciBERT\n",
        "    - [x] `allenai/scibert_scivocab_uncased` https://huggingface.co/allenai/scibert_scivocab_uncased\n",
        "- [ ] Augmentation https://neptune.ai/blog/data-augmentation-nlp\n",
        "    - [ ] Back translation: 他言語に翻訳して、もう一回翻訳する（英語→フランス語→英語） https://qiita.com/nena0undefined/items/c2926bad07039e5540ab\n",
        "        - [ ] ラベル 1 のだけやって、学習データに追加する\n",
        "    - [ ] Synonym Replacement: 単語のいくつかを、同じ意味の別の単語に置き換える\n",
        "        - [x] 自然言語の augmentation ができるライブラリ https://github.com/makcedward/nlpaug\n",
        "- [ ] TTA\n",
        "- [ ] ベースラインのシンプルさを取り戻す。(思ったよりベースラインのスコアが良かったので、それを取り込む・・・）\n",
        "    - [ ] weight decay を調整 0.01 or 0\n",
        "\n",
        "\n",
        "### Experiments\n",
        "\n",
        "- BERT でアブストの　pre train をしてもスコアは上がっていない（学習の方法を工夫した方がよいかも）\n",
        "- BERT Large は title の学習には大きすぎて？ loss が Base モデルに及ばない。\n",
        "- epoch 3 で val loss が下がらないので、 epoch 3 で aug かけるとかありかもしれない\n",
        "- `dmis-lab/biobert-base-cased-v1.1` と `bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12` の成績がよい\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68842c71"
      },
      "source": [
        "## Prepare for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14137a0f",
        "outputId": "0dfffe69-eba8-493e-9a0c-2ce17ba18990"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep  7 01:11:38 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4871daf1",
        "outputId": "5f530525-e444-4d6c-bcc1-ca2485d4a816"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if os.path.exists('init.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    if 'google.colab' in sys.modules:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        !cp /content/drive/MyDrive/Datasets/signate-471/train.csv .\n",
        "        !cp /content/drive/MyDrive/Datasets/signate-471/test.csv .\n",
        "        !cp /content/drive/MyDrive/Datasets/signate-471/sample_submit.csv .\n",
        "\n",
        "    # for StratifiedGroupKFold\n",
        "    # !pip uninstall -y scikit-learn\n",
        "    # !pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn\n",
        "\n",
        "    # for MultilabelStratifiedKFold\n",
        "    !pip install -q iterative-stratification\n",
        "\n",
        "    # !pip install -qU 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n",
        "\n",
        "    !pip install -q wandb\n",
        "    !pip install -q optuna\n",
        "\n",
        "    !pip install -q transformers\n",
        "    !pip install -q textstat\n",
        "    !pip install -q nlpaug\n",
        "\n",
        "    # https://qiita.com/_yushuu/items/83c51e29771530646659\n",
        "    # !pip install -q googletrans==4.0.0-rc1\n",
        "\n",
        "    !touch init.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkZ4bEVgUxxa",
        "outputId": "c9782cb1-b7b0-419f-eda7-cd58087914eb"
      },
      "source": [
        "# Install_LightGBM_with_GPU\n",
        "\n",
        "if os.path.exists('init_lightgbm.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    ! git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "\n",
        "    %cd /content/LightGBM\n",
        "    ! mkdir -p build\n",
        "\n",
        "    %cd build\n",
        "    ! cmake -DUSE_GPU=1 /content/LightGBM\n",
        "    ! make -j$(nproc)\n",
        "    ! sudo apt-get -y install python-pip\n",
        "    ! sudo -H pip install setuptools numpy scipy scikit-learn -U\n",
        "    ! sudo -H pip install pandas==1.3.0\n",
        "\n",
        "    %cd /content/LightGBM/python-package\n",
        "    ! sudo python setup.py install --precompile\n",
        "\n",
        "    %cd /content/\n",
        "\n",
        "    !touch init_lightgbm.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c39b7222"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63096cb"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# import lightgbm as lgb\n",
        "# import optuna.integration.lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "import textstat\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers as T\n",
        "import wandb\n",
        "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
        "# from googletrans import Translator\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, fbeta_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold  # , StratifiedGroupKFold\n",
        "from torch.optim import SGD, Adam  # , AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c830faec"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16eb8ed5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cZeQJ7Xw7d8",
        "outputId": "7589ed6c-ba33-4eba-fb4d-efd3b1838afe"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc53e8c",
        "outputId": "0a889988-ed45-4e04-df2c-be8133fdafb8"
      },
      "source": [
        "netrc = \"../input/wandbtoken/.netrc\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    netrc = \"/content/drive/MyDrive/.netrc\"\n",
        "\n",
        "!cp -f {netrc} ~/\n",
        "\n",
        "!wandb login"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB5QkUQJq_6U"
      },
      "source": [
        "wandb_job_type = \"\"\n",
        "wandb_notes = \"\"\n",
        "wandb_tags = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71d9ccbd"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a62a05f"
      },
      "source": [
        "DATA_DIR = \"../input/signate-471/\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_DIR = \"./\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26350797"
      },
      "source": [
        "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
        "sub = pd.read_csv(DATA_DIR + \"sample_submit.csv\", header=None)\n",
        "sub.columns = [\"id\", \"judgement\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7ef06f8"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0177571"
      },
      "source": [
        "class Config:\n",
        "    wandb_entity = \"ponkots\"\n",
        "    wandb_project = \"signate-471\"\n",
        "    print_freq = 100\n",
        "\n",
        "    pre_train = False\n",
        "    train = False\n",
        "    validate = False\n",
        "    inference = False\n",
        "    stack = False\n",
        "    stack_optuna = False\n",
        "    ensemble = True\n",
        "\n",
        "    debug = False\n",
        "    multi_gpu = False\n",
        "    apex = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxS_DM-WpMv8"
      },
      "source": [
        "if Config.stack_optuna:\n",
        "    import optuna.integration.lightgbm as lgb\n",
        "else:\n",
        "    import lightgbm as lgb"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a195fe0"
      },
      "source": [
        "if Config.pre_train:\n",
        "    wandb_job_type = \"pre_training\"\n",
        "\n",
        "elif Config.train:\n",
        "    wandb_job_type = \"training\"\n",
        "\n",
        "elif Config.inference:\n",
        "    wandb_job_type = \"inference\"\n",
        "\n",
        "elif Config.validate:\n",
        "    wandb_job_type = \"validation\"\n",
        "\n",
        "elif Config.stack:\n",
        "    wandb_job_type = \"stacking\"\n",
        "\n",
        "elif Config.ensemble:\n",
        "    wandb_job_type = \"ensemble\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccb61787"
      },
      "source": [
        "if Config.apex:\n",
        "    from apex import amp"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWDHvHvNxoD3",
        "outputId": "4d8dc1a4-f929-468d-8aa6-700a0c2a8c10"
      },
      "source": [
        "# seed = random.randrange(10000)\n",
        "seed = 440\n",
        "\n",
        "print(seed)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daf057a9"
      },
      "source": [
        "config_defaults = {\n",
        "    \"seed\": seed,\n",
        "    \"input\": \"title_abstract\",\n",
        "    \"max_len\": 512,\n",
        "    \"border\": \"minimize\",\n",
        "    \"n_class\": 1,\n",
        "    \"n_fold\": 5,\n",
        "    \"gradient_accumulation_steps\": 2,\n",
        "    \"max_grad_norm\": 1000,\n",
        "    \"num_workers\": 4,\n",
        "    \"batch_size\": 12,\n",
        "    \"epochs\": 3,\n",
        "    \"optimizer\": \"BertAdamW\",\n",
        "    \"scheduler\": \"get_cosine_schedule_with_warmup\",\n",
        "    \"criterion\": \"BCEWithLogitsLoss\",  # \"FBetaLoss\",  # \"BCEWithLogitsLoss\",\n",
        "    \"lr\": 2e-5,\n",
        "    \"min_lr\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"dropout\": 0.1,\n",
        "    \"model_name\": \"dmis-lab/biobert-base-cased-v1.1-squad\",\n",
        "    \"reinit_layers\": 0,\n",
        "    \"freeze_layers\": 0,\n",
        "    \"best\": \"loss\",  # \"score\",\n",
        "    \"inference_runs\": [\n",
        "        \"3rnktuhs\",  # 3\n",
        "        \"pnhvuu65\",  # 1 (21al58cv は除外する)\n",
        "        \"1zwt0m0n\",  # 1\n",
        "        \"38pysxqh\",  # 1\n",
        "        \"asrbkkjc\",  # 1\n",
        "    ],\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFOA0aiExa5R"
      },
      "source": [
        "if Config.stack:\n",
        "    config_stack = {\n",
        "        \"objective\": \"binary\" if config_defaults[\"n_class\"] == 1 else \"multiclass\",\n",
        "        \"criterion\": \"binary_logloss\" if config_defaults[\"n_class\"] == 1 else \"multi_logloss\",\n",
        "    }\n",
        "    config_defaults.update(config_stack)\n",
        "\n",
        "    if not Config.stack_optuna:\n",
        "        config_stack_manual = {\n",
        "            \"lr\": 0.01,\n",
        "            \"max_depth\": 7,\n",
        "            \"num_leaves\": 31,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"dropout\": 0.1,\n",
        "        }\n",
        "        config_defaults.update(config_stack_manual)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUQbknvvbZR5"
      },
      "source": [
        "if not (Config.validate or Config.inference or Config.stack or Config.ensemble):\n",
        "    config_defaults[\"inference_runs\"] = []"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd440361"
      },
      "source": [
        "if Config.debug:\n",
        "    config_defaults[\"epochs\"] = 1\n",
        "    Config.print_freq = 10"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgjHEBuwETmp"
      },
      "source": [
        "if config_defaults[\"optimizer\"] == \"BertAdamW\":\n",
        "    config_defaults[\"lr_69\"] = 5e-5\n",
        "    config_defaults[\"lr_133\"] = 1e-4"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a710ed",
        "outputId": "7ac3a505-82f8-43b7-b9f1-2bcd813dcd6a"
      },
      "source": [
        "# Update by epoch\n",
        "# num_steps = config_defaults[\"epochs\"]\n",
        "\n",
        "# Update by batch\n",
        "num_data = 1000 if Config.debug else len(train)\n",
        "num_steps = num_data // config_defaults[\"n_fold\"] * (config_defaults[\"n_fold\"] - 1) // config_defaults[\"batch_size\"] // config_defaults[\"gradient_accumulation_steps\"] * config_defaults[\"epochs\"]\n",
        "\n",
        "print(num_steps)\n",
        "\n",
        "if config_defaults[\"scheduler\"] == \"CosineAnnealingWarmRestarts\":\n",
        "    config_defaults[\"T_0\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingLR\":\n",
        "    config_defaults[\"T_max\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
        "    config_defaults[\"factor\"] = 0.2\n",
        "    config_defaults[\"patience\"] = 4\n",
        "    config_defaults[\"eps\"] = 1e-6\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingWarmupRestarts\":\n",
        "    config_defaults[\"first_cycle_steps\"] = num_steps\n",
        "    config_defaults[\"warmup_steps\"] = num_steps // 10\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"get_cosine_schedule_with_warmup\":\n",
        "    config_defaults[\"num_training_steps\"] = num_steps\n",
        "    config_defaults[\"num_warmup_steps\"] = max(50, num_steps // 10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "a6a78770",
        "outputId": "fa919ace-2bd3-49ac-a3e1-8d4a729931cc"
      },
      "source": [
        "if Config.debug:\n",
        "    run = wandb.init(entity=Config.wandb_entity, project=Config.wandb_project, config=config_defaults, mode=\"disabled\")\n",
        "else:\n",
        "    run = wandb.init(entity=Config.wandb_entity, project=Config.wandb_project, config=config_defaults, notes=wandb_notes, tags=wandb_tags, job_type=wandb_job_type, save_code=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">still-dew-85</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ponkots/signate-471\" target=\"_blank\">https://wandb.ai/ponkots/signate-471</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ponkots/signate-471/runs/2di2sp58\" target=\"_blank\">https://wandb.ai/ponkots/signate-471/runs/2di2sp58</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210907_011149-2di2sp58</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2408ee43"
      },
      "source": [
        "config = wandb.config"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezOfV_OKnV2I"
      },
      "source": [
        "## EDA-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1C7cU7ka70h",
        "outputId": "cdb5d5a8-2585-489f-e16d-a80bc3b1b679"
      },
      "source": [
        "# アブストが空っぽのが結構ある\n",
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id              0\n",
            "title           0\n",
            "abstract     4390\n",
            "judgement       0\n",
            "dtype: int64\n",
            "id             0\n",
            "title          0\n",
            "abstract    6546\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4fTaf66DiXj"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuuU17phnFMz"
      },
      "source": [
        "def preprocess(data):\n",
        "    \n",
        "    title_abstract = []\n",
        "    for e in data:\n",
        "\n",
        "        # アルファベット以外は空白に置換します。\n",
        "        e = re.sub(\"[^a-zA-Z]\", \" \", e)\n",
        "\n",
        "        # 小文字に変換します。\n",
        "        e = e.lower()\n",
        "\n",
        "        # token に分割します。\n",
        "        e = nltk.word_tokenize(e)\n",
        "\n",
        "        # stop word を削除します。\n",
        "        e = [word for word in e if not word in set(nltk.corpus.stopwords.words(\"english\"))]\n",
        "\n",
        "        # 見出し語化します。\n",
        "        lemma = nltk.WordNetLemmatizer()\n",
        "        e = [lemma.lemmatize(word) for word in e]\n",
        "        e = \" \".join(e)\n",
        "\n",
        "        title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM-NHL8HLzOc"
      },
      "source": [
        "def back_translation_de(data):\n",
        "    print(\"Back Translation (en -> de -> en)\")\n",
        "    title_abstract = []\n",
        "    back_translation_aug = naw.BackTranslationAug(\n",
        "        from_model_name='facebook/wmt19-en-de', \n",
        "        to_model_name='facebook/wmt19-de-en',\n",
        "        max_length=config.max_len,\n",
        "        device='cuda',\n",
        "    )\n",
        "\n",
        "    for e in tqdm(data, total=len(data)):\n",
        "        if random.random() < 0.1:\n",
        "            try:\n",
        "                title_abstract.append(back_translation_aug.augment(e))\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                title_abstract.append(e)\n",
        "        else:\n",
        "            title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBV7kf3uWECm"
      },
      "source": [
        "def synonym_augmenter(data):\n",
        "    print(\"Synonym Augmenter\")\n",
        "    title_abstract = []\n",
        "    aug = naw.SynonymAug(aug_src='wordnet', aug_max=None, aug_p=0.3)\n",
        "\n",
        "    for e in tqdm(data, total=len(data)):\n",
        "        if random.random() < 0.3:\n",
        "            try:\n",
        "                title_abstract.append(aug.augment(e))\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                title_abstract.append(e)\n",
        "        else:\n",
        "            title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQCGtu9kbatB"
      },
      "source": [
        "def abstractive_summarization_augmenter(data):\n",
        "    print(\"Abstractive Summarization Augmenter\")\n",
        "    title_abstract = []\n",
        "    aug = nas.AbstSummAug(\n",
        "        model_path='t5-base',\n",
        "        max_length=config.max_len,\n",
        "        device='cuda',\n",
        "    )\n",
        "\n",
        "    for e in tqdm(data, total=len(data)):\n",
        "        if len(e.split()) > config.max_len:\n",
        "            try:\n",
        "                title_abstract.append(aug.augment(e))\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                title_abstract.append(e)\n",
        "        else:\n",
        "            title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylcVBT02nIGZ"
      },
      "source": [
        "def get_train_data(train):\n",
        "\n",
        "    # NaN を空白で埋めます。\n",
        "    train = train.fillna(\"\")\n",
        "\n",
        "    # judgement を one hot encoding\n",
        "    # train[\"judgement_str\"] = train[\"judgement\"].astype(str)\n",
        "    # train = pd.get_dummies(train, columns=[\"judgement_str\"], prefix=[\"judgement\"])\n",
        "\n",
        "    # abstract の有無を Stratified KFold で使います。\n",
        "    train[\"nan_abstract\"] = np.where(train[\"abstract\"] == \"\", 1, 0)\n",
        "\n",
        "    # title の単語数\n",
        "    # train[\"len_title\"] = train[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # abstract の単語数\n",
        "    # train[\"len_abstract\"] = train[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # title と abstract を接続します。\n",
        "    train[\"title_abstract\"] = train[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "    # train[\"abstract_title\"] = train[[\"abstract\", \"title\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "    # Abstractive Summarization Augmenter\n",
        "    train[\"title_abstract\"] = abstractive_summarization_augmenter(train[\"title_abstract\"])\n",
        "\n",
        "    # Back Translation (en -> de -> en)\n",
        "    train[\"title_abstract\"] = back_translation_de(train[\"title_abstract\"])\n",
        "\n",
        "    # Synonym Augmenter\n",
        "    train[\"title_abstract\"] = synonym_augmenter(train[\"title_abstract\"])\n",
        "\n",
        "    train[\"len_input\"] = train[config.input].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # train[\"preprocessed_title_abstract\"] = preprocess(train[\"title_abstract\"])\n",
        "\n",
        "    # 前処理した文の単語数\n",
        "    # train[\"len_preprocessed_title_abstract\"] = train[\"preprocessed_title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return train"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YskezxynKkm"
      },
      "source": [
        "def get_test_data(test):\n",
        "\n",
        "    # NaN を空白で埋めます。\n",
        "    test = test.fillna(\"\")\n",
        "\n",
        "    # title の単語数\n",
        "    # test[\"len_title\"] = test[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # abstract の単語数\n",
        "    # test[\"len_abstract\"] = test[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # title と abstract を接続します。\n",
        "    test[\"title_abstract\"] = test[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "    # test[\"abstract_title\"] = test[[\"abstract\", \"title\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "    # Abstractive Summarization Augmenter\n",
        "    test[\"title_abstract\"] = abstractive_summarization_augmenter(test[\"title_abstract\"])\n",
        "\n",
        "    test[\"len_input\"] = test[config.input].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # test[\"preprocessed_title_abstract\"] = preprocess(test[\"title_abstract\"])\n",
        "\n",
        "    # 前処理した文の単語数\n",
        "    # test[\"len_preprocessed_title_abstract\"] = test[\"preprocessed_title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return test"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0CPmvZnQFP"
      },
      "source": [
        "if os.path.exists(\"/content/drive/MyDrive/Datasets/signate-471/preprocessed_train.csv\"):\n",
        "    !cp -f /content/drive/MyDrive/Datasets/signate-471/preprocessed_train.csv .\n",
        "    train = pd.read_csv(\"preprocessed_train.csv\")\n",
        "\n",
        "    # csv を再読み込みすると NaN に戻ってしまうので、再度変換します。\n",
        "    train = train.fillna(\"\")\n",
        "\n",
        "else:\n",
        "    # 一度、前処理したものは保存しておきます。\n",
        "    train = get_train_data(train)\n",
        "    train.to_csv(\"preprocessed_train.csv\")\n",
        "\n",
        "    # artifact = wandb.Artifact('preprocessed_train', type='dataset')\n",
        "    # artifact.add_file(\"preprocessed_train.csv\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    !cp -f preprocessed_train.csv /content/drive/MyDrive/Datasets/signate-471/"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A248D057nSd6"
      },
      "source": [
        "if os.path.exists(\"/content/drive/MyDrive/Datasets/signate-471/preprocessed_test.csv\"):\n",
        "    !cp -f /content/drive/MyDrive/Datasets/signate-471/preprocessed_test.csv .\n",
        "    test = pd.read_csv(\"preprocessed_test.csv\")\n",
        "\n",
        "    # csv を再読み込みすると NaN に戻ってしまうので、再度変換します。\n",
        "    test = test.fillna(\"\")\n",
        "\n",
        "else:\n",
        "    # 一度、前処理したものは保存しておきます。\n",
        "    test = get_test_data(test)\n",
        "    test.to_csv(\"preprocessed_test.csv\")\n",
        "\n",
        "    # artifact = wandb.Artifact('preprocessed_test', type='dataset')\n",
        "    # artifact.add_file(\"preprocessed_test.csv\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    !cp -f preprocessed_test.csv /content/drive/MyDrive/Datasets/signate-471/"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UPOk9WroUmX"
      },
      "source": [
        "## EDA-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BloR0mcceTWK",
        "outputId": "c95a937a-b3cf-4340-8417-d91c4ba1a046"
      },
      "source": [
        "# abstract に改行は含まれていない\n",
        "print(len(train[train[\"abstract\"].str.contains(\"\\n\")]))\n",
        "print(len(test[test[\"abstract\"].str.contains(\"\\n\")]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHfTQdU8Cezv",
        "outputId": "bf40e89b-6205-4d7d-e42b-45618e4ccab9"
      },
      "source": [
        "# input の単語数\n",
        "print(train[\"len_input\"].max())\n",
        "print(test[\"len_input\"].max())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "758\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "18097672",
        "outputId": "c6c336e7-8681-42bf-9b88-6ca53fbb3273"
      },
      "source": [
        "for ds in [train, test, sub]:\n",
        "    print(f\"=\" * 80)\n",
        "    ds.info()\n",
        "    display(ds.head())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27145 entries, 0 to 27144\n",
            "Data columns (total 8 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Unnamed: 0      27145 non-null  int64 \n",
            " 1   id              27145 non-null  int64 \n",
            " 2   title           27145 non-null  object\n",
            " 3   abstract        27145 non-null  object\n",
            " 4   judgement       27145 non-null  int64 \n",
            " 5   nan_abstract    27145 non-null  int64 \n",
            " 6   title_abstract  27145 non-null  object\n",
            " 7   len_input       27145 non-null  int64 \n",
            "dtypes: int64(5), object(3)\n",
            "memory usage: 1.7+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>judgement</th>\n",
              "      <th>nan_abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>len_input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>Longitudinal studies indicate that declines in...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>The present study was undertaken to validate t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>Objective: To report a case series in which ba...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Occurrence of basal ganglion germ cell neoplas...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id  ...                                     title_abstract len_input\n",
              "0           0   0  ...  One-year age changes in MRI brain volumes in o...       203\n",
              "1           1   1  ...  Supportive CSF biomarker evidence to enhance t...       237\n",
              "2           2   2  ...  Occurrence of basal ganglion germ cell neoplas...       155\n",
              "3           3   3  ...  New developments in diagnosis and therapy of C...       387\n",
              "4           4   4  ...  Prolonged shedding of SARS-CoV-2 in an elderly...        16\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Unnamed: 0      40834 non-null  int64 \n",
            " 1   id              40834 non-null  int64 \n",
            " 2   title           40834 non-null  object\n",
            " 3   abstract        40834 non-null  object\n",
            " 4   title_abstract  40834 non-null  object\n",
            " 5   len_input       40834 non-null  int64 \n",
            "dtypes: int64(3), object(3)\n",
            "memory usage: 1.9+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>len_input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>27145</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>The objective of the paper is to analyse chang...</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>27146</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td></td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>27147</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>27148</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>We present a method that significantly improve...</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>27149</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>The objective of this study is to compare the ...</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  len_input\n",
              "0           0  ...        261\n",
              "1           1  ...          8\n",
              "2           2  ...        329\n",
              "3           3  ...        130\n",
              "4           4  ...        237\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype\n",
            "---  ------     --------------  -----\n",
            " 0   id         40834 non-null  int64\n",
            " 1   judgement  40834 non-null  int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 638.2 KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>judgement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27146</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27147</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  judgement\n",
              "0  27145          0\n",
              "1  27146          1\n",
              "2  27147          1\n",
              "3  27148          0\n",
              "4  27149          1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9L3nMYzDMqJ"
      },
      "source": [
        "### 目的変数 judgement の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "3f5772d0",
        "outputId": "ea875d1c-1ed5-4457-e2b8-2afe8f980723"
      },
      "source": [
        "sns.distplot(train[\"judgement\"], kde=False)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f50f53da6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuZVvlM8Xy91",
        "outputId": "580bd5a3-a823-4ac5-8e27-4e9ec7099528"
      },
      "source": [
        "train[\"judgement\"].value_counts()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    26515\n",
              "1      630\n",
              "Name: judgement, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E-56356_L3T",
        "outputId": "cb0c8194-08ea-4d59-8e0f-08a257d4afcf"
      },
      "source": [
        "border = len(train[train[\"judgement\"] == 1]) / len(train[\"judgement\"])\n",
        "print(border)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0232086940504697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZNrZoksDSMb"
      },
      "source": [
        "### input の単語数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "ixixzShVH80j",
        "outputId": "d5fe1c94-263f-4b42-c871-d5b45583144a"
      },
      "source": [
        "g = sns.FacetGrid(train[[\"judgement\", \"len_input\"]], hue='judgement')\n",
        "g.map(sns.distplot, 'len_input', label='judgement', hist=True, rug=False)\n",
        "g.add_legend()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f50f5934e90>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 278.125x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W_kt9XDpGTm2",
        "outputId": "871b5f4d-5c28-440f-ceef-4334b3701636"
      },
      "source": [
        "sns.distplot(test[\"len_input\"], hist=True, rug=False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f50f0359ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeZesLBHnfl5"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOdN4h2grTzx"
      },
      "source": [
        "if Config.validate:\n",
        "    api = wandb.Api()\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        try:\n",
        "            run.file(\"oof_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        oof = pd.read_csv(f\"{run_id}/oof_df.csv\")[[\"id\", \"preds\"]]\n",
        "        oof.columns = [\"id\", f\"preds{n}\"]\n",
        "        train = pd.merge(train, oof, on=\"id\")\n",
        "    \n",
        "    print(train.columns)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM2fDBrNi2_K"
      },
      "source": [
        "if Config.inference:\n",
        "    api = wandb.Api()\n",
        "    inference_models = []\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        inference_model = {}\n",
        "        inference_model[\"run_id\"] = run_id\n",
        "        inference_model[\"model_name\"] = run.config[\"model_name\"]\n",
        "\n",
        "        for fold in range(config.n_fold):\n",
        "            try:\n",
        "                run.file(f\"{inference_model['model_name'].replace('/', '-')}_fold{fold}_best.pth\").download(run_id)\n",
        "            except wandb.CommError:\n",
        "                # Already downloaded.\n",
        "                pass\n",
        "\n",
        "            model_preds = torch.load(f\"{run_id}/{inference_model['model_name'].replace('/', '-')}_fold{fold}_best.pth\")\n",
        "            inference_model[f\"state_fold{fold}\"] = model_preds[\"model\"]\n",
        "            inference_model[f\"preds_fold{fold}\"] = model_preds[\"preds\"]\n",
        "\n",
        "        inference_models.append(inference_model)\n",
        "    \n",
        "    print({m['run_id']: m['model_name'] for m in inference_models})"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXmpjcJxQhBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5893dd-7803-47a1-a767-5df2c5d9b7e9"
      },
      "source": [
        "if Config.stack or Config.ensemble:\n",
        "    api = wandb.Api()\n",
        "\n",
        "    feat_id = 0\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        try:\n",
        "            run.file(\"validation_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            run.file(\"prediction_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        val = pd.read_csv(f\"{run_id}/validation_df.csv\")\n",
        "        pred = pd.read_csv(f\"{run_id}/prediction_df.csv\")\n",
        "\n",
        "        if Config.ensemble:\n",
        "            cols = [c for c in val.columns if c.startswith(\"class_preds\")]\n",
        "        else:\n",
        "            cols = [c for c in val.columns if c.startswith(\"preds\") and c != \"preds\"]\n",
        "\n",
        "        val = val[[\"id\"] + cols]\n",
        "        pred = pred[[\"id\"] + cols]\n",
        "\n",
        "        adjust_cols = [\"id\"] + [f\"preds{n}\" for n in range(feat_id, feat_id + len(cols))]\n",
        "        val.columns = adjust_cols\n",
        "        pred.columns = adjust_cols\n",
        "\n",
        "        feat_id += len(cols)\n",
        "\n",
        "        train = pd.merge(train, val, on=\"id\")\n",
        "        test = pd.merge(test, pred, on=\"id\")\n",
        "\n",
        "    train.drop(\"preds4\", inplace=True, axis=1)\n",
        "    test.drop(\"preds4\", inplace=True, axis=1)\n",
        "\n",
        "    print(f\"train: {train.columns}\")\n",
        "    print(f\"test: {test.columns}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: Index(['Unnamed: 0', 'id', 'title', 'abstract', 'judgement', 'nan_abstract',\n",
            "       'title_abstract', 'len_input', 'preds0', 'preds1', 'preds2', 'preds3',\n",
            "       'preds5', 'preds6', 'preds7'],\n",
            "      dtype='object')\n",
            "test: Index(['Unnamed: 0', 'id', 'title', 'abstract', 'title_abstract', 'len_input',\n",
            "       'preds0', 'preds1', 'preds2', 'preds3', 'preds5', 'preds6', 'preds7'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba31d893"
      },
      "source": [
        "if Config.debug and not Config.stack:\n",
        "    train = train.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    test = test.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    sub = sub.sample(n=1000, random_state=config.seed).reset_index(drop=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQ7fKQ2IC6i"
      },
      "source": [
        "## CV Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Lt-ZLtIHCG",
        "outputId": "e38b366b-0e12-48d1-f1cd-e705e654698f"
      },
      "source": [
        "Fold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train[[\"judgement\", \"nan_abstract\"]])):\n",
        "    train.loc[val_index, \"fold\"] = int(n)\n",
        "train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n",
        "print(train.groupby([\"fold\", \"judgement\", \"nan_abstract\"]).size())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold  judgement  nan_abstract\n",
            "0     0          0               4455\n",
            "                 1                848\n",
            "      1          0                198\n",
            "                 1                 54\n",
            "1     0          0               4453\n",
            "                 1                850\n",
            "      1          0                200\n",
            "                 1                 52\n",
            "2     0          0               4446\n",
            "                 1                857\n",
            "      1          0                207\n",
            "                 1                 45\n",
            "3     0          0               4445\n",
            "                 1                858\n",
            "      1          0                208\n",
            "                 1                 44\n",
            "4     0          0               4446\n",
            "                 1                857\n",
            "      1          0                207\n",
            "                 1                 45\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d423ea8"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5985d91d"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=config.seed)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596efb85"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2721636"
      },
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, df, model_name, include_labels=True):\n",
        "        tokenizer = T.AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        self.df = df\n",
        "        self.include_labels = include_labels\n",
        "\n",
        "        self.title = df[config.input].tolist()\n",
        "        self.encoded = tokenizer.batch_encode_plus(\n",
        "            self.title,\n",
        "            padding = 'max_length',            \n",
        "            max_length = config.max_len,\n",
        "            truncation = True,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        \n",
        "        if self.include_labels:\n",
        "            self.labels = df[\"judgement\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = torch.tensor(self.encoded['input_ids'][idx])\n",
        "        attention_mask = torch.tensor(self.encoded['attention_mask'][idx])\n",
        "\n",
        "        if self.include_labels:\n",
        "            label = torch.tensor(self.labels[idx]).float()\n",
        "            return input_ids, attention_mask, label\n",
        "\n",
        "        return input_ids, attention_mask\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e56a1c49",
        "outputId": "aa767b94-dd0b-4b9d-9858-585fe84cbde0"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "\n",
        "    train_ds = BaseDataset(train, config.model_name)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_ids, attention_mask, label = train_ds[i]\n",
        "        print(input_ids)\n",
        "        print(attention_mask)\n",
        "        print(f\"label: {label}\")\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101,  1141,   118,  1214,  1425,  2607,  1107,   182,  2047,  3575,\n",
            "         6357,  1107,  2214,  6323,   119, 23191,  2527,  5057,  1115,  6246,\n",
            "         1116,  1107,  1884, 25763,  1105,  2962, 26872,  1170,  1425,  3102,\n",
            "         1201,   119,  1103, 24928, 11955,  3906, 18778,  1596,  1105, 24928,\n",
            "        11955, 22192, 23652, 13791,  1596,  1223,  6709,  3381,  1116,  1104,\n",
            "        12176,  1849,  1132, 10527,  1112,  1175,  1110,  1376,  1869,  1113,\n",
            "        23191,  3575,  2607,   119,  1195,  1132,  9239,   170, 23191, 24928,\n",
            "        11955,  8628,  3375,  2025,  1104,  1664,  2007, 24674,  2214,  6635,\n",
            "         1107,  1103,   171,  1348,  3121,  4982, 23191,  2025,  1104, 14195,\n",
            "          119,  1142,  2592,  7203,  1113,  1425,  1105,  2673,  5408,  1107,\n",
            "         3575,  2401,  7140,  1118,  8364, 20370, 14377,  1219,  1103,  1148,\n",
            "         1160,  2683, 10540,  1116,   119,  2771,   118,  2237,  1348,  2686,\n",
            "         1121, 13096,  6635,  4079,  4589,   118,  4859,  1201,  7063,  5409,\n",
            "         2610, 21828,  4907,  5552,  6357,  1105,  2964,  5021,  1105,  1653,\n",
            "         2187,  6357,  1107,  2214,  3402,  1114,  3247,  6635,  1105,  1107,\n",
            "         1441,  3402,  1114,  1535,   119,  2918,  3575,  6357,  1437,  1115,\n",
            "         1103,  3154,  1104,  1425,  1105,  2673,  1132,  1136,  6029,  1506,\n",
            "         3575,  4001,   119,  1425,  5408,  1132,  4459,  1111,  1103, 14247,\n",
            "        22331,  1348,  1805,   119,  2673,  5408,  6613,  1106,  1129,  2610,\n",
            "         1111, 22172,  1105, 18107,  1190, 14247, 22331,  1348,  1105,   184,\n",
            "        19557, 18965,  1348,  4001,   119, 23191,  3622, 17798,  1126,  2773,\n",
            "         1104, 15722,  1545,  2608,   113,   124,   114,  1107, 21828,  4907,\n",
            "         5552,  3884,  1166,   122,  1214,  1133,  1185, 11552,  1895,  1849,\n",
            "         1107,  1703,  1137,  2918,  3575,  6357,   119,  5754,  1104,  1103,\n",
            "         4844,  1105,  2603,  1104, 23191,  3575,  2607,  1209, 11000,  1103,\n",
            "        11432,  1104,  3507,  7542,  3575,  2607,  1134,  1336,  1129, 17163,\n",
            "         3864,  1104, 26707,  3452,  1465,   119,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d681dabf"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Y5LnDCMPcC"
      },
      "source": [
        "### BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHPwf3JzPmjI",
        "outputId": "958cd30d-33f5-492b-9565-14222485970a"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    print(T.AutoConfig.from_pretrained(config.model_name))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "229d18e7"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "\n",
        "        if \"base\" in model_name or \"L-12\" in model_name or \"scibert\" in model_name:\n",
        "            out_dim = 768\n",
        "        elif \"large\" in model_name or \"L-24\" in model_name:\n",
        "            out_dim = 1024\n",
        "\n",
        "        auto_config = T.AutoConfig.from_pretrained(model_name)\n",
        "        auto_config.update({\n",
        "            \"output_hidden_states\": True,\n",
        "            \"hidden_dropout_prob\": config.dropout,\n",
        "            # \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "        \n",
        "        self.auto_model = T.AutoModel.from_pretrained(model_name, config=auto_config)  \n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(out_dim, 512),            \n",
        "            nn.Tanh(),                       \n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )        \n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(out_dim, 1)                        \n",
        "        )\n",
        "\n",
        "        if config.reinit_layers > 0:\n",
        "            self.re_init()\n",
        "\n",
        "        if config.freeze_layers > 0:\n",
        "            self.freeze()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.auto_model(input_ids=input_ids, attention_mask=attention_mask)        \n",
        "\n",
        "        # There are a total of 13 layers of hidden states.\n",
        "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
        "        # We take the hidden states from the last Roberta layer.\n",
        "        last_layer_hidden_states = bert_output.hidden_states[-1]\n",
        "\n",
        "        # The number of cells is config.max_len.\n",
        "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
        "        # In order to condense hidden states of all cells to a context vector,\n",
        "        # we compute a weighted average of the hidden states of all cells.\n",
        "        # We compute the weight of each cell, using the attention neural network.\n",
        "        weights = self.attention(last_layer_hidden_states)\n",
        "                \n",
        "        # weights.shape is config.batch_size x config.max_len x 1\n",
        "        # last_layer_hidden_states.shape is config.batch_size x config.max_len x 768        \n",
        "        # Now we compute context_vector as the weighted average.\n",
        "        # context_vector.shape is config.batch_size x 768\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
        "        \n",
        "        # Now we reduce the context vector to the prediction score.\n",
        "        out = self.regressor(context_vector).squeeze()\n",
        "\n",
        "        return out\n",
        "\n",
        "    def re_init(self):\n",
        "        # re-init pooler\n",
        "        self.auto_model.pooler.dense.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "        self.auto_model.pooler.dense.bias.data.zero_()\n",
        "        for p in self.auto_model.pooler.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        # re-init encoder\n",
        "        layers = self.auto_model.encoder.layer[-config.reinit_layers:]\n",
        "        for layer in layers:\n",
        "            for module in layer.modules():\n",
        "                if isinstance(module, nn.Linear):\n",
        "                    # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "                    # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.bias is not None:\n",
        "                        module.bias.data.zero_()\n",
        "                elif isinstance(module, nn.Embedding):\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.padding_idx is not None:\n",
        "                        module.weight.data[module.padding_idx].zero_()\n",
        "                elif isinstance(module, nn.LayerNorm):\n",
        "                    module.bias.data.zero_()\n",
        "                    module.weight.data.fill_(1.0)\n",
        "\n",
        "    def freeze(self):\n",
        "        # freeze embedding\n",
        "        for param in self.auto_model.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # freeze encoder\n",
        "        layers = self.auto_model.encoder.layer[:config.freeze_layers]\n",
        "        for layer in layers:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a3978b1",
        "outputId": "a1bdea82-aa55-4ca6-cba7-a64696b52b59"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "\n",
        "    model = BaseModel(config.model_name)\n",
        "    print(model)\n",
        "\n",
        "    train_dataset = BaseDataset(train, config.model_name)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "    for input_ids, attention_mask, labels in train_loader:\n",
        "        output = model(input_ids, attention_mask)\n",
        "        print(output)\n",
        "        break\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModel(\n",
            "  (auto_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (attention): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (3): Softmax(dim=1)\n",
            "  )\n",
            "  (regressor): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "tensor([-0.5487, -0.5745, -0.4820, -0.5766], grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlpHUm-SrcLV",
        "outputId": "d8c39a3f-24c7-47dc-d91c-5c707a205fa6"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
        "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0: True, auto_model.embeddings.word_embeddings.weight\n",
            "   1: True, auto_model.embeddings.position_embeddings.weight\n",
            "   2: True, auto_model.embeddings.token_type_embeddings.weight\n",
            "   3: True, auto_model.embeddings.LayerNorm.weight\n",
            "   4: True, auto_model.embeddings.LayerNorm.bias\n",
            "   5: True, auto_model.encoder.layer.0.attention.self.query.weight\n",
            "   6: True, auto_model.encoder.layer.0.attention.self.query.bias\n",
            "   7: True, auto_model.encoder.layer.0.attention.self.key.weight\n",
            "   8: True, auto_model.encoder.layer.0.attention.self.key.bias\n",
            "   9: True, auto_model.encoder.layer.0.attention.self.value.weight\n",
            "  10: True, auto_model.encoder.layer.0.attention.self.value.bias\n",
            "  11: True, auto_model.encoder.layer.0.attention.output.dense.weight\n",
            "  12: True, auto_model.encoder.layer.0.attention.output.dense.bias\n",
            "  13: True, auto_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  14: True, auto_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  15: True, auto_model.encoder.layer.0.intermediate.dense.weight\n",
            "  16: True, auto_model.encoder.layer.0.intermediate.dense.bias\n",
            "  17: True, auto_model.encoder.layer.0.output.dense.weight\n",
            "  18: True, auto_model.encoder.layer.0.output.dense.bias\n",
            "  19: True, auto_model.encoder.layer.0.output.LayerNorm.weight\n",
            "  20: True, auto_model.encoder.layer.0.output.LayerNorm.bias\n",
            "  21: True, auto_model.encoder.layer.1.attention.self.query.weight\n",
            "  22: True, auto_model.encoder.layer.1.attention.self.query.bias\n",
            "  23: True, auto_model.encoder.layer.1.attention.self.key.weight\n",
            "  24: True, auto_model.encoder.layer.1.attention.self.key.bias\n",
            "  25: True, auto_model.encoder.layer.1.attention.self.value.weight\n",
            "  26: True, auto_model.encoder.layer.1.attention.self.value.bias\n",
            "  27: True, auto_model.encoder.layer.1.attention.output.dense.weight\n",
            "  28: True, auto_model.encoder.layer.1.attention.output.dense.bias\n",
            "  29: True, auto_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  30: True, auto_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  31: True, auto_model.encoder.layer.1.intermediate.dense.weight\n",
            "  32: True, auto_model.encoder.layer.1.intermediate.dense.bias\n",
            "  33: True, auto_model.encoder.layer.1.output.dense.weight\n",
            "  34: True, auto_model.encoder.layer.1.output.dense.bias\n",
            "  35: True, auto_model.encoder.layer.1.output.LayerNorm.weight\n",
            "  36: True, auto_model.encoder.layer.1.output.LayerNorm.bias\n",
            "  37: True, auto_model.encoder.layer.2.attention.self.query.weight\n",
            "  38: True, auto_model.encoder.layer.2.attention.self.query.bias\n",
            "  39: True, auto_model.encoder.layer.2.attention.self.key.weight\n",
            "  40: True, auto_model.encoder.layer.2.attention.self.key.bias\n",
            "  41: True, auto_model.encoder.layer.2.attention.self.value.weight\n",
            "  42: True, auto_model.encoder.layer.2.attention.self.value.bias\n",
            "  43: True, auto_model.encoder.layer.2.attention.output.dense.weight\n",
            "  44: True, auto_model.encoder.layer.2.attention.output.dense.bias\n",
            "  45: True, auto_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  46: True, auto_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  47: True, auto_model.encoder.layer.2.intermediate.dense.weight\n",
            "  48: True, auto_model.encoder.layer.2.intermediate.dense.bias\n",
            "  49: True, auto_model.encoder.layer.2.output.dense.weight\n",
            "  50: True, auto_model.encoder.layer.2.output.dense.bias\n",
            "  51: True, auto_model.encoder.layer.2.output.LayerNorm.weight\n",
            "  52: True, auto_model.encoder.layer.2.output.LayerNorm.bias\n",
            "  53: True, auto_model.encoder.layer.3.attention.self.query.weight\n",
            "  54: True, auto_model.encoder.layer.3.attention.self.query.bias\n",
            "  55: True, auto_model.encoder.layer.3.attention.self.key.weight\n",
            "  56: True, auto_model.encoder.layer.3.attention.self.key.bias\n",
            "  57: True, auto_model.encoder.layer.3.attention.self.value.weight\n",
            "  58: True, auto_model.encoder.layer.3.attention.self.value.bias\n",
            "  59: True, auto_model.encoder.layer.3.attention.output.dense.weight\n",
            "  60: True, auto_model.encoder.layer.3.attention.output.dense.bias\n",
            "  61: True, auto_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  62: True, auto_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  63: True, auto_model.encoder.layer.3.intermediate.dense.weight\n",
            "  64: True, auto_model.encoder.layer.3.intermediate.dense.bias\n",
            "  65: True, auto_model.encoder.layer.3.output.dense.weight\n",
            "  66: True, auto_model.encoder.layer.3.output.dense.bias\n",
            "  67: True, auto_model.encoder.layer.3.output.LayerNorm.weight\n",
            "  68: True, auto_model.encoder.layer.3.output.LayerNorm.bias\n",
            "  69: True, auto_model.encoder.layer.4.attention.self.query.weight\n",
            "  70: True, auto_model.encoder.layer.4.attention.self.query.bias\n",
            "  71: True, auto_model.encoder.layer.4.attention.self.key.weight\n",
            "  72: True, auto_model.encoder.layer.4.attention.self.key.bias\n",
            "  73: True, auto_model.encoder.layer.4.attention.self.value.weight\n",
            "  74: True, auto_model.encoder.layer.4.attention.self.value.bias\n",
            "  75: True, auto_model.encoder.layer.4.attention.output.dense.weight\n",
            "  76: True, auto_model.encoder.layer.4.attention.output.dense.bias\n",
            "  77: True, auto_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  78: True, auto_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  79: True, auto_model.encoder.layer.4.intermediate.dense.weight\n",
            "  80: True, auto_model.encoder.layer.4.intermediate.dense.bias\n",
            "  81: True, auto_model.encoder.layer.4.output.dense.weight\n",
            "  82: True, auto_model.encoder.layer.4.output.dense.bias\n",
            "  83: True, auto_model.encoder.layer.4.output.LayerNorm.weight\n",
            "  84: True, auto_model.encoder.layer.4.output.LayerNorm.bias\n",
            "  85: True, auto_model.encoder.layer.5.attention.self.query.weight\n",
            "  86: True, auto_model.encoder.layer.5.attention.self.query.bias\n",
            "  87: True, auto_model.encoder.layer.5.attention.self.key.weight\n",
            "  88: True, auto_model.encoder.layer.5.attention.self.key.bias\n",
            "  89: True, auto_model.encoder.layer.5.attention.self.value.weight\n",
            "  90: True, auto_model.encoder.layer.5.attention.self.value.bias\n",
            "  91: True, auto_model.encoder.layer.5.attention.output.dense.weight\n",
            "  92: True, auto_model.encoder.layer.5.attention.output.dense.bias\n",
            "  93: True, auto_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  94: True, auto_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  95: True, auto_model.encoder.layer.5.intermediate.dense.weight\n",
            "  96: True, auto_model.encoder.layer.5.intermediate.dense.bias\n",
            "  97: True, auto_model.encoder.layer.5.output.dense.weight\n",
            "  98: True, auto_model.encoder.layer.5.output.dense.bias\n",
            "  99: True, auto_model.encoder.layer.5.output.LayerNorm.weight\n",
            " 100: True, auto_model.encoder.layer.5.output.LayerNorm.bias\n",
            " 101: True, auto_model.encoder.layer.6.attention.self.query.weight\n",
            " 102: True, auto_model.encoder.layer.6.attention.self.query.bias\n",
            " 103: True, auto_model.encoder.layer.6.attention.self.key.weight\n",
            " 104: True, auto_model.encoder.layer.6.attention.self.key.bias\n",
            " 105: True, auto_model.encoder.layer.6.attention.self.value.weight\n",
            " 106: True, auto_model.encoder.layer.6.attention.self.value.bias\n",
            " 107: True, auto_model.encoder.layer.6.attention.output.dense.weight\n",
            " 108: True, auto_model.encoder.layer.6.attention.output.dense.bias\n",
            " 109: True, auto_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            " 110: True, auto_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            " 111: True, auto_model.encoder.layer.6.intermediate.dense.weight\n",
            " 112: True, auto_model.encoder.layer.6.intermediate.dense.bias\n",
            " 113: True, auto_model.encoder.layer.6.output.dense.weight\n",
            " 114: True, auto_model.encoder.layer.6.output.dense.bias\n",
            " 115: True, auto_model.encoder.layer.6.output.LayerNorm.weight\n",
            " 116: True, auto_model.encoder.layer.6.output.LayerNorm.bias\n",
            " 117: True, auto_model.encoder.layer.7.attention.self.query.weight\n",
            " 118: True, auto_model.encoder.layer.7.attention.self.query.bias\n",
            " 119: True, auto_model.encoder.layer.7.attention.self.key.weight\n",
            " 120: True, auto_model.encoder.layer.7.attention.self.key.bias\n",
            " 121: True, auto_model.encoder.layer.7.attention.self.value.weight\n",
            " 122: True, auto_model.encoder.layer.7.attention.self.value.bias\n",
            " 123: True, auto_model.encoder.layer.7.attention.output.dense.weight\n",
            " 124: True, auto_model.encoder.layer.7.attention.output.dense.bias\n",
            " 125: True, auto_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            " 126: True, auto_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            " 127: True, auto_model.encoder.layer.7.intermediate.dense.weight\n",
            " 128: True, auto_model.encoder.layer.7.intermediate.dense.bias\n",
            " 129: True, auto_model.encoder.layer.7.output.dense.weight\n",
            " 130: True, auto_model.encoder.layer.7.output.dense.bias\n",
            " 131: True, auto_model.encoder.layer.7.output.LayerNorm.weight\n",
            " 132: True, auto_model.encoder.layer.7.output.LayerNorm.bias\n",
            " 133: True, auto_model.encoder.layer.8.attention.self.query.weight\n",
            " 134: True, auto_model.encoder.layer.8.attention.self.query.bias\n",
            " 135: True, auto_model.encoder.layer.8.attention.self.key.weight\n",
            " 136: True, auto_model.encoder.layer.8.attention.self.key.bias\n",
            " 137: True, auto_model.encoder.layer.8.attention.self.value.weight\n",
            " 138: True, auto_model.encoder.layer.8.attention.self.value.bias\n",
            " 139: True, auto_model.encoder.layer.8.attention.output.dense.weight\n",
            " 140: True, auto_model.encoder.layer.8.attention.output.dense.bias\n",
            " 141: True, auto_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            " 142: True, auto_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            " 143: True, auto_model.encoder.layer.8.intermediate.dense.weight\n",
            " 144: True, auto_model.encoder.layer.8.intermediate.dense.bias\n",
            " 145: True, auto_model.encoder.layer.8.output.dense.weight\n",
            " 146: True, auto_model.encoder.layer.8.output.dense.bias\n",
            " 147: True, auto_model.encoder.layer.8.output.LayerNorm.weight\n",
            " 148: True, auto_model.encoder.layer.8.output.LayerNorm.bias\n",
            " 149: True, auto_model.encoder.layer.9.attention.self.query.weight\n",
            " 150: True, auto_model.encoder.layer.9.attention.self.query.bias\n",
            " 151: True, auto_model.encoder.layer.9.attention.self.key.weight\n",
            " 152: True, auto_model.encoder.layer.9.attention.self.key.bias\n",
            " 153: True, auto_model.encoder.layer.9.attention.self.value.weight\n",
            " 154: True, auto_model.encoder.layer.9.attention.self.value.bias\n",
            " 155: True, auto_model.encoder.layer.9.attention.output.dense.weight\n",
            " 156: True, auto_model.encoder.layer.9.attention.output.dense.bias\n",
            " 157: True, auto_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            " 158: True, auto_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            " 159: True, auto_model.encoder.layer.9.intermediate.dense.weight\n",
            " 160: True, auto_model.encoder.layer.9.intermediate.dense.bias\n",
            " 161: True, auto_model.encoder.layer.9.output.dense.weight\n",
            " 162: True, auto_model.encoder.layer.9.output.dense.bias\n",
            " 163: True, auto_model.encoder.layer.9.output.LayerNorm.weight\n",
            " 164: True, auto_model.encoder.layer.9.output.LayerNorm.bias\n",
            " 165: True, auto_model.encoder.layer.10.attention.self.query.weight\n",
            " 166: True, auto_model.encoder.layer.10.attention.self.query.bias\n",
            " 167: True, auto_model.encoder.layer.10.attention.self.key.weight\n",
            " 168: True, auto_model.encoder.layer.10.attention.self.key.bias\n",
            " 169: True, auto_model.encoder.layer.10.attention.self.value.weight\n",
            " 170: True, auto_model.encoder.layer.10.attention.self.value.bias\n",
            " 171: True, auto_model.encoder.layer.10.attention.output.dense.weight\n",
            " 172: True, auto_model.encoder.layer.10.attention.output.dense.bias\n",
            " 173: True, auto_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            " 174: True, auto_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            " 175: True, auto_model.encoder.layer.10.intermediate.dense.weight\n",
            " 176: True, auto_model.encoder.layer.10.intermediate.dense.bias\n",
            " 177: True, auto_model.encoder.layer.10.output.dense.weight\n",
            " 178: True, auto_model.encoder.layer.10.output.dense.bias\n",
            " 179: True, auto_model.encoder.layer.10.output.LayerNorm.weight\n",
            " 180: True, auto_model.encoder.layer.10.output.LayerNorm.bias\n",
            " 181: True, auto_model.encoder.layer.11.attention.self.query.weight\n",
            " 182: True, auto_model.encoder.layer.11.attention.self.query.bias\n",
            " 183: True, auto_model.encoder.layer.11.attention.self.key.weight\n",
            " 184: True, auto_model.encoder.layer.11.attention.self.key.bias\n",
            " 185: True, auto_model.encoder.layer.11.attention.self.value.weight\n",
            " 186: True, auto_model.encoder.layer.11.attention.self.value.bias\n",
            " 187: True, auto_model.encoder.layer.11.attention.output.dense.weight\n",
            " 188: True, auto_model.encoder.layer.11.attention.output.dense.bias\n",
            " 189: True, auto_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            " 190: True, auto_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            " 191: True, auto_model.encoder.layer.11.intermediate.dense.weight\n",
            " 192: True, auto_model.encoder.layer.11.intermediate.dense.bias\n",
            " 193: True, auto_model.encoder.layer.11.output.dense.weight\n",
            " 194: True, auto_model.encoder.layer.11.output.dense.bias\n",
            " 195: True, auto_model.encoder.layer.11.output.LayerNorm.weight\n",
            " 196: True, auto_model.encoder.layer.11.output.LayerNorm.bias\n",
            " 197: True, auto_model.pooler.dense.weight\n",
            " 198: True, auto_model.pooler.dense.bias\n",
            " 199: True, attention.0.weight\n",
            " 200: True, attention.0.bias\n",
            " 201: True, attention.2.weight\n",
            " 202: True, attention.2.bias\n",
            " 203: True, regressor.0.weight\n",
            " 204: True, regressor.0.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYPJSbAxMTN7"
      },
      "source": [
        "### StackingModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am2WTaLaMVRQ"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PcTNCYuDeuC"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzoJMxr3DeVG"
      },
      "source": [
        "def bert_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "    \n",
        "    if \"albert-base\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:23]    \n",
        "        attention_parameters = named_parameters[25:29]\n",
        "        regressor_parameters = named_parameters[29:]\n",
        "        second_block = 999\n",
        "        third_block = 999\n",
        "\n",
        "    elif \"base\" in config.model_name or \"L-12\" in config.model_name or \"scibert\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:197]    \n",
        "        attention_parameters = named_parameters[199:203]\n",
        "        regressor_parameters = named_parameters[203:]\n",
        "        second_block = 69\n",
        "        third_block = 133\n",
        "\n",
        "    elif \"large\" in config.model_name or \"L-24\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:388]    \n",
        "        attention_parameters = named_parameters[391:395]\n",
        "        regressor_parameters = named_parameters[395:]\n",
        "        second_block = 133\n",
        "        third_block = 261\n",
        "        \n",
        "    attention_group = [params for (name, params) in attention_parameters]\n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": attention_group})\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(bert_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else config.weight_decay\n",
        "\n",
        "        lr = config.lr\n",
        "\n",
        "        if layer_num >= second_block:        \n",
        "            lr = config.lr_69\n",
        "\n",
        "        if layer_num >= third_block:\n",
        "            lr = config.lr_133\n",
        "\n",
        "        parameters.append({\"params\": params, \"weight_decay\": weight_decay, \"lr\": lr})\n",
        "\n",
        "    return T.AdamW(parameters)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de50761e"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47fcae06"
      },
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-7):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self, yhat, y):\n",
        "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
        "        return loss"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjpp5Rh-4jKW"
      },
      "source": [
        "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
        "class FBetaLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, beta=1.0, epsilon=1e-7):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
        "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
        "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "\n",
        "        beta_squared = self.beta ** 2\n",
        "        fbeta = (1 + beta_squared) * precision * recall / (beta_squared * precision + recall + self.epsilon)\n",
        "        fbeta = fbeta.clamp(min=self.epsilon, max=1-self.epsilon)\n",
        "        return 1 - fbeta.mean()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93661540"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19d9d03c"
      },
      "source": [
        "def get_score(y_true, y_pred, b=border):\n",
        "    y_pred = np.where(y_pred < b, 0, 1)\n",
        "    return fbeta_score(y_true, y_pred, beta=7.0)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1b92d4f"
      },
      "source": [
        "def get_result(result_df, fold=config.n_fold):\n",
        "    preds = result_df[\"preds\"].values\n",
        "    labels = result_df[\"judgement\"].values\n",
        "    score = get_score(labels, preds)\n",
        "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "    # wandb.log({\"fold\": fold, \"CV\": score})\n",
        "    if fold == config.n_fold:\n",
        "        wandb.run.summary[f\"CV\"] = score\n",
        "    else:\n",
        "        wandb.run.summary[f\"CV_fold{fold}\"] = score\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJUo-Mjlv_2"
      },
      "source": [
        "def determine_border(b, y_true, y_pred):\n",
        "    return -1 * get_score(y_true, y_pred, b)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf498df"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5b0e152"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNxJNSgwg-0E"
      },
      "source": [
        "def pre_train_fn():\n",
        "    tokenizer = T.AutoTokenizer.from_pretrained(config.model_name)\n",
        "    model = T.AutoModelForMaskedLM.from_pretrained(config.model_name)\n",
        "\n",
        "    tokenizer.save_pretrained(f\"./pretrained_{config.model_name}\")\n",
        "\n",
        "    train_dataset = T.LineByLineTextDataset(tokenizer=tokenizer, file_path=\"abstracts.txt\", block_size=512)\n",
        "    valid_dataset = T.LineByLineTextDataset(tokenizer=tokenizer, file_path=\"abstracts.txt\", block_size=512)\n",
        "\n",
        "    data_collator = T.DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        "    )\n",
        "\n",
        "    training_args = T.TrainingArguments(\n",
        "        output_dir = f\"./pretrained_{config.model_name}_chk\",\n",
        "        overwrite_output_dir = True,\n",
        "        num_train_epochs = 5,\n",
        "        per_device_train_batch_size = 4,\n",
        "        per_device_eval_batch_size = 4,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        evaluation_strategy = 'steps',\n",
        "        save_total_limit = 2,\n",
        "        eval_steps = 105,\n",
        "        save_steps = 105,\n",
        "        metric_for_best_model = 'eval_loss',\n",
        "        greater_is_better = False,\n",
        "        load_best_model_at_end = True,\n",
        "        prediction_loss_only = True,\n",
        "        report_to = \"wandb\",\n",
        "    )\n",
        "\n",
        "    trainer = T.Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=valid_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    trainer.save_model(f\"./pretrained_{config.model_name}\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99a3bfb5"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "            \n",
        "        if Config.apex:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "\n",
        "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(scheduler, ReduceLROnPlateau):\n",
        "                scheduler.step(avg_val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "            \n",
        "            global_step += 1\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                # f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
        "                f\"LR: {scheduler.get_lr()[0]:.6f}  \"\n",
        "            )\n",
        "\n",
        "    return losses.avg"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "186c441d"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # record score\n",
        "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        preds.append(y_preds.to(\"cpu\").numpy())\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "            )\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7cdfc9"
      },
      "source": [
        "def inference():\n",
        "    predictions = sub.copy()\n",
        "\n",
        "    for n, model_item in enumerate(inference_models):\n",
        "        test_dataset = BaseDataset(test, model_item['model_name'], include_labels=False)\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True\n",
        "        )\n",
        "\n",
        "        preds = []\n",
        "        for fold in range(config.n_fold):\n",
        "            LOGGER.info(f\"========== ID: {model_item['run_id']} model: {model_item['model_name']} fold: {fold} inference ==========\")\n",
        "            model = BaseModel(model_item['model_name'])\n",
        "            model.to(device)\n",
        "            model.load_state_dict(model_item[f\"state_fold{fold}\"])\n",
        "            model.eval()\n",
        "            fold_preds = []\n",
        "            for i, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                with torch.no_grad():\n",
        "                    y_preds = model(input_ids, attention_mask)\n",
        "                # avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "                fold_preds.append(y_preds.to(\"cpu\").numpy())\n",
        "            preds.append(np.concatenate(fold_preds))\n",
        "\n",
        "        preds = np.mean(preds, axis=0)\n",
        "\n",
        "        if config.criterion == \"BCEWithLogitsLoss\":\n",
        "            preds = 1 / (1 + np.exp(-preds))\n",
        "\n",
        "        predictions[f\"preds{n}\"] = preds\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuZncamGqu8I"
      },
      "source": [
        "def stacking_inference():\n",
        "    feature_cols = [col for col in test.columns if col.startswith(\"preds\")]\n",
        "    # predictions = sub.copy()\n",
        "\n",
        "    preds = []\n",
        "    for fold in range(config.n_fold):\n",
        "        LOGGER.info(f\"========== fold: {fold} inference ==========\")\n",
        "        bst = lgb.Booster(model_file=OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\")\n",
        "        fold_preds = bst.predict(test[feature_cols])\n",
        "        preds.append(fold_preds)\n",
        "\n",
        "    preds = np.mean(preds, axis=0)\n",
        "    # predictions[f\"preds\"] = preds\n",
        "\n",
        "    return preds"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9663c1"
      },
      "source": [
        "## Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357969e6"
      },
      "source": [
        "def train_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BaseDataset(train_folds, config.model_name)\n",
        "    valid_dataset = BaseDataset(valid_folds, config.model_name)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Optimizer\n",
        "    # ====================================================\n",
        "    def get_optimizer(model):\n",
        "        if config.optimizer == \"Adam\":\n",
        "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay, amsgrad=False)\n",
        "        elif config.optimizer == \"AdamW\":\n",
        "            optimizer = T.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "        elif config.optimizer == \"BertAdamW\":\n",
        "            optimizer = bert_optimizer(model)\n",
        "        return optimizer\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        if config.scheduler == \"ReduceLROnPlateau\":\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=config.factor, patience=config.patience, verbose=True, eps=config.eps\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=config.T_max, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(\n",
        "                optimizer, T_0=config.T_0, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
        "            scheduler = CosineAnnealingWarmupRestarts(\n",
        "                optimizer, first_cycle_steps=config.first_cycle_steps, max_lr=config.lr, min_lr=config.min_lr, warmup_steps=config.warmup_steps\n",
        "            )\n",
        "        elif config.scheduler == \"get_cosine_schedule_with_warmup\":\n",
        "            scheduler = T.get_cosine_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_training_steps=config.num_training_steps, \n",
        "                num_warmup_steps=config.num_warmup_steps\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # Model\n",
        "    # ====================================================\n",
        "    model = BaseModel(config.model_name)\n",
        "    model.to(device)\n",
        "\n",
        "    # Use multi GPU\n",
        "    if device == torch.device(\"cuda\") and not Config.apex and Config.multi_gpu:\n",
        "        model = torch.nn.DataParallel(model)  # make parallel\n",
        "        # torch.backends.cudnn.benchmark=True\n",
        "\n",
        "    optimizer = get_optimizer(model)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # Apex\n",
        "    # ====================================================\n",
        "    if Config.apex:\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "        elif config.criterion == \"MSELoss\":\n",
        "            criterion = nn.MSELoss()\n",
        "        elif config.criterion == \"RMSELoss\":\n",
        "            criterion = RMSELoss()\n",
        "        elif config.criterion == \"FBetaLoss\":\n",
        "            criterion = FBetaLoss(7.0)\n",
        "\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "    best_score = -1\n",
        "    best_loss = np.inf\n",
        "    best_preds = None\n",
        "\n",
        "    # if not Config.multi_gpu:\n",
        "    #     wandb.watch(model, log_freq=Config.print_freq)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
        "        valid_labels = valid_folds[\"judgement\"].values\n",
        "\n",
        "        # if isinstance(scheduler, ReduceLROnPlateau):\n",
        "        #     scheduler.step(avg_val_loss)\n",
        "        # else:\n",
        "        #     scheduler.step()\n",
        "\n",
        "        if config.criterion == \"BCEWithLogitsLoss\":\n",
        "            preds = 1 / (1 + np.exp(-preds))\n",
        "\n",
        "        # scoring\n",
        "        # score = get_score(valid_labels, preds.argmax(1))\n",
        "        score = get_score(valid_labels, preds)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(\n",
        "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
        "        )\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
        "\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                f\"loss/train_fold{fold}\": avg_loss,\n",
        "                f\"loss/val_fold{fold}\": avg_val_loss,\n",
        "                f\"score/fold{fold}\": score,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if (\n",
        "            (config.best == \"score\" and score > best_score)\n",
        "            or (config.best == \"loss\" and avg_val_loss < best_loss)\n",
        "        ):\n",
        "            best_score = score\n",
        "            best_loss = avg_val_loss\n",
        "            best_preds = preds\n",
        "\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model (Loss: {best_loss:.4f})\")\n",
        "            wandb.run.summary[f\"loss_fold{fold}\"] = score\n",
        "\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\"\n",
        "            )\n",
        "            wandb.save(OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "        # if epoch == config.epochs - 1:\n",
        "        #     LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
        "        #     torch.save(\n",
        "        #         {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name}_fold{fold}_final.pth\"\n",
        "        #     )\n",
        "\n",
        "    check_point = torch.load(OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "    if config.n_class == 1:\n",
        "        valid_folds[\"preds\"] = best_preds\n",
        "    else:\n",
        "        valid_folds[[str(c) for c in range(config.n_class)]] = best_preds\n",
        "        valid_folds[\"preds\"] = best_preds.argmax(1)\n",
        "\n",
        "    return valid_folds"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8mXDD4u0G3R"
      },
      "source": [
        "## Stack loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VejK7F2hzIsK"
      },
      "source": [
        "def stack_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # ====================================================\n",
        "    # Dataset\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    feature_cols = [col for col in df.columns if col.startswith(\"preds\")]\n",
        "    label_cols = [\"judgement\"]\n",
        "\n",
        "    train_dataset = lgb.Dataset(data=train_folds[feature_cols], label=train_folds[label_cols], free_raw_data=False)\n",
        "    valid_dataset = lgb.Dataset(data=valid_folds[feature_cols], label=valid_folds[label_cols], free_raw_data=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # Parameters\n",
        "    # ====================================================\n",
        "\n",
        "    lgb_params = {\n",
        "        \"objective\": config.objective,\n",
        "        \"metric\": config.criterion,\n",
        "        \"num_class\": config.n_class,\n",
        "        \"device_type\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "        \"seed\": seed + fold,\n",
        "        \"verbosity\": -1,\n",
        "    }\n",
        "\n",
        "    if not Config.stack_optuna:\n",
        "        lgb_params_manual = {\n",
        "            \"learning_rate\": config.lr,\n",
        "            \"max_depth\": config.max_depth,\n",
        "            \"num_leaves\": config.num_leaves,\n",
        "            \"min_data_in_leaf\": config.min_data_in_leaf,\n",
        "            \"drop_rate\": config.dropout,\n",
        "        }\n",
        "        lgb_params.update(lgb_params_manual)\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "\n",
        "    evaluation_results = {}\n",
        "    clf = lgb.train(\n",
        "        params=lgb_params,\n",
        "        train_set=train_dataset,\n",
        "        num_boost_round=10000,\n",
        "        valid_sets=[train_dataset, valid_dataset], \n",
        "        valid_names=['train', 'eval'],\n",
        "        early_stopping_rounds=100,\n",
        "        evals_result=evaluation_results,\n",
        "        verbose_eval=100,\n",
        "    )\n",
        "\n",
        "    importances = pd.DataFrame({\n",
        "        'features': clf.feature_name(),\n",
        "        'importance': clf.feature_importance()\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    preds = clf.predict(valid_folds[feature_cols], num_iteration=clf.best_iteration)\n",
        "    valid_labels = valid_folds[\"judgement\"].values\n",
        "\n",
        "    if Config.stack_optuna:\n",
        "        LOGGER.info(f\"Best Params {fold} - {clf.params}\")\n",
        "\n",
        "    # scoring\n",
        "    if config.n_class == 1:\n",
        "        score = get_score(valid_labels, preds)\n",
        "    else:\n",
        "        score = get_score(valid_labels, preds.argmax(1))\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    LOGGER.info(f\"Result {fold} - Score: {score}, time: {elapsed:.0f}s\")\n",
        "\n",
        "    LOGGER.info(f\"Result {fold} - Save Best Model\")\n",
        "    # wandb.run.summary[f\"loss_fold{fold}\"] = score\n",
        "\n",
        "    clf.save_model(OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\", clf.best_iteration)\n",
        "    wandb.save(OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\")\n",
        "\n",
        "    if config.n_class == 1:\n",
        "        valid_folds[\"preds\"] = preds\n",
        "    else:\n",
        "        valid_folds[[str(c) for c in range(config.n_class)]] = preds\n",
        "        valid_folds[\"preds\"] = preds.argmax(1)\n",
        "\n",
        "    return valid_folds"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97b42fa3"
      },
      "source": [
        "## Main\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5baf150d"
      },
      "source": [
        "def main():\n",
        "    # ====================================================\n",
        "    # Pre Training\n",
        "    # ====================================================\n",
        "    if Config.pre_train:\n",
        "        abstract_df = pd.concat([train[\"abstract\"], test[\"abstract\"]])\n",
        "        abstracts  = '\\n'.join(abstract_df.tolist())\n",
        "        with open(\"abstracts.txt\", \"w\") as f:\n",
        "            f.write(abstracts)\n",
        "\n",
        "        pre_train_fn()\n",
        "\n",
        "    # ====================================================\n",
        "    # Training\n",
        "    # ====================================================\n",
        "    if Config.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df = train_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "            \n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        \n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Validation\n",
        "    # ====================================================\n",
        "    if Config.validate:\n",
        "        probs = []\n",
        "        borders = []\n",
        "        class_cols = []\n",
        "\n",
        "        for n in range(len(config.inference_runs)):\n",
        "            probs.append(train[f\"preds{n}\"].values)\n",
        "\n",
        "            if config.border == \"minimize\":\n",
        "                res = sp.optimize.minimize_scalar(\n",
        "                    determine_border,\n",
        "                    method='bounded',\n",
        "                    bounds=(0, 1),\n",
        "                    args=(train[\"judgement\"].values, train[f\"preds{n}\"].values)\n",
        "                )\n",
        "                b = res.x\n",
        "\n",
        "                # CV result\n",
        "                LOGGER.info(f\"========== Border Optimization ==========\")\n",
        "                LOGGER.info(f\"Border: {b:<.5f}, Score: {-res.fun:<.5f}\")\n",
        "\n",
        "            else:\n",
        "                raise f\"Invalid config.border parameter: {config.border}\"\n",
        "\n",
        "            borders.append(b)\n",
        "            class_cols.append(f\"class_preds{n}\")\n",
        "            train[f\"class_preds{n}\"] = np.where(train[f\"preds{n}\"].values < b, 0, 1)\n",
        "\n",
        "        train[\"voting\"] = train[class_cols].sum(axis=1)\n",
        "        train[\"preds\"] = np.where(train[\"voting\"].values < len(config.inference_runs) / 2, 0, 1)\n",
        "\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(train)\n",
        "\n",
        "        # save result\n",
        "        train.to_csv(OUTPUT_DIR + \"validation_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"validation_df.csv\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Inference\n",
        "    # ====================================================\n",
        "    if Config.inference:\n",
        "        prediction_df = inference()\n",
        "\n",
        "        probs = []\n",
        "        for n in range(len(config.inference_runs)):\n",
        "            probs.append(prediction_df[f\"preds{n}\"].values)\n",
        "\n",
        "            prediction_df[f\"class_preds{n}\"] = np.where(prediction_df[f\"preds{n}\"].values < borders[n], 0, 1)\n",
        "\n",
        "        prediction_df[\"voting\"] = prediction_df[class_cols].sum(axis=1)\n",
        "        prediction_df[\"preds\"] = np.where(prediction_df[\"voting\"].values < len(config.inference_runs) / 2, 0, 1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = prediction_df[\"preds\"]  # .argmax(1)\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n",
        "\n",
        "        prediction_df.to_csv(OUTPUT_DIR + \"prediction_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"prediction_df.csv\")\n",
        "        \n",
        "    # ====================================================\n",
        "    # Stack\n",
        "    # ====================================================\n",
        "    if Config.stack:\n",
        "        # Training\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df = stack_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "\n",
        "        # CV result\n",
        "        if config.n_class > 1 or config.border == \"fixed\":\n",
        "            # CV result\n",
        "            LOGGER.info(f\"========== CV ==========\")\n",
        "            get_result(oof_df)\n",
        "            b = border\n",
        "\n",
        "        elif config.border == \"minimize\":\n",
        "            res = sp.optimize.minimize_scalar(determine_border, method='bounded', bounds=(0, 1), args=(oof_df[\"judgement\"].values, oof_df[\"preds\"].values))\n",
        "            LOGGER.info(f\"========== CV: Border Optimization ==========\")\n",
        "            LOGGER.info(f\"Border: {res.x:<.5f}, Score: {-res.fun:<.5f}\")\n",
        "            wandb.run.summary[f\"CV\"] = -res.fun\n",
        "            b = res.x\n",
        "\n",
        "        if config.n_class == 1:\n",
        "            wandb.run.summary[f\"border\"] = b\n",
        "\n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"stacking_oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"stacking_oof_df.csv\")\n",
        "\n",
        "        # Inference\n",
        "        preds = stacking_inference()\n",
        "\n",
        "        if config.n_class == 1:\n",
        "            predictions = np.where(preds < b, 0, 1)\n",
        "        else:\n",
        "            predictions = preds.argmax(1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = predictions\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n",
        "\n",
        "        if config.n_class == 1:\n",
        "            sub[\"preds\"] = preds\n",
        "        else:\n",
        "            sub[[str(c) for c in range(config.n_class)]] = preds\n",
        "            sub[\"preds\"] = preds.argmax(1)\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"stacking_prediction_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"stacking_prediction_df.csv\")\n",
        "                \n",
        "    # ====================================================\n",
        "    # Ensemble\n",
        "    # ====================================================\n",
        "    if Config.ensemble:\n",
        "        cols = [c for c in train.columns if c.startswith(\"preds\") and c != \"preds\"]\n",
        "\n",
        "        train[\"voting\"] = train[cols].sum(axis=1)\n",
        "        train[\"preds\"] = np.where(train[\"voting\"].values < len(cols) / 2, 0, 1)\n",
        "\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(train)\n",
        "\n",
        "        test[\"voting\"] = test[cols].sum(axis=1)\n",
        "        test[\"preds\"] = np.where(test[\"voting\"].values < len(cols) / 2, 0, 1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = test[\"preds\"]  # .argmax(1)\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n",
        "\n",
        "        test.to_csv(OUTPUT_DIR + \"prediction_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"prediction_df.csv\")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "726e744f",
        "outputId": "87dff0bb-ba85-41e1-f445-deef14ba01ca"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== CV ==========\n",
            "Score: 0.94347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    37914\n",
            "1     2920\n",
            "Name: judgement, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "43e865fc6c3146399251db6e4fbf78bb",
            "3da8586149994392ae99542643573d39",
            "243d167efa3541cdbd46478ec4a3a796",
            "e340bccf48dc425cb99999bf48352a9c",
            "20d61c909cc04aa883e5792c2d5faf3d",
            "cb69290873404305a9c3c8f3fc1cef65",
            "6f0a9cb69c594f5ba3eac74efb6c2f0c",
            "f6722884bac74a6d881962f27bcc2f9a"
          ]
        },
        "id": "CPHezhr_NHYR",
        "outputId": "8ba7b940-c942-42e6-f4d4-ec6de17717ed"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3359<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43e865fc6c3146399251db6e4fbf78bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 112.88MB of 112.88MB uploaded (0.18MB deduped)\\r'), FloatProgress(value=1.0, max=…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210907_011149-2di2sp58/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210907_011149-2di2sp58/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>CV</td><td>0.94347</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 47 artifact file(s) and 3 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">still-dew-85</strong>: <a href=\"https://wandb.ai/ponkots/signate-471/runs/2di2sp58\" target=\"_blank\">https://wandb.ai/ponkots/signate-471/runs/2di2sp58</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-scfhV4ueW4K"
      },
      "source": [
        "## Public LB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNsH2CvA1He"
      },
      "source": [
        "RUN_PATH = \"ponkots/signate-471/2di2sp58\"\n",
        "LB_SCORE = 0.9170040485829959"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS7aRYF_eh7z"
      },
      "source": [
        "if LB_SCORE is not None:\n",
        "    import wandb\n",
        "    api = wandb.Api()\n",
        "\n",
        "    run = api.run(RUN_PATH)\n",
        "    run.summary[\"LB\"] = LB_SCORE\n",
        "    run.summary.update()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANpuUeypNmLF"
      },
      "source": [
        ""
      ],
      "execution_count": 72,
      "outputs": []
    }
  ]
}