{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "医学論文の自動仕分けチャレンジ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a8d50389dea45f7b94652df677d2a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ab45bc32abb4110b7bffc8042a55648",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_216bec62b1e74fea8bbddca167240fab",
              "IPY_MODEL_2fb794b57ba8487d869d49e443362b22",
              "IPY_MODEL_81a61033a796439c97cbdd7a37670f27"
            ]
          }
        },
        "4ab45bc32abb4110b7bffc8042a55648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "216bec62b1e74fea8bbddca167240fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_05953a1501d044cf8037fa69366d11df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ace466f23ab45d48ae1f7a412f95416"
          }
        },
        "2fb794b57ba8487d869d49e443362b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a30ac326d9d94c1298ad2f0b6a305d2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3403,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3403,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92a5c3fc458644579c7571ed95208d76"
          }
        },
        "81a61033a796439c97cbdd7a37670f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9483f04f06c7419cae60ad4e85c26bb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3403/3403 [06:47&lt;00:00,  8.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_402be2621625424fbf3b4cb08a32d459"
          }
        },
        "05953a1501d044cf8037fa69366d11df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ace466f23ab45d48ae1f7a412f95416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a30ac326d9d94c1298ad2f0b6a305d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92a5c3fc458644579c7571ed95208d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9483f04f06c7419cae60ad4e85c26bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "402be2621625424fbf3b4cb08a32d459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f21d55281c84ad680d0d92701db4c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a84b48721a2146c680cd6cb07f5d87f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f24eec12f6249b9975ba039bc1e1802",
              "IPY_MODEL_185550b3401e466495a9a997e8a4de08",
              "IPY_MODEL_1d2643b73c424e689bf18d80c9711315"
            ]
          }
        },
        "a84b48721a2146c680cd6cb07f5d87f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f24eec12f6249b9975ba039bc1e1802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f4a992c673e4f8298353155b21ac3ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23a1023882d640c593b9f235d442f643"
          }
        },
        "185550b3401e466495a9a997e8a4de08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba61cf57c0224b6e892c1a0c93ee4308",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3403,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3403,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d90490f83fae42d4bbbd16c1ee692cba"
          }
        },
        "1d2643b73c424e689bf18d80c9711315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa46ef39cbbb4ea28b0766dd6f0baa66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3403/3403 [06:47&lt;00:00,  8.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32697224365b4f17b89e6893d9416460"
          }
        },
        "6f4a992c673e4f8298353155b21ac3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23a1023882d640c593b9f235d442f643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba61cf57c0224b6e892c1a0c93ee4308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d90490f83fae42d4bbbd16c1ee692cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa46ef39cbbb4ea28b0766dd6f0baa66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32697224365b4f17b89e6893d9416460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "810ce31e825545689d25d7560454805e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ea437e74cf646078eea34c31441b605",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_557faa340e3f4577ada31dd183614bf2",
              "IPY_MODEL_04a1c6ae27eb485ebb8c48a69f07f63f",
              "IPY_MODEL_eec1a153f4c94a338e05120cfffe3ed0"
            ]
          }
        },
        "5ea437e74cf646078eea34c31441b605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "557faa340e3f4577ada31dd183614bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c6eac2043634994b83fd92a5344e44c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79f56ebd16e5448babf2c2e529463c98"
          }
        },
        "04a1c6ae27eb485ebb8c48a69f07f63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f9a20b671954431892ce65ad33b5eb7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3403,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3403,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c140c5b2fa24ba3a0dc0227f5bb012b"
          }
        },
        "eec1a153f4c94a338e05120cfffe3ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f731650f31d40819a08dac9ebebafe2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3403/3403 [06:47&lt;00:00,  8.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f4b395c63d645659af04d01b498af9f"
          }
        },
        "1c6eac2043634994b83fd92a5344e44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79f56ebd16e5448babf2c2e529463c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f9a20b671954431892ce65ad33b5eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c140c5b2fa24ba3a0dc0227f5bb012b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f731650f31d40819a08dac9ebebafe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f4b395c63d645659af04d01b498af9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f11fbbdca4b843bd9333f4bb9cfff551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_70dd66973ccf47f680bd67a12689cd8b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b6dfe5b0bb0469fa069a35af4e95173",
              "IPY_MODEL_49ba582c6913449f923350bebadaedaf",
              "IPY_MODEL_8f76c266aa2347f8a17f84bb38b7c924"
            ]
          }
        },
        "70dd66973ccf47f680bd67a12689cd8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b6dfe5b0bb0469fa069a35af4e95173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81c02dc5926b44b9bd21a776dd5355be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f335418c9ad54743aac05d7bca55dfd6"
          }
        },
        "49ba582c6913449f923350bebadaedaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_59af51e484854399bb51889cde0b827e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3403,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3403,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96c32a8687f641ce952e5c22d0f874fe"
          }
        },
        "8f76c266aa2347f8a17f84bb38b7c924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2f9101587c34350b1133c938e00c917",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3403/3403 [06:47&lt;00:00,  8.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bfbce35b4734b1db15f35cd26ed58b6"
          }
        },
        "81c02dc5926b44b9bd21a776dd5355be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f335418c9ad54743aac05d7bca55dfd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59af51e484854399bb51889cde0b827e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96c32a8687f641ce952e5c22d0f874fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2f9101587c34350b1133c938e00c917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bfbce35b4734b1db15f35cd26ed58b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3742439a25194100ad57c4403a640861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bba4aeb9f64e4a4982114ca6df74cac8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13abde03a1fc47dca838adac0eea7981",
              "IPY_MODEL_dc55445b4ae7474687d27c1200ea4917",
              "IPY_MODEL_d150a39610514740a37250bd931152f6"
            ]
          }
        },
        "bba4aeb9f64e4a4982114ca6df74cac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13abde03a1fc47dca838adac0eea7981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_80fcd8f206a643f398f5bbd2a216c5c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a24945ff02b439c97f4f61e8824322f"
          }
        },
        "dc55445b4ae7474687d27c1200ea4917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_450e50ae650a487895a64191eb8b66d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3403,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3403,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9430e9e57b1b46f6980a7c76523ee8dc"
          }
        },
        "d150a39610514740a37250bd931152f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_330137091550422e8ced598c1f48dcf1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3403/3403 [06:47&lt;00:00,  8.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67cc3097e2e4401896f1e20464d6637c"
          }
        },
        "80fcd8f206a643f398f5bbd2a216c5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a24945ff02b439c97f4f61e8824322f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "450e50ae650a487895a64191eb8b66d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9430e9e57b1b46f6980a7c76523ee8dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "330137091550422e8ced598c1f48dcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67cc3097e2e4401896f1e20464d6637c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba4e10a3e7f54f8798b2ded6051497ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50c79b914cd24e0a9b53d2cf5588cff5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e947eb7ca8594698b67559323e3d13c0",
              "IPY_MODEL_4c9cb27b6b0e4fe18082f7fa3a3929f0"
            ]
          }
        },
        "50c79b914cd24e0a9b53d2cf5588cff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e947eb7ca8594698b67559323e3d13c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_52bf12190fef4733bf66d320951b4de9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 78.83MB of 78.83MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c8a29529e7b424cbe422574c39e1f98"
          }
        },
        "4c9cb27b6b0e4fe18082f7fa3a3929f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd10742a8e8b4b6c855dcfc9bf205d34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f98e0cf04fa4ef19c62be6802568f40"
          }
        },
        "52bf12190fef4733bf66d320951b4de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c8a29529e7b424cbe422574c39e1f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd10742a8e8b4b6c855dcfc9bf205d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f98e0cf04fa4ef19c62be6802568f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/signate-471/blob/main/%E5%8C%BB%E5%AD%A6%E8%AB%96%E6%96%87%E3%81%AE%E8%87%AA%E5%8B%95%E4%BB%95%E5%88%86%E3%81%91%E3%83%81%E3%83%A3%E3%83%AC%E3%83%B3%E3%82%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e4660c1"
      },
      "source": [
        "# About this notebook ...\n",
        "\n",
        "competition site: https://signate.jp/competitions/471\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dhs2SIWJzKz"
      },
      "source": [
        "## ToDo\n",
        "\n",
        "- [ ] pre train のモデルの save と load\n",
        "- [ ] preprocess したデータの save と load (wandb)\n",
        "- [ ] optune の seed 固定 https://book-read-yoshi.hatenablog.com/entry/2021/03/22/lightgbm_optuna_deterministic\n",
        "\n",
        "### Idea\n",
        "\n",
        "- [x] [ラベル判定結果の誤りに関するお知らせ](https://signate.jp/competitions/471/discussions/20210816152356-59) をとりこむ \n",
        "- [x] 分類で推論、回帰で推論\n",
        "- [x] 回帰の場合の境界値の最適化\n",
        "    - [x] second stage で学習べきかも\n",
        "        - [ ] heamy という stacking のライブラリがある\n",
        "        - [ ] CNN で stacking がいいかもしれない https://tawara.hatenablog.com/entry/2020/12/16/132415\n",
        "            - 縦・横、チャネル数が、クラス数（１）・モデル数（ｎ）・１で、 1xn で畳み込む \n",
        "        - [x] lightGBM\n",
        "    - [ ] Nelder-Mead 法 という最適化手法を調べる\n",
        "- [ ] 最適な境界値はモデルによって異なるので、アンサンブルの時は、 vote ensemble がいいかもしれない\n",
        "- [x] アブストで事前学習して、タイトルでメイン学習 https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n",
        "    - 事前学習は、Masked LM\n",
        "- [x] タイトルだけで学習・推論\n",
        "- [ ] タイトル + アブストで学習・推論\n",
        "    - [ ] タイトルだけで推論したのとアンサンブルができる\n",
        "    - [ ] Longformer がいいかもしれない `allenai/longformer-base-4096`\n",
        "    - [ ] large モデルためす\n",
        "- [ ] アブスト + タイトル で学習・推論\n",
        "- [ ] アブストが空 or not でモデルわける\n",
        "- [ ] アブストの max length 調整\n",
        "    - [ ] 途中で切る。デフォルトの 512 はありそう。ほとんどのアブストがその長さで収まる\n",
        "    - [ ] 要約する方法があるかなぁ\n",
        "- [x] dropout を 0 にする\n",
        "- [x] gradient cripping を 0.2 or 0.5 で試す\n",
        "- [ ] re-initialization\n",
        "    - This paper (https://arxiv.org/pdf/2006.05987.pdf) shows that fine-tuning with reinitialization last N layers works well.\n",
        "    - Different models have different optimal N. Almost models set N=4~5, gpt2-models set N=6.\n",
        "    - https://github.com/kurupical/commonlit/blob/8781139c8ed4cc59f7c7ac9d97c72c351ee91377/exp/exp502.py#L497\n",
        "- [ ] Pre trained なレイヤーのfreeze https://raphaelb.org/posts/freezing-bert/\n",
        "- [ ] Recall を伸ばすための loss function は考えられるか。 https://openreview.net/pdf?id=SlprFTIQP3\n",
        "    - [x] f1 score を微分可能にして、 loss 関数に使うアプローチ https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354 https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d\n",
        "    - [ ] epoch ごとに beta の値を増やしていく epoch * 2 とか\n",
        "- [ ] 出現する単語のクラスタリング\n",
        "- [x] TF-IDF して、 リッジ回帰 → ベースライン2 でやった\n",
        "    - IF-IDF の結果もBERTの特徴量にできないだろうか\n",
        "    - https://www.kaggle.com/semyonkoshkarov/tf-idf-linearsvr-baseline も参考になるかも\n",
        "- [ ] 医療用語で事前学習されたモデルを使ってみる\n",
        "    - [x] BioBERT https://github.com/dmis-lab/biobert `dmis-lab/biobert-base-cased-v1.1` 286k downloads\n",
        "        - [ ] large モデル試す\n",
        "    - [ ] Med-BERT https://github.com/ZhiGroup/Med-BERT\n",
        "        - 診断精度に貢献しているかもしれない(いや、一般的な話だったｗ) https://www.nature.com/articles/s41746-021-00455-y\n",
        "    - [x] `microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext` 30.8k downloads https://www.axion.zone/microsoft-researchers-claim-state-of-the-art-biomedical-nlp-model/\n",
        "    - [x] `bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12` 4.3k downloads https://github.com/ncbi-nlp/bluebert\n",
        "        - [ ] large モデル試す\n",
        "    - [x] `emilyalsentzer/Bio_ClinicalBERT` https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n",
        "    - [ ] `emilyalsentzer/Bio_Discharge_Summary_BERT` https://huggingface.co/emilyalsentzer/Bio_Discharge_Summary_BERT\n",
        "    - [x] `lordtt13/COVID-SciBERT` https://huggingface.co/lordtt13/COVID-SciBERT\n",
        "    - [x] `allenai/scibert_scivocab_uncased` https://huggingface.co/allenai/scibert_scivocab_uncased\n",
        "- [ ] Augmentation https://neptune.ai/blog/data-augmentation-nlp\n",
        "    - [ ] Back translation: 他言語に翻訳して、もう一回翻訳する（英語→フランス語→英語） https://qiita.com/nena0undefined/items/c2926bad07039e5540ab\n",
        "        - [ ] ラベル 1 のだけやって、学習データに追加する\n",
        "    - [ ] Synonym Replacement: 単語のいくつかを、同じ意味の別の単語に置き換える\n",
        "        - [ ] 自然言語の augmentation ができるライブラリ https://github.com/makcedward/nlpaug\n",
        "- [ ] TTA\n",
        "- [ ] ベースラインのシンプルさを取り戻す。(思ったよりベースラインのスコアが良かったので、それを取り込む・・・）\n",
        "    - [ ] weight decay を調整 0.01 or 0\n",
        "\n",
        "\n",
        "### Experiments\n",
        "\n",
        "- BERT でアブストの　pre train をしてもスコアは上がっていない（学習の方法を工夫した方がよいかも）\n",
        "- BERT Large は title の学習には大きすぎて？ loss が Base モデルに及ばない。\n",
        "- epoch 3 で val loss が下がらないので、 epoch 3 で aug かけるとかありかもしれない\n",
        "- `dmis-lab/biobert-base-cased-v1.1` と `bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12` の成績がよい\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68842c71"
      },
      "source": [
        "## Prepare for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14137a0f",
        "outputId": "92f2b323-713c-46e7-afde-0194399a2fbd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep  5 16:00:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    48W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4871daf1",
        "outputId": "42a11277-2646-47d2-8819-71fa816ba2a4"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if os.path.exists('init.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    if 'google.colab' in sys.modules:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        !cp /content/drive/MyDrive/Datasets/signate-471/train.csv .\n",
        "        !cp /content/drive/MyDrive/Datasets/signate-471/test.csv .\n",
        "        !cp /content/drive/MyDrive/Datasets/signate-471/sample_submit.csv .\n",
        "\n",
        "    # for StratifiedGroupKFold\n",
        "    # !pip uninstall -y scikit-learn\n",
        "    # !pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn\n",
        "\n",
        "    # for MultilabelStratifiedKFold\n",
        "    !pip install -q iterative-stratification\n",
        "\n",
        "    # !pip install -qU 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n",
        "\n",
        "    !pip install -q wandb\n",
        "    !pip install -q optuna\n",
        "\n",
        "    !pip install -q transformers\n",
        "    !pip install -q textstat\n",
        "    !pip install -q nlpaug\n",
        "\n",
        "    # https://qiita.com/_yushuu/items/83c51e29771530646659\n",
        "    # !pip install -q googletrans==4.0.0-rc1\n",
        "\n",
        "    !touch init.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkZ4bEVgUxxa",
        "outputId": "07310fc5-1b79-4302-961b-e079e8700217"
      },
      "source": [
        "# Install_LightGBM_with_GPU\n",
        "\n",
        "if os.path.exists('init_lightgbm.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    ! git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "\n",
        "    %cd /content/LightGBM\n",
        "    ! mkdir -p build\n",
        "\n",
        "    %cd build\n",
        "    ! cmake -DUSE_GPU=1 /content/LightGBM\n",
        "    ! make -j$(nproc)\n",
        "    ! sudo apt-get -y install python-pip\n",
        "    ! sudo -H pip install setuptools numpy scipy scikit-learn -U\n",
        "    ! sudo -H pip install pandas==1.3.0\n",
        "\n",
        "    %cd /content/LightGBM/python-package\n",
        "    ! sudo python setup.py install --precompile\n",
        "\n",
        "    %cd /content/\n",
        "\n",
        "    !touch init_lightgbm.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c39b7222"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63096cb"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# import lightgbm as lgb\n",
        "# import optuna.integration.lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "import textstat\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers as T\n",
        "import wandb\n",
        "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
        "# from googletrans import Translator\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, fbeta_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold  # , StratifiedGroupKFold\n",
        "from torch.optim import SGD, Adam  # , AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c830faec"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16eb8ed5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cZeQJ7Xw7d8",
        "outputId": "5682fcbc-b977-4d3e-9128-7212cb1fabdd"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc53e8c",
        "outputId": "2ba8eb6b-5b4d-4482-fddb-e84d920c6ff4"
      },
      "source": [
        "netrc = \"../input/wandbtoken/.netrc\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    netrc = \"/content/drive/MyDrive/.netrc\"\n",
        "\n",
        "!cp -f {netrc} ~/\n",
        "\n",
        "!wandb login"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB5QkUQJq_6U"
      },
      "source": [
        "wandb_job_type = \"\"\n",
        "wandb_notes = \"\"\n",
        "wandb_tags = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71d9ccbd"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a62a05f"
      },
      "source": [
        "DATA_DIR = \"../input/signate-471/\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_DIR = \"./\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26350797"
      },
      "source": [
        "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
        "sub = pd.read_csv(DATA_DIR + \"sample_submit.csv\", header=None)\n",
        "sub.columns = [\"id\", \"judgement\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7ef06f8"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0177571"
      },
      "source": [
        "class Config:\n",
        "    wandb_entity = \"ponkots\"\n",
        "    wandb_project = \"signate-471\"\n",
        "    print_freq = 100\n",
        "\n",
        "    pre_train = False\n",
        "    train = False\n",
        "    validate = True\n",
        "    inference = True\n",
        "    stack = False\n",
        "    stack_optuna = False\n",
        "    ensemble = False\n",
        "\n",
        "    debug = False\n",
        "    multi_gpu = False\n",
        "    apex = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxS_DM-WpMv8"
      },
      "source": [
        "if Config.stack_optuna:\n",
        "    import optuna.integration.lightgbm as lgb\n",
        "else:\n",
        "    import lightgbm as lgb"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a195fe0"
      },
      "source": [
        "if Config.pre_train:\n",
        "    wandb_job_type = \"pre_training\"\n",
        "\n",
        "elif Config.train:\n",
        "    wandb_job_type = \"training\"\n",
        "\n",
        "elif Config.inference:\n",
        "    wandb_job_type = \"inference\"\n",
        "\n",
        "elif Config.validate:\n",
        "    wandb_job_type = \"validation\"\n",
        "\n",
        "elif Config.stack:\n",
        "    wandb_job_type = \"stacking\"\n",
        "\n",
        "elif Config.ensemble:\n",
        "    wandb_job_type = \"ensemble\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccb61787"
      },
      "source": [
        "if Config.apex:\n",
        "    from apex import amp"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWDHvHvNxoD3",
        "outputId": "60f247d2-0437-4453-df59-6809cec9a7ab"
      },
      "source": [
        "# seed = random.randrange(10000)\n",
        "seed = 440\n",
        "\n",
        "print(seed)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daf057a9"
      },
      "source": [
        "config_defaults = {\n",
        "    \"seed\": seed,\n",
        "    \"input\": \"title_abstract\",\n",
        "    \"max_len\": 512,\n",
        "    \"border\": \"minimize\",\n",
        "    \"n_class\": 1,\n",
        "    \"n_fold\": 5,\n",
        "    \"gradient_accumulation_steps\": 2,\n",
        "    \"max_grad_norm\": 1000,\n",
        "    \"num_workers\": 4,\n",
        "    \"batch_size\": 12,\n",
        "    \"epochs\": 3,\n",
        "    \"optimizer\": \"BertAdamW\",\n",
        "    \"scheduler\": \"get_cosine_schedule_with_warmup\",\n",
        "    \"criterion\": \"BCEWithLogitsLoss\",  # \"FBetaLoss\",  # \"BCEWithLogitsLoss\",\n",
        "    \"lr\": 2e-5,\n",
        "    \"min_lr\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"dropout\": 0.1,\n",
        "    \"model_name\": \"dmis-lab/biobert-base-cased-v1.1-squad\",\n",
        "    \"reinit_layers\": 0,\n",
        "    \"freeze_layers\": 0,\n",
        "    \"best\": \"loss\",  # \"score\",\n",
        "    \"inference_runs\": [\n",
        "        \"1ostvjfa\",\n",
        "    ],\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFOA0aiExa5R"
      },
      "source": [
        "if Config.stack:\n",
        "    config_stack = {\n",
        "        \"objective\": \"binary\" if config_defaults[\"n_class\"] == 1 else \"multiclass\",\n",
        "        \"criterion\": \"binary_logloss\" if config_defaults[\"n_class\"] == 1 else \"multi_logloss\",\n",
        "    }\n",
        "    config_defaults.update(config_stack)\n",
        "\n",
        "    if not Config.stack_optuna:\n",
        "        config_stack_manual = {\n",
        "            \"lr\": 0.01,\n",
        "            \"max_depth\": 7,\n",
        "            \"num_leaves\": 31,\n",
        "            \"min_data_in_leaf\": 20,\n",
        "            \"dropout\": 0.1,\n",
        "        }\n",
        "        config_defaults.update(config_stack_manual)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUQbknvvbZR5"
      },
      "source": [
        "if not (Config.validate or Config.inference or Config.stack or Config.ensemble):\n",
        "    config_defaults[\"inference_runs\"] = []"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd440361"
      },
      "source": [
        "if Config.debug:\n",
        "    config_defaults[\"epochs\"] = 1\n",
        "    Config.print_freq = 10"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgjHEBuwETmp"
      },
      "source": [
        "if config_defaults[\"optimizer\"] == \"BertAdamW\":\n",
        "    config_defaults[\"lr_69\"] = 5e-5\n",
        "    config_defaults[\"lr_133\"] = 1e-4"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a710ed",
        "outputId": "c8065a53-67ef-4faa-f6b2-bdc84a7f327f"
      },
      "source": [
        "# Update by epoch\n",
        "# num_steps = config_defaults[\"epochs\"]\n",
        "\n",
        "# Update by batch\n",
        "num_data = 1000 if Config.debug else len(train)\n",
        "num_steps = num_data // config_defaults[\"n_fold\"] * (config_defaults[\"n_fold\"] - 1) // config_defaults[\"batch_size\"] // config_defaults[\"gradient_accumulation_steps\"] * config_defaults[\"epochs\"]\n",
        "\n",
        "print(num_steps)\n",
        "\n",
        "if config_defaults[\"scheduler\"] == \"CosineAnnealingWarmRestarts\":\n",
        "    config_defaults[\"T_0\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingLR\":\n",
        "    config_defaults[\"T_max\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
        "    config_defaults[\"factor\"] = 0.2\n",
        "    config_defaults[\"patience\"] = 4\n",
        "    config_defaults[\"eps\"] = 1e-6\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingWarmupRestarts\":\n",
        "    config_defaults[\"first_cycle_steps\"] = num_steps\n",
        "    config_defaults[\"warmup_steps\"] = num_steps // 10\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"get_cosine_schedule_with_warmup\":\n",
        "    config_defaults[\"num_training_steps\"] = num_steps\n",
        "    config_defaults[\"num_warmup_steps\"] = max(50, num_steps // 10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "a6a78770",
        "outputId": "e218fad0-032c-4113-ee4a-78dd1b496e9d"
      },
      "source": [
        "if Config.debug:\n",
        "    run = wandb.init(entity=Config.wandb_entity, project=Config.wandb_project, config=config_defaults, mode=\"disabled\")\n",
        "else:\n",
        "    run = wandb.init(entity=Config.wandb_entity, project=Config.wandb_project, config=config_defaults, notes=wandb_notes, tags=wandb_tags, job_type=wandb_job_type, save_code=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">fanciful-rain-76</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ponkots/signate-471\" target=\"_blank\">https://wandb.ai/ponkots/signate-471</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ponkots/signate-471/runs/1zwt0m0n\" target=\"_blank\">https://wandb.ai/ponkots/signate-471/runs/1zwt0m0n</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210905_160034-1zwt0m0n</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2408ee43"
      },
      "source": [
        "config = wandb.config"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezOfV_OKnV2I"
      },
      "source": [
        "## EDA-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1C7cU7ka70h",
        "outputId": "3a056d43-0ec7-4d41-9b6e-a5b1bfcaa895"
      },
      "source": [
        "# アブストが空っぽのが結構ある\n",
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id              0\n",
            "title           0\n",
            "abstract     4390\n",
            "judgement       0\n",
            "dtype: int64\n",
            "id             0\n",
            "title          0\n",
            "abstract    6546\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4fTaf66DiXj"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuuU17phnFMz"
      },
      "source": [
        "def preprocess(data):\n",
        "    \n",
        "    title_abstract = []\n",
        "    for e in data:\n",
        "\n",
        "        # アルファベット以外は空白に置換します。\n",
        "        e = re.sub(\"[^a-zA-Z]\", \" \", e)\n",
        "\n",
        "        # 小文字に変換します。\n",
        "        e = e.lower()\n",
        "\n",
        "        # token に分割します。\n",
        "        e = nltk.word_tokenize(e)\n",
        "\n",
        "        # stop word を削除します。\n",
        "        e = [word for word in e if not word in set(nltk.corpus.stopwords.words(\"english\"))]\n",
        "\n",
        "        # 見出し語化します。\n",
        "        lemma = nltk.WordNetLemmatizer()\n",
        "        e = [lemma.lemmatize(word) for word in e]\n",
        "        e = \" \".join(e)\n",
        "\n",
        "        title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM-NHL8HLzOc"
      },
      "source": [
        "def back_translation_de(data):\n",
        "    print(\"Back Translation (en -> de -> en)\")\n",
        "    title_abstract = []\n",
        "    back_translation_aug = naw.BackTranslationAug(\n",
        "        from_model_name='facebook/wmt19-en-de', \n",
        "        to_model_name='facebook/wmt19-de-en'\n",
        "    )\n",
        "\n",
        "    for e in tqdm(data, total=len(data)):\n",
        "        try:\n",
        "            title_abstract.append(back_translation_aug.augment(e))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBV7kf3uWECm"
      },
      "source": [
        "def synonym_augmenter(data):\n",
        "    print(\"Synonym Augmenter\")\n",
        "    title_abstract = []\n",
        "    aug = naw.SynonymAug(aug_src='wordnet')\n",
        "\n",
        "    for e in tqdm(data, total=len(data)):\n",
        "        try:\n",
        "            title_abstract.append(aug.augment(e))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQCGtu9kbatB"
      },
      "source": [
        "def abstractive_summarization_augmenter(data):\n",
        "    print(\"Abstractive Summarization Augmenter\")\n",
        "    title_abstract = []\n",
        "    aug = nas.AbstSummAug(model_path='t5-base', max_length=config.max_len, device='cuda')\n",
        "\n",
        "    for e in tqdm(data, total=len(data)):\n",
        "        try:\n",
        "            title_abstract.append(aug.augment(e))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylcVBT02nIGZ"
      },
      "source": [
        "def get_train_data(train):\n",
        "\n",
        "    # NaN を空白で埋めます。\n",
        "    train = train.fillna(\"\")\n",
        "\n",
        "    # judgement を one hot encoding\n",
        "    # train[\"judgement_str\"] = train[\"judgement\"].astype(str)\n",
        "    # train = pd.get_dummies(train, columns=[\"judgement_str\"], prefix=[\"judgement\"])\n",
        "\n",
        "    # abstract の有無を Stratified KFold で使います。\n",
        "    train[\"nan_abstract\"] = np.where(train[\"abstract\"] == \"\", 1, 0)\n",
        "\n",
        "    # title の単語数\n",
        "    # train[\"len_title\"] = train[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # abstract の単語数\n",
        "    # train[\"len_abstract\"] = train[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # title と abstract を接続します。\n",
        "    train[\"title_abstract\"] = train[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "    # train[\"abstract_title\"] = train[[\"abstract\", \"title\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "    # Back Translation (en -> de -> en)\n",
        "    #train_bt_de = train[train[\"judgement\"] == 1].copy()\n",
        "    #train_bt_de[\"title_abstract\"] = back_translation_de(train_bt_de[\"title_abstract\"])\n",
        "\n",
        "    # Synonym Augmenter\n",
        "    #train_sa = train[train[\"judgement\"] == 1].copy()\n",
        "    #train_sa[\"title_abstract\"] = synonym_augmenter(train_sa[\"title_abstract\"])\n",
        "\n",
        "    #train = pd.concat([train, train_bt_de, train_sa], axis=0)\n",
        "\n",
        "    train[\"len_input\"] = train[config.input].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # Abstractive Summarization Augmenter\n",
        "    train.loc[train['len_input'] > config.max_len, config.input] = abstractive_summarization_augmenter(train.loc[train['len_input'] > config.max_len, config.input])\n",
        "    train[\"len_input\"] = train[config.input].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # train[\"preprocessed_title_abstract\"] = preprocess(train[\"title_abstract\"])\n",
        "\n",
        "    # 前処理した文の単語数\n",
        "    # train[\"len_preprocessed_title_abstract\"] = train[\"preprocessed_title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return train"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YskezxynKkm"
      },
      "source": [
        "def get_test_data(test):\n",
        "\n",
        "    # NaN を空白で埋めます。\n",
        "    test = test.fillna(\"\")\n",
        "\n",
        "    # title の単語数\n",
        "    # test[\"len_title\"] = test[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # abstract の単語数\n",
        "    # test[\"len_abstract\"] = test[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # title と abstract を接続します。\n",
        "    test[\"title_abstract\"] = test[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "    # test[\"abstract_title\"] = test[[\"abstract\", \"title\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "    test[\"len_input\"] = test[config.input].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # Abstractive Summarization Augmenter\n",
        "    test.loc[test['len_input'] > config.max_len, config.input] = abstractive_summarization_augmenter(test.loc[test['len_input'] > config.max_len, config.input])\n",
        "    test[\"len_input\"] = test[config.input].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # test[\"preprocessed_title_abstract\"] = preprocess(test[\"title_abstract\"])\n",
        "\n",
        "    # 前処理した文の単語数\n",
        "    # test[\"len_preprocessed_title_abstract\"] = test[\"preprocessed_title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return test"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0CPmvZnQFP"
      },
      "source": [
        "if os.path.exists(\"/content/drive/MyDrive/Datasets/signate-471/preprocessed_train.csv\"):\n",
        "    !cp -f /content/drive/MyDrive/Datasets/signate-471/preprocessed_train.csv .\n",
        "    train = pd.read_csv(\"preprocessed_train.csv\")\n",
        "\n",
        "    # csv を再読み込みすると NaN に戻ってしまうので、再度変換します。\n",
        "    train = train.fillna(\"\")\n",
        "\n",
        "else:\n",
        "    # 一度、前処理したものは保存しておきます。\n",
        "    train = get_train_data(train)\n",
        "    train.to_csv(\"preprocessed_train.csv\")\n",
        "\n",
        "    # artifact = wandb.Artifact('preprocessed_train', type='dataset')\n",
        "    # artifact.add_file(\"preprocessed_train.csv\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    !cp -f preprocessed_train.csv /content/drive/MyDrive/Datasets/signate-471/"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A248D057nSd6"
      },
      "source": [
        "if os.path.exists(\"/content/drive/MyDrive/Datasets/signate-471/preprocessed_test.csv\"):\n",
        "    !cp -f /content/drive/MyDrive/Datasets/signate-471/preprocessed_test.csv .\n",
        "    test = pd.read_csv(\"preprocessed_test.csv\")\n",
        "\n",
        "    # csv を再読み込みすると NaN に戻ってしまうので、再度変換します。\n",
        "    test = test.fillna(\"\")\n",
        "\n",
        "else:\n",
        "    # 一度、前処理したものは保存しておきます。\n",
        "    test = get_test_data(test)\n",
        "    test.to_csv(\"preprocessed_test.csv\")\n",
        "\n",
        "    # artifact = wandb.Artifact('preprocessed_test', type='dataset')\n",
        "    # artifact.add_file(\"preprocessed_test.csv\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    !cp -f preprocessed_test.csv /content/drive/MyDrive/Datasets/signate-471/"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UPOk9WroUmX"
      },
      "source": [
        "## EDA-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BloR0mcceTWK",
        "outputId": "6ddf546c-c26b-4872-f928-bccaa8f38bdb"
      },
      "source": [
        "# abstract に改行は含まれていない\n",
        "print(len(train[train[\"abstract\"].str.contains(\"\\n\")]))\n",
        "print(len(test[test[\"abstract\"].str.contains(\"\\n\")]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHfTQdU8Cezv",
        "outputId": "c6d09576-0307-491d-f776-54ea8cd3695b"
      },
      "source": [
        "# input の単語数\n",
        "print(train[\"len_input\"].max())\n",
        "print(test[\"len_input\"].max())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "18097672",
        "outputId": "20e43090-0630-453c-a46e-21ff58eb6d7c"
      },
      "source": [
        "for ds in [train, test, sub]:\n",
        "    print(f\"=\" * 80)\n",
        "    ds.info()\n",
        "    display(ds.head())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27145 entries, 0 to 27144\n",
            "Data columns (total 8 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Unnamed: 0      27145 non-null  int64 \n",
            " 1   id              27145 non-null  int64 \n",
            " 2   title           27145 non-null  object\n",
            " 3   abstract        27145 non-null  object\n",
            " 4   judgement       27145 non-null  int64 \n",
            " 5   nan_abstract    27145 non-null  int64 \n",
            " 6   title_abstract  27145 non-null  object\n",
            " 7   len_input       27145 non-null  int64 \n",
            "dtypes: int64(5), object(3)\n",
            "memory usage: 1.7+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>judgement</th>\n",
              "      <th>nan_abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>len_input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>Longitudinal studies indicate that declines in...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>The present study was undertaken to validate t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>Objective: To report a case series in which ba...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  id  ...                                     title_abstract len_input\n",
              "0           0   0  ...  One-year age changes in MRI brain volumes in o...       203\n",
              "1           1   1  ...  Supportive CSF biomarker evidence to enhance t...       237\n",
              "2           2   2  ...  Occurrence of basal ganglia germ cell tumors w...       143\n",
              "3           3   3  ...  New developments in diagnosis and therapy of C...       387\n",
              "4           4   4  ...  Prolonged shedding of SARS-CoV-2 in an elderly...        16\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Unnamed: 0      40834 non-null  int64 \n",
            " 1   id              40834 non-null  int64 \n",
            " 2   title           40834 non-null  object\n",
            " 3   abstract        40834 non-null  object\n",
            " 4   title_abstract  40834 non-null  object\n",
            " 5   len_input       40834 non-null  int64 \n",
            "dtypes: int64(3), object(3)\n",
            "memory usage: 1.9+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>len_input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>27145</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>The objective of the paper is to analyse chang...</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>27146</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td></td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>27147</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>27148</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>We present a method that significantly improve...</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>27149</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>The objective of this study is to compare the ...</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  len_input\n",
              "0           0  ...        261\n",
              "1           1  ...          8\n",
              "2           2  ...        329\n",
              "3           3  ...        130\n",
              "4           4  ...        237\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype\n",
            "---  ------     --------------  -----\n",
            " 0   id         40834 non-null  int64\n",
            " 1   judgement  40834 non-null  int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 638.2 KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>judgement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27146</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27147</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  judgement\n",
              "0  27145          0\n",
              "1  27146          1\n",
              "2  27147          1\n",
              "3  27148          0\n",
              "4  27149          1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9L3nMYzDMqJ"
      },
      "source": [
        "### 目的変数 judgement の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "3f5772d0",
        "outputId": "147e0b50-c582-4604-8fda-73c845a74f78"
      },
      "source": [
        "sns.distplot(train[\"judgement\"], kde=False)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2c6735090>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuZVvlM8Xy91",
        "outputId": "93185abb-0d88-46a5-e5b9-ea2bd5c04349"
      },
      "source": [
        "train[\"judgement\"].value_counts()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    26515\n",
              "1      630\n",
              "Name: judgement, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E-56356_L3T",
        "outputId": "6829cbaa-2b05-4588-d06f-ee6cca6e8749"
      },
      "source": [
        "border = len(train[train[\"judgement\"] == 1]) / len(train[\"judgement\"])\n",
        "print(border)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0232086940504697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZNrZoksDSMb"
      },
      "source": [
        "### input の単語数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "ixixzShVH80j",
        "outputId": "9afbf742-5346-41b3-d876-04664a5cf8f3"
      },
      "source": [
        "g = sns.FacetGrid(train[[\"judgement\", \"len_input\"]], hue='judgement')\n",
        "g.map(sns.distplot, 'len_input', label='judgement', hist=True, rug=False)\n",
        "g.add_legend()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fc2bd3bf450>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 278.125x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W_kt9XDpGTm2",
        "outputId": "7b156bac-1e58-4b76-c018-ce74edb3e12a"
      },
      "source": [
        "sns.distplot(test[\"len_input\"], hist=True, rug=False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2b2da7d90>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeZesLBHnfl5"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOdN4h2grTzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6ab3eb-4b9d-4348-996a-f74fc0cc9e36"
      },
      "source": [
        "if Config.validate:\n",
        "    api = wandb.Api()\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        try:\n",
        "            run.file(\"oof_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        oof = pd.read_csv(f\"{run_id}/oof_df.csv\")[[\"id\", \"preds\"]]\n",
        "        oof.columns = [\"id\", f\"preds{n}\"]\n",
        "        train = pd.merge(train, oof, on=\"id\")\n",
        "    \n",
        "    print(train.columns)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'id', 'title', 'abstract', 'judgement', 'nan_abstract',\n",
            "       'title_abstract', 'len_input', 'preds0'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM2fDBrNi2_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd3380e-d8ee-43e5-cbee-07400e52f9ab"
      },
      "source": [
        "if Config.inference:\n",
        "    api = wandb.Api()\n",
        "    inference_models = []\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        inference_model = {}\n",
        "        inference_model[\"run_id\"] = run_id\n",
        "        inference_model[\"model_name\"] = run.config[\"model_name\"]\n",
        "\n",
        "        for fold in range(config.n_fold):\n",
        "            try:\n",
        "                run.file(f\"{inference_model['model_name'].replace('/', '-')}_fold{fold}_best.pth\").download(run_id)\n",
        "            except wandb.CommError:\n",
        "                # Already downloaded.\n",
        "                pass\n",
        "\n",
        "            model_preds = torch.load(f\"{run_id}/{inference_model['model_name'].replace('/', '-')}_fold{fold}_best.pth\")\n",
        "            inference_model[f\"state_fold{fold}\"] = model_preds[\"model\"]\n",
        "            inference_model[f\"preds_fold{fold}\"] = model_preds[\"preds\"]\n",
        "\n",
        "        inference_models.append(inference_model)\n",
        "    \n",
        "    print({m['run_id']: m['model_name'] for m in inference_models})"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1ostvjfa': 'dmis-lab/biobert-base-cased-v1.1-squad'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXmpjcJxQhBc"
      },
      "source": [
        "if Config.stack or Config.ensemble:\n",
        "    api = wandb.Api()\n",
        "\n",
        "    feat_id = 0\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        try:\n",
        "            run.file(\"validation_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            run.file(\"prediction_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        val = pd.read_csv(f\"{run_id}/validation_df.csv\")\n",
        "        pred = pd.read_csv(f\"{run_id}/prediction_df.csv\")\n",
        "\n",
        "        # cols = [c for c in val.columns if c.startswith(\"preds\") and c != \"preds\"]\n",
        "        cols = [c for c in val.columns if c.startswith(\"class_preds\")]\n",
        "        val = val[[\"id\"] + cols]\n",
        "        pred = pred[[\"id\"] + cols]\n",
        "\n",
        "        adjust_cols = [\"id\"] + [f\"preds{n}\" for n in range(feat_id, feat_id + len(cols))]\n",
        "        val.columns = adjust_cols\n",
        "        pred.columns = adjust_cols\n",
        "\n",
        "        feat_id += len(cols)\n",
        "\n",
        "        train = pd.merge(train, val, on=\"id\")\n",
        "        test = pd.merge(test, pred, on=\"id\")\n",
        "    \n",
        "    print(f\"train: {train.columns}\")\n",
        "    print(f\"test: {test.columns}\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba31d893"
      },
      "source": [
        "if Config.debug and not Config.stack:\n",
        "    train = train.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    test = test.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    sub = sub.sample(n=1000, random_state=config.seed).reset_index(drop=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQ7fKQ2IC6i"
      },
      "source": [
        "## CV Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Lt-ZLtIHCG",
        "outputId": "3f46a928-6829-4bd7-dfe3-d0e30afab976"
      },
      "source": [
        "Fold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train[[\"judgement\", \"nan_abstract\"]])):\n",
        "    train.loc[val_index, \"fold\"] = int(n)\n",
        "train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n",
        "print(train.groupby([\"fold\", \"judgement\", \"nan_abstract\"]).size())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold  judgement  nan_abstract\n",
            "0     0          0               4446\n",
            "                 1                857\n",
            "      1          0                105\n",
            "                 1                 21\n",
            "1     0          0               4448\n",
            "                 1                855\n",
            "      1          0                103\n",
            "                 1                 23\n",
            "2     0          0               4448\n",
            "                 1                855\n",
            "      1          0                103\n",
            "                 1                 23\n",
            "3     0          0               4448\n",
            "                 1                855\n",
            "      1          0                103\n",
            "                 1                 23\n",
            "4     0          0               4455\n",
            "                 1                848\n",
            "      1          0                 96\n",
            "                 1                 30\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d423ea8"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5985d91d"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=config.seed)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596efb85"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2721636"
      },
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, df, model_name, include_labels=True):\n",
        "        tokenizer = T.AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        self.df = df\n",
        "        self.include_labels = include_labels\n",
        "\n",
        "        self.title = df[config.input].tolist()\n",
        "        self.encoded = tokenizer.batch_encode_plus(\n",
        "            self.title,\n",
        "            padding = 'max_length',            \n",
        "            max_length = config.max_len,\n",
        "            truncation = True,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        \n",
        "        if self.include_labels:\n",
        "            self.labels = df[\"judgement\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = torch.tensor(self.encoded['input_ids'][idx])\n",
        "        attention_mask = torch.tensor(self.encoded['attention_mask'][idx])\n",
        "\n",
        "        if self.include_labels:\n",
        "            label = torch.tensor(self.labels[idx]).float()\n",
        "            return input_ids, attention_mask, label\n",
        "\n",
        "        return input_ids, attention_mask\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e56a1c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57bd2703-b2fe-4387-f084-e9b8011c0265"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "\n",
        "    train_ds = BaseDataset(train, config.model_name)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_ids, attention_mask, label = train_ds[i]\n",
        "        print(input_ids)\n",
        "        print(attention_mask)\n",
        "        print(f\"label: {label}\")\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101,  1141,   118,  1214,  1425,  2607,  1107,   182,  2047,  3575,\n",
            "         6357,  1107,  2214,  6323,   119, 23191,  2527,  5057,  1115,  6246,\n",
            "         1116,  1107,  1884, 25763,  1105,  2962, 26872,  1170,  1425,  3102,\n",
            "         1201,   119,  1103, 24928, 11955,  3906, 18778,  1596,  1105, 24928,\n",
            "        11955, 22192, 23652, 13791,  1596,  1223,  6709,  3381,  1116,  1104,\n",
            "        12176,  1849,  1132, 10527,  1112,  1175,  1110,  1376,  1869,  1113,\n",
            "        23191,  3575,  2607,   119,  1195,  1132,  9239,   170, 23191, 24928,\n",
            "        11955,  8628,  3375,  2025,  1104,  1664,  2007, 24674,  2214,  6635,\n",
            "         1107,  1103,   171,  1348,  3121,  4982, 23191,  2025,  1104, 14195,\n",
            "          119,  1142,  2592,  7203,  1113,  1425,  1105,  2673,  5408,  1107,\n",
            "         3575,  2401,  7140,  1118,  8364, 20370, 14377,  1219,  1103,  1148,\n",
            "         1160,  2683, 10540,  1116,   119,  2771,   118,  2237,  1348,  2686,\n",
            "         1121, 13096,  6635,  4079,  4589,   118,  4859,  1201,  7063,  5409,\n",
            "         2610, 21828,  4907,  5552,  6357,  1105,  2964,  5021,  1105,  1653,\n",
            "         2187,  6357,  1107,  2214,  3402,  1114,  3247,  6635,  1105,  1107,\n",
            "         1441,  3402,  1114,  1535,   119,  2918,  3575,  6357,  1437,  1115,\n",
            "         1103,  3154,  1104,  1425,  1105,  2673,  1132,  1136,  6029,  1506,\n",
            "         3575,  4001,   119,  1425,  5408,  1132,  4459,  1111,  1103, 14247,\n",
            "        22331,  1348,  1805,   119,  2673,  5408,  6613,  1106,  1129,  2610,\n",
            "         1111, 22172,  1105, 18107,  1190, 14247, 22331,  1348,  1105,   184,\n",
            "        19557, 18965,  1348,  4001,   119, 23191,  3622, 17798,  1126,  2773,\n",
            "         1104, 15722,  1545,  2608,   113,   124,   114,  1107, 21828,  4907,\n",
            "         5552,  3884,  1166,   122,  1214,  1133,  1185, 11552,  1895,  1849,\n",
            "         1107,  1703,  1137,  2918,  3575,  6357,   119,  5754,  1104,  1103,\n",
            "         4844,  1105,  2603,  1104, 23191,  3575,  2607,  1209, 11000,  1103,\n",
            "        11432,  1104,  3507,  7542,  3575,  2607,  1134,  1336,  1129, 17163,\n",
            "         3864,  1104, 26707,  3452,  1465,   119,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d681dabf"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Y5LnDCMPcC"
      },
      "source": [
        "### BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHPwf3JzPmjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7846a3d0-0d79-4bad-db70-b4bdb9dad8fe"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    print(T.AutoConfig.from_pretrained(config.model_name))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "229d18e7"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "\n",
        "        if \"base\" in model_name or \"L-12\" in model_name or \"scibert\" in model_name:\n",
        "            out_dim = 768\n",
        "        elif \"large\" in model_name or \"L-24\" in model_name:\n",
        "            out_dim = 1024\n",
        "\n",
        "        auto_config = T.AutoConfig.from_pretrained(model_name)\n",
        "        auto_config.update({\n",
        "            \"output_hidden_states\": True,\n",
        "            \"hidden_dropout_prob\": config.dropout,\n",
        "            # \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "        \n",
        "        self.auto_model = T.AutoModel.from_pretrained(model_name, config=auto_config)  \n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(out_dim, 512),            \n",
        "            nn.Tanh(),                       \n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )        \n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(out_dim, 1)                        \n",
        "        )\n",
        "\n",
        "        if config.reinit_layers > 0:\n",
        "            self.re_init()\n",
        "\n",
        "        if config.freeze_layers > 0:\n",
        "            self.freeze()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.auto_model(input_ids=input_ids, attention_mask=attention_mask)        \n",
        "\n",
        "        # There are a total of 13 layers of hidden states.\n",
        "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
        "        # We take the hidden states from the last Roberta layer.\n",
        "        last_layer_hidden_states = bert_output.hidden_states[-1]\n",
        "\n",
        "        # The number of cells is config.max_len.\n",
        "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
        "        # In order to condense hidden states of all cells to a context vector,\n",
        "        # we compute a weighted average of the hidden states of all cells.\n",
        "        # We compute the weight of each cell, using the attention neural network.\n",
        "        weights = self.attention(last_layer_hidden_states)\n",
        "                \n",
        "        # weights.shape is config.batch_size x config.max_len x 1\n",
        "        # last_layer_hidden_states.shape is config.batch_size x config.max_len x 768        \n",
        "        # Now we compute context_vector as the weighted average.\n",
        "        # context_vector.shape is config.batch_size x 768\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
        "        \n",
        "        # Now we reduce the context vector to the prediction score.\n",
        "        out = self.regressor(context_vector).squeeze()\n",
        "\n",
        "        return out\n",
        "\n",
        "    def re_init(self):\n",
        "        # re-init pooler\n",
        "        self.auto_model.pooler.dense.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "        self.auto_model.pooler.dense.bias.data.zero_()\n",
        "        for p in self.auto_model.pooler.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        # re-init encoder\n",
        "        layers = self.auto_model.encoder.layer[-config.reinit_layers:]\n",
        "        for layer in layers:\n",
        "            for module in layer.modules():\n",
        "                if isinstance(module, nn.Linear):\n",
        "                    # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "                    # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.bias is not None:\n",
        "                        module.bias.data.zero_()\n",
        "                elif isinstance(module, nn.Embedding):\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.padding_idx is not None:\n",
        "                        module.weight.data[module.padding_idx].zero_()\n",
        "                elif isinstance(module, nn.LayerNorm):\n",
        "                    module.bias.data.zero_()\n",
        "                    module.weight.data.fill_(1.0)\n",
        "\n",
        "    def freeze(self):\n",
        "        # freeze embedding\n",
        "        for param in self.auto_model.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # freeze encoder\n",
        "        layers = self.auto_model.encoder.layer[:config.freeze_layers]\n",
        "        for layer in layers:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a3978b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f885362a-6a1a-4f87-e944-6b7851a56281"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "\n",
        "    model = BaseModel(config.model_name)\n",
        "    print(model)\n",
        "\n",
        "    train_dataset = BaseDataset(train, config.model_name)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "    for input_ids, attention_mask, labels in train_loader:\n",
        "        output = model(input_ids, attention_mask)\n",
        "        print(output)\n",
        "        break\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModel(\n",
            "  (auto_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (attention): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (3): Softmax(dim=1)\n",
            "  )\n",
            "  (regressor): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "tensor([-5.3693e-01, -6.5467e-01, -4.1586e-01,  2.1973e-04],\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlpHUm-SrcLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40cfa54-459c-41b3-e52d-f07a45a990e8"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
        "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0: True, auto_model.embeddings.word_embeddings.weight\n",
            "   1: True, auto_model.embeddings.position_embeddings.weight\n",
            "   2: True, auto_model.embeddings.token_type_embeddings.weight\n",
            "   3: True, auto_model.embeddings.LayerNorm.weight\n",
            "   4: True, auto_model.embeddings.LayerNorm.bias\n",
            "   5: True, auto_model.encoder.layer.0.attention.self.query.weight\n",
            "   6: True, auto_model.encoder.layer.0.attention.self.query.bias\n",
            "   7: True, auto_model.encoder.layer.0.attention.self.key.weight\n",
            "   8: True, auto_model.encoder.layer.0.attention.self.key.bias\n",
            "   9: True, auto_model.encoder.layer.0.attention.self.value.weight\n",
            "  10: True, auto_model.encoder.layer.0.attention.self.value.bias\n",
            "  11: True, auto_model.encoder.layer.0.attention.output.dense.weight\n",
            "  12: True, auto_model.encoder.layer.0.attention.output.dense.bias\n",
            "  13: True, auto_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  14: True, auto_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  15: True, auto_model.encoder.layer.0.intermediate.dense.weight\n",
            "  16: True, auto_model.encoder.layer.0.intermediate.dense.bias\n",
            "  17: True, auto_model.encoder.layer.0.output.dense.weight\n",
            "  18: True, auto_model.encoder.layer.0.output.dense.bias\n",
            "  19: True, auto_model.encoder.layer.0.output.LayerNorm.weight\n",
            "  20: True, auto_model.encoder.layer.0.output.LayerNorm.bias\n",
            "  21: True, auto_model.encoder.layer.1.attention.self.query.weight\n",
            "  22: True, auto_model.encoder.layer.1.attention.self.query.bias\n",
            "  23: True, auto_model.encoder.layer.1.attention.self.key.weight\n",
            "  24: True, auto_model.encoder.layer.1.attention.self.key.bias\n",
            "  25: True, auto_model.encoder.layer.1.attention.self.value.weight\n",
            "  26: True, auto_model.encoder.layer.1.attention.self.value.bias\n",
            "  27: True, auto_model.encoder.layer.1.attention.output.dense.weight\n",
            "  28: True, auto_model.encoder.layer.1.attention.output.dense.bias\n",
            "  29: True, auto_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  30: True, auto_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  31: True, auto_model.encoder.layer.1.intermediate.dense.weight\n",
            "  32: True, auto_model.encoder.layer.1.intermediate.dense.bias\n",
            "  33: True, auto_model.encoder.layer.1.output.dense.weight\n",
            "  34: True, auto_model.encoder.layer.1.output.dense.bias\n",
            "  35: True, auto_model.encoder.layer.1.output.LayerNorm.weight\n",
            "  36: True, auto_model.encoder.layer.1.output.LayerNorm.bias\n",
            "  37: True, auto_model.encoder.layer.2.attention.self.query.weight\n",
            "  38: True, auto_model.encoder.layer.2.attention.self.query.bias\n",
            "  39: True, auto_model.encoder.layer.2.attention.self.key.weight\n",
            "  40: True, auto_model.encoder.layer.2.attention.self.key.bias\n",
            "  41: True, auto_model.encoder.layer.2.attention.self.value.weight\n",
            "  42: True, auto_model.encoder.layer.2.attention.self.value.bias\n",
            "  43: True, auto_model.encoder.layer.2.attention.output.dense.weight\n",
            "  44: True, auto_model.encoder.layer.2.attention.output.dense.bias\n",
            "  45: True, auto_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  46: True, auto_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  47: True, auto_model.encoder.layer.2.intermediate.dense.weight\n",
            "  48: True, auto_model.encoder.layer.2.intermediate.dense.bias\n",
            "  49: True, auto_model.encoder.layer.2.output.dense.weight\n",
            "  50: True, auto_model.encoder.layer.2.output.dense.bias\n",
            "  51: True, auto_model.encoder.layer.2.output.LayerNorm.weight\n",
            "  52: True, auto_model.encoder.layer.2.output.LayerNorm.bias\n",
            "  53: True, auto_model.encoder.layer.3.attention.self.query.weight\n",
            "  54: True, auto_model.encoder.layer.3.attention.self.query.bias\n",
            "  55: True, auto_model.encoder.layer.3.attention.self.key.weight\n",
            "  56: True, auto_model.encoder.layer.3.attention.self.key.bias\n",
            "  57: True, auto_model.encoder.layer.3.attention.self.value.weight\n",
            "  58: True, auto_model.encoder.layer.3.attention.self.value.bias\n",
            "  59: True, auto_model.encoder.layer.3.attention.output.dense.weight\n",
            "  60: True, auto_model.encoder.layer.3.attention.output.dense.bias\n",
            "  61: True, auto_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  62: True, auto_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  63: True, auto_model.encoder.layer.3.intermediate.dense.weight\n",
            "  64: True, auto_model.encoder.layer.3.intermediate.dense.bias\n",
            "  65: True, auto_model.encoder.layer.3.output.dense.weight\n",
            "  66: True, auto_model.encoder.layer.3.output.dense.bias\n",
            "  67: True, auto_model.encoder.layer.3.output.LayerNorm.weight\n",
            "  68: True, auto_model.encoder.layer.3.output.LayerNorm.bias\n",
            "  69: True, auto_model.encoder.layer.4.attention.self.query.weight\n",
            "  70: True, auto_model.encoder.layer.4.attention.self.query.bias\n",
            "  71: True, auto_model.encoder.layer.4.attention.self.key.weight\n",
            "  72: True, auto_model.encoder.layer.4.attention.self.key.bias\n",
            "  73: True, auto_model.encoder.layer.4.attention.self.value.weight\n",
            "  74: True, auto_model.encoder.layer.4.attention.self.value.bias\n",
            "  75: True, auto_model.encoder.layer.4.attention.output.dense.weight\n",
            "  76: True, auto_model.encoder.layer.4.attention.output.dense.bias\n",
            "  77: True, auto_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  78: True, auto_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  79: True, auto_model.encoder.layer.4.intermediate.dense.weight\n",
            "  80: True, auto_model.encoder.layer.4.intermediate.dense.bias\n",
            "  81: True, auto_model.encoder.layer.4.output.dense.weight\n",
            "  82: True, auto_model.encoder.layer.4.output.dense.bias\n",
            "  83: True, auto_model.encoder.layer.4.output.LayerNorm.weight\n",
            "  84: True, auto_model.encoder.layer.4.output.LayerNorm.bias\n",
            "  85: True, auto_model.encoder.layer.5.attention.self.query.weight\n",
            "  86: True, auto_model.encoder.layer.5.attention.self.query.bias\n",
            "  87: True, auto_model.encoder.layer.5.attention.self.key.weight\n",
            "  88: True, auto_model.encoder.layer.5.attention.self.key.bias\n",
            "  89: True, auto_model.encoder.layer.5.attention.self.value.weight\n",
            "  90: True, auto_model.encoder.layer.5.attention.self.value.bias\n",
            "  91: True, auto_model.encoder.layer.5.attention.output.dense.weight\n",
            "  92: True, auto_model.encoder.layer.5.attention.output.dense.bias\n",
            "  93: True, auto_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  94: True, auto_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  95: True, auto_model.encoder.layer.5.intermediate.dense.weight\n",
            "  96: True, auto_model.encoder.layer.5.intermediate.dense.bias\n",
            "  97: True, auto_model.encoder.layer.5.output.dense.weight\n",
            "  98: True, auto_model.encoder.layer.5.output.dense.bias\n",
            "  99: True, auto_model.encoder.layer.5.output.LayerNorm.weight\n",
            " 100: True, auto_model.encoder.layer.5.output.LayerNorm.bias\n",
            " 101: True, auto_model.encoder.layer.6.attention.self.query.weight\n",
            " 102: True, auto_model.encoder.layer.6.attention.self.query.bias\n",
            " 103: True, auto_model.encoder.layer.6.attention.self.key.weight\n",
            " 104: True, auto_model.encoder.layer.6.attention.self.key.bias\n",
            " 105: True, auto_model.encoder.layer.6.attention.self.value.weight\n",
            " 106: True, auto_model.encoder.layer.6.attention.self.value.bias\n",
            " 107: True, auto_model.encoder.layer.6.attention.output.dense.weight\n",
            " 108: True, auto_model.encoder.layer.6.attention.output.dense.bias\n",
            " 109: True, auto_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            " 110: True, auto_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            " 111: True, auto_model.encoder.layer.6.intermediate.dense.weight\n",
            " 112: True, auto_model.encoder.layer.6.intermediate.dense.bias\n",
            " 113: True, auto_model.encoder.layer.6.output.dense.weight\n",
            " 114: True, auto_model.encoder.layer.6.output.dense.bias\n",
            " 115: True, auto_model.encoder.layer.6.output.LayerNorm.weight\n",
            " 116: True, auto_model.encoder.layer.6.output.LayerNorm.bias\n",
            " 117: True, auto_model.encoder.layer.7.attention.self.query.weight\n",
            " 118: True, auto_model.encoder.layer.7.attention.self.query.bias\n",
            " 119: True, auto_model.encoder.layer.7.attention.self.key.weight\n",
            " 120: True, auto_model.encoder.layer.7.attention.self.key.bias\n",
            " 121: True, auto_model.encoder.layer.7.attention.self.value.weight\n",
            " 122: True, auto_model.encoder.layer.7.attention.self.value.bias\n",
            " 123: True, auto_model.encoder.layer.7.attention.output.dense.weight\n",
            " 124: True, auto_model.encoder.layer.7.attention.output.dense.bias\n",
            " 125: True, auto_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            " 126: True, auto_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            " 127: True, auto_model.encoder.layer.7.intermediate.dense.weight\n",
            " 128: True, auto_model.encoder.layer.7.intermediate.dense.bias\n",
            " 129: True, auto_model.encoder.layer.7.output.dense.weight\n",
            " 130: True, auto_model.encoder.layer.7.output.dense.bias\n",
            " 131: True, auto_model.encoder.layer.7.output.LayerNorm.weight\n",
            " 132: True, auto_model.encoder.layer.7.output.LayerNorm.bias\n",
            " 133: True, auto_model.encoder.layer.8.attention.self.query.weight\n",
            " 134: True, auto_model.encoder.layer.8.attention.self.query.bias\n",
            " 135: True, auto_model.encoder.layer.8.attention.self.key.weight\n",
            " 136: True, auto_model.encoder.layer.8.attention.self.key.bias\n",
            " 137: True, auto_model.encoder.layer.8.attention.self.value.weight\n",
            " 138: True, auto_model.encoder.layer.8.attention.self.value.bias\n",
            " 139: True, auto_model.encoder.layer.8.attention.output.dense.weight\n",
            " 140: True, auto_model.encoder.layer.8.attention.output.dense.bias\n",
            " 141: True, auto_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            " 142: True, auto_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            " 143: True, auto_model.encoder.layer.8.intermediate.dense.weight\n",
            " 144: True, auto_model.encoder.layer.8.intermediate.dense.bias\n",
            " 145: True, auto_model.encoder.layer.8.output.dense.weight\n",
            " 146: True, auto_model.encoder.layer.8.output.dense.bias\n",
            " 147: True, auto_model.encoder.layer.8.output.LayerNorm.weight\n",
            " 148: True, auto_model.encoder.layer.8.output.LayerNorm.bias\n",
            " 149: True, auto_model.encoder.layer.9.attention.self.query.weight\n",
            " 150: True, auto_model.encoder.layer.9.attention.self.query.bias\n",
            " 151: True, auto_model.encoder.layer.9.attention.self.key.weight\n",
            " 152: True, auto_model.encoder.layer.9.attention.self.key.bias\n",
            " 153: True, auto_model.encoder.layer.9.attention.self.value.weight\n",
            " 154: True, auto_model.encoder.layer.9.attention.self.value.bias\n",
            " 155: True, auto_model.encoder.layer.9.attention.output.dense.weight\n",
            " 156: True, auto_model.encoder.layer.9.attention.output.dense.bias\n",
            " 157: True, auto_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            " 158: True, auto_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            " 159: True, auto_model.encoder.layer.9.intermediate.dense.weight\n",
            " 160: True, auto_model.encoder.layer.9.intermediate.dense.bias\n",
            " 161: True, auto_model.encoder.layer.9.output.dense.weight\n",
            " 162: True, auto_model.encoder.layer.9.output.dense.bias\n",
            " 163: True, auto_model.encoder.layer.9.output.LayerNorm.weight\n",
            " 164: True, auto_model.encoder.layer.9.output.LayerNorm.bias\n",
            " 165: True, auto_model.encoder.layer.10.attention.self.query.weight\n",
            " 166: True, auto_model.encoder.layer.10.attention.self.query.bias\n",
            " 167: True, auto_model.encoder.layer.10.attention.self.key.weight\n",
            " 168: True, auto_model.encoder.layer.10.attention.self.key.bias\n",
            " 169: True, auto_model.encoder.layer.10.attention.self.value.weight\n",
            " 170: True, auto_model.encoder.layer.10.attention.self.value.bias\n",
            " 171: True, auto_model.encoder.layer.10.attention.output.dense.weight\n",
            " 172: True, auto_model.encoder.layer.10.attention.output.dense.bias\n",
            " 173: True, auto_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            " 174: True, auto_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            " 175: True, auto_model.encoder.layer.10.intermediate.dense.weight\n",
            " 176: True, auto_model.encoder.layer.10.intermediate.dense.bias\n",
            " 177: True, auto_model.encoder.layer.10.output.dense.weight\n",
            " 178: True, auto_model.encoder.layer.10.output.dense.bias\n",
            " 179: True, auto_model.encoder.layer.10.output.LayerNorm.weight\n",
            " 180: True, auto_model.encoder.layer.10.output.LayerNorm.bias\n",
            " 181: True, auto_model.encoder.layer.11.attention.self.query.weight\n",
            " 182: True, auto_model.encoder.layer.11.attention.self.query.bias\n",
            " 183: True, auto_model.encoder.layer.11.attention.self.key.weight\n",
            " 184: True, auto_model.encoder.layer.11.attention.self.key.bias\n",
            " 185: True, auto_model.encoder.layer.11.attention.self.value.weight\n",
            " 186: True, auto_model.encoder.layer.11.attention.self.value.bias\n",
            " 187: True, auto_model.encoder.layer.11.attention.output.dense.weight\n",
            " 188: True, auto_model.encoder.layer.11.attention.output.dense.bias\n",
            " 189: True, auto_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            " 190: True, auto_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            " 191: True, auto_model.encoder.layer.11.intermediate.dense.weight\n",
            " 192: True, auto_model.encoder.layer.11.intermediate.dense.bias\n",
            " 193: True, auto_model.encoder.layer.11.output.dense.weight\n",
            " 194: True, auto_model.encoder.layer.11.output.dense.bias\n",
            " 195: True, auto_model.encoder.layer.11.output.LayerNorm.weight\n",
            " 196: True, auto_model.encoder.layer.11.output.LayerNorm.bias\n",
            " 197: True, auto_model.pooler.dense.weight\n",
            " 198: True, auto_model.pooler.dense.bias\n",
            " 199: True, attention.0.weight\n",
            " 200: True, attention.0.bias\n",
            " 201: True, attention.2.weight\n",
            " 202: True, attention.2.bias\n",
            " 203: True, regressor.0.weight\n",
            " 204: True, regressor.0.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYPJSbAxMTN7"
      },
      "source": [
        "### StackingModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am2WTaLaMVRQ"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PcTNCYuDeuC"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzoJMxr3DeVG"
      },
      "source": [
        "def bert_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "    \n",
        "    if \"albert-base\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:23]    \n",
        "        attention_parameters = named_parameters[25:29]\n",
        "        regressor_parameters = named_parameters[29:]\n",
        "        second_block = 999\n",
        "        third_block = 999\n",
        "\n",
        "    elif \"base\" in config.model_name or \"L-12\" in config.model_name or \"scibert\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:197]    \n",
        "        attention_parameters = named_parameters[199:203]\n",
        "        regressor_parameters = named_parameters[203:]\n",
        "        second_block = 69\n",
        "        third_block = 133\n",
        "\n",
        "    elif \"large\" in config.model_name or \"L-24\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:388]    \n",
        "        attention_parameters = named_parameters[391:395]\n",
        "        regressor_parameters = named_parameters[395:]\n",
        "        second_block = 133\n",
        "        third_block = 261\n",
        "        \n",
        "    attention_group = [params for (name, params) in attention_parameters]\n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": attention_group})\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(bert_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else config.weight_decay\n",
        "\n",
        "        lr = config.lr\n",
        "\n",
        "        if layer_num >= second_block:        \n",
        "            lr = config.lr_69\n",
        "\n",
        "        if layer_num >= third_block:\n",
        "            lr = config.lr_133\n",
        "\n",
        "        parameters.append({\"params\": params, \"weight_decay\": weight_decay, \"lr\": lr})\n",
        "\n",
        "    return T.AdamW(parameters)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de50761e"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47fcae06"
      },
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-7):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self, yhat, y):\n",
        "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
        "        return loss"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjpp5Rh-4jKW"
      },
      "source": [
        "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
        "class FBetaLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, beta=1.0, epsilon=1e-7):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
        "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
        "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "\n",
        "        beta_squared = self.beta ** 2\n",
        "        fbeta = (1 + beta_squared) * precision * recall / (beta_squared * precision + recall + self.epsilon)\n",
        "        fbeta = fbeta.clamp(min=self.epsilon, max=1-self.epsilon)\n",
        "        return 1 - fbeta.mean()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93661540"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19d9d03c"
      },
      "source": [
        "def get_score(y_true, y_pred, b=border):\n",
        "    y_pred = np.where(y_pred < b, 0, 1)\n",
        "    return fbeta_score(y_true, y_pred, beta=7.0)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1b92d4f"
      },
      "source": [
        "def get_result(result_df, fold=config.n_fold):\n",
        "    preds = result_df[\"preds\"].values\n",
        "    labels = result_df[\"judgement\"].values\n",
        "    score = get_score(labels, preds)\n",
        "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "    # wandb.log({\"fold\": fold, \"CV\": score})\n",
        "    if fold == config.n_fold:\n",
        "        wandb.run.summary[f\"CV\"] = score\n",
        "    else:\n",
        "        wandb.run.summary[f\"CV_fold{fold}\"] = score\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJUo-Mjlv_2"
      },
      "source": [
        "def determine_border(b, y_true, y_pred):\n",
        "    return -1 * get_score(y_true, y_pred, b)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf498df"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5b0e152"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNxJNSgwg-0E"
      },
      "source": [
        "def pre_train_fn():\n",
        "    tokenizer = T.AutoTokenizer.from_pretrained(config.model_name)\n",
        "    model = T.AutoModelForMaskedLM.from_pretrained(config.model_name)\n",
        "\n",
        "    tokenizer.save_pretrained(f\"./pretrained_{config.model_name}\")\n",
        "\n",
        "    train_dataset = T.LineByLineTextDataset(tokenizer=tokenizer, file_path=\"abstracts.txt\", block_size=512)\n",
        "    valid_dataset = T.LineByLineTextDataset(tokenizer=tokenizer, file_path=\"abstracts.txt\", block_size=512)\n",
        "\n",
        "    data_collator = T.DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        "    )\n",
        "\n",
        "    training_args = T.TrainingArguments(\n",
        "        output_dir = f\"./pretrained_{config.model_name}_chk\",\n",
        "        overwrite_output_dir = True,\n",
        "        num_train_epochs = 5,\n",
        "        per_device_train_batch_size = 4,\n",
        "        per_device_eval_batch_size = 4,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        evaluation_strategy = 'steps',\n",
        "        save_total_limit = 2,\n",
        "        eval_steps = 105,\n",
        "        save_steps = 105,\n",
        "        metric_for_best_model = 'eval_loss',\n",
        "        greater_is_better = False,\n",
        "        load_best_model_at_end = True,\n",
        "        prediction_loss_only = True,\n",
        "        report_to = \"wandb\",\n",
        "    )\n",
        "\n",
        "    trainer = T.Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=valid_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    trainer.save_model(f\"./pretrained_{config.model_name}\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99a3bfb5"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "            \n",
        "        if Config.apex:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "\n",
        "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(scheduler, ReduceLROnPlateau):\n",
        "                scheduler.step(avg_val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "            \n",
        "            global_step += 1\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                # f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
        "                f\"LR: {scheduler.get_lr()[0]:.6f}  \"\n",
        "            )\n",
        "\n",
        "    return losses.avg"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "186c441d"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # record score\n",
        "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        preds.append(y_preds.to(\"cpu\").numpy())\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "            )\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7cdfc9"
      },
      "source": [
        "def inference():\n",
        "    predictions = sub.copy()\n",
        "\n",
        "    for n, model_item in enumerate(inference_models):\n",
        "        test_dataset = BaseDataset(test, model_item['model_name'], include_labels=False)\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True\n",
        "        )\n",
        "\n",
        "        preds = []\n",
        "        for fold in range(config.n_fold):\n",
        "            LOGGER.info(f\"========== ID: {model_item['run_id']} model: {model_item['model_name']} fold: {fold} inference ==========\")\n",
        "            model = BaseModel(model_item['model_name'])\n",
        "            model.to(device)\n",
        "            model.load_state_dict(model_item[f\"state_fold{fold}\"])\n",
        "            model.eval()\n",
        "            fold_preds = []\n",
        "            for i, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                with torch.no_grad():\n",
        "                    y_preds = model(input_ids, attention_mask)\n",
        "                # avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "                fold_preds.append(y_preds.to(\"cpu\").numpy())\n",
        "            preds.append(np.concatenate(fold_preds))\n",
        "\n",
        "        preds = np.mean(preds, axis=0)\n",
        "\n",
        "        if config.criterion == \"BCEWithLogitsLoss\":\n",
        "            preds = 1 / (1 + np.exp(-preds))\n",
        "\n",
        "        predictions[f\"preds{n}\"] = preds\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuZncamGqu8I"
      },
      "source": [
        "def stacking_inference():\n",
        "    feature_cols = [col for col in test.columns if col.startswith(\"preds\")]\n",
        "    # predictions = sub.copy()\n",
        "\n",
        "    preds = []\n",
        "    for fold in range(config.n_fold):\n",
        "        LOGGER.info(f\"========== fold: {fold} inference ==========\")\n",
        "        bst = lgb.Booster(model_file=OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\")\n",
        "        fold_preds = bst.predict(test[feature_cols])\n",
        "        preds.append(fold_preds)\n",
        "\n",
        "    preds = np.mean(preds, axis=0)\n",
        "    # predictions[f\"preds\"] = preds\n",
        "\n",
        "    return preds"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9663c1"
      },
      "source": [
        "## Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357969e6"
      },
      "source": [
        "def train_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BaseDataset(train_folds, config.model_name)\n",
        "    valid_dataset = BaseDataset(valid_folds, config.model_name)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Optimizer\n",
        "    # ====================================================\n",
        "    def get_optimizer(model):\n",
        "        if config.optimizer == \"Adam\":\n",
        "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay, amsgrad=False)\n",
        "        elif config.optimizer == \"AdamW\":\n",
        "            optimizer = T.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "        elif config.optimizer == \"BertAdamW\":\n",
        "            optimizer = bert_optimizer(model)\n",
        "        return optimizer\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        if config.scheduler == \"ReduceLROnPlateau\":\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=config.factor, patience=config.patience, verbose=True, eps=config.eps\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=config.T_max, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(\n",
        "                optimizer, T_0=config.T_0, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
        "            scheduler = CosineAnnealingWarmupRestarts(\n",
        "                optimizer, first_cycle_steps=config.first_cycle_steps, max_lr=config.lr, min_lr=config.min_lr, warmup_steps=config.warmup_steps\n",
        "            )\n",
        "        elif config.scheduler == \"get_cosine_schedule_with_warmup\":\n",
        "            scheduler = T.get_cosine_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_training_steps=config.num_training_steps, \n",
        "                num_warmup_steps=config.num_warmup_steps\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # Model\n",
        "    # ====================================================\n",
        "    model = BaseModel(config.model_name)\n",
        "    model.to(device)\n",
        "\n",
        "    # Use multi GPU\n",
        "    if device == torch.device(\"cuda\") and not Config.apex and Config.multi_gpu:\n",
        "        model = torch.nn.DataParallel(model)  # make parallel\n",
        "        # torch.backends.cudnn.benchmark=True\n",
        "\n",
        "    optimizer = get_optimizer(model)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # Apex\n",
        "    # ====================================================\n",
        "    if Config.apex:\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "        elif config.criterion == \"MSELoss\":\n",
        "            criterion = nn.MSELoss()\n",
        "        elif config.criterion == \"RMSELoss\":\n",
        "            criterion = RMSELoss()\n",
        "        elif config.criterion == \"FBetaLoss\":\n",
        "            criterion = FBetaLoss(7.0)\n",
        "\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "    best_score = -1\n",
        "    best_loss = np.inf\n",
        "    best_preds = None\n",
        "\n",
        "    # if not Config.multi_gpu:\n",
        "    #     wandb.watch(model, log_freq=Config.print_freq)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
        "        valid_labels = valid_folds[\"judgement\"].values\n",
        "\n",
        "        # if isinstance(scheduler, ReduceLROnPlateau):\n",
        "        #     scheduler.step(avg_val_loss)\n",
        "        # else:\n",
        "        #     scheduler.step()\n",
        "\n",
        "        if config.criterion == \"BCEWithLogitsLoss\":\n",
        "            preds = 1 / (1 + np.exp(-preds))\n",
        "\n",
        "        # scoring\n",
        "        # score = get_score(valid_labels, preds.argmax(1))\n",
        "        score = get_score(valid_labels, preds)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(\n",
        "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
        "        )\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
        "\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                f\"loss/train_fold{fold}\": avg_loss,\n",
        "                f\"loss/val_fold{fold}\": avg_val_loss,\n",
        "                f\"score/fold{fold}\": score,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if (\n",
        "            (config.best == \"score\" and score > best_score)\n",
        "            or (config.best == \"loss\" and avg_val_loss < best_loss)\n",
        "        ):\n",
        "            best_score = score\n",
        "            best_loss = avg_val_loss\n",
        "            best_preds = preds\n",
        "\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model (Loss: {best_loss:.4f})\")\n",
        "            wandb.run.summary[f\"loss_fold{fold}\"] = score\n",
        "\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\"\n",
        "            )\n",
        "            wandb.save(OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "        # if epoch == config.epochs - 1:\n",
        "        #     LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
        "        #     torch.save(\n",
        "        #         {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name}_fold{fold}_final.pth\"\n",
        "        #     )\n",
        "\n",
        "    check_point = torch.load(OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "    if config.n_class == 1:\n",
        "        valid_folds[\"preds\"] = best_preds\n",
        "    else:\n",
        "        valid_folds[[str(c) for c in range(config.n_class)]] = best_preds\n",
        "        valid_folds[\"preds\"] = best_preds.argmax(1)\n",
        "\n",
        "    return valid_folds"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8mXDD4u0G3R"
      },
      "source": [
        "## Stack loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VejK7F2hzIsK"
      },
      "source": [
        "def stack_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # ====================================================\n",
        "    # Dataset\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    feature_cols = [col for col in df.columns if col.startswith(\"preds\")]\n",
        "    label_cols = [\"judgement\"]\n",
        "\n",
        "    train_dataset = lgb.Dataset(data=train_folds[feature_cols], label=train_folds[label_cols], free_raw_data=False)\n",
        "    valid_dataset = lgb.Dataset(data=valid_folds[feature_cols], label=valid_folds[label_cols], free_raw_data=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # Parameters\n",
        "    # ====================================================\n",
        "\n",
        "    lgb_params = {\n",
        "        \"objective\": config.objective,\n",
        "        \"metric\": config.criterion,\n",
        "        \"num_class\": config.n_class,\n",
        "        \"device_type\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "        \"seed\": seed + fold,\n",
        "        \"verbosity\": -1,\n",
        "    }\n",
        "\n",
        "    if not Config.stack_optuna:\n",
        "        lgb_params_manual = {\n",
        "            \"learning_rate\": config.lr,\n",
        "            \"max_depth\": config.max_depth,\n",
        "            \"num_leaves\": config.num_leaves,\n",
        "            \"min_data_in_leaf\": config.min_data_in_leaf,\n",
        "            \"drop_rate\": config.dropout,\n",
        "        }\n",
        "        lgb_params.update(lgb_params_manual)\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "\n",
        "    evaluation_results = {}\n",
        "    clf = lgb.train(\n",
        "        params=lgb_params,\n",
        "        train_set=train_dataset,\n",
        "        num_boost_round=10000,\n",
        "        valid_sets=[train_dataset, valid_dataset], \n",
        "        valid_names=['train', 'eval'],\n",
        "        early_stopping_rounds=100,\n",
        "        evals_result=evaluation_results,\n",
        "        verbose_eval=100,\n",
        "    )\n",
        "\n",
        "    importances = pd.DataFrame({\n",
        "        'features': clf.feature_name(),\n",
        "        'importance': clf.feature_importance()\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    preds = clf.predict(valid_folds[feature_cols], num_iteration=clf.best_iteration)\n",
        "    valid_labels = valid_folds[\"judgement\"].values\n",
        "\n",
        "    if Config.stack_optuna:\n",
        "        LOGGER.info(f\"Best Params {fold} - {clf.params}\")\n",
        "\n",
        "    # scoring\n",
        "    if config.n_class == 1:\n",
        "        score = get_score(valid_labels, preds)\n",
        "    else:\n",
        "        score = get_score(valid_labels, preds.argmax(1))\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    LOGGER.info(f\"Result {fold} - Score: {score}, time: {elapsed:.0f}s\")\n",
        "\n",
        "    LOGGER.info(f\"Result {fold} - Save Best Model\")\n",
        "    # wandb.run.summary[f\"loss_fold{fold}\"] = score\n",
        "\n",
        "    clf.save_model(OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\", clf.best_iteration)\n",
        "    wandb.save(OUTPUT_DIR + f\"lgb_fold{fold}_best.txt\")\n",
        "\n",
        "    if config.n_class == 1:\n",
        "        valid_folds[\"preds\"] = preds\n",
        "    else:\n",
        "        valid_folds[[str(c) for c in range(config.n_class)]] = preds\n",
        "        valid_folds[\"preds\"] = preds.argmax(1)\n",
        "\n",
        "    return valid_folds"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97b42fa3"
      },
      "source": [
        "## Main\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5baf150d"
      },
      "source": [
        "def main():\n",
        "    # ====================================================\n",
        "    # Pre Training\n",
        "    # ====================================================\n",
        "    if Config.pre_train:\n",
        "        abstract_df = pd.concat([train[\"abstract\"], test[\"abstract\"]])\n",
        "        abstracts  = '\\n'.join(abstract_df.tolist())\n",
        "        with open(\"abstracts.txt\", \"w\") as f:\n",
        "            f.write(abstracts)\n",
        "\n",
        "        pre_train_fn()\n",
        "\n",
        "    # ====================================================\n",
        "    # Training\n",
        "    # ====================================================\n",
        "    if Config.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df = train_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "            \n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        \n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Validation\n",
        "    # ====================================================\n",
        "    if Config.validate:\n",
        "        probs = []\n",
        "        borders = []\n",
        "        class_cols = []\n",
        "\n",
        "        for n in range(len(config.inference_runs)):\n",
        "            probs.append(train[f\"preds{n}\"].values)\n",
        "\n",
        "            if config.border == \"minimize\":\n",
        "                res = sp.optimize.minimize_scalar(\n",
        "                    determine_border,\n",
        "                    method='bounded',\n",
        "                    bounds=(0, 1),\n",
        "                    args=(train[\"judgement\"].values, train[f\"preds{n}\"].values)\n",
        "                )\n",
        "                b = res.x\n",
        "\n",
        "                # CV result\n",
        "                LOGGER.info(f\"========== Border Optimization ==========\")\n",
        "                LOGGER.info(f\"Border: {b:<.5f}, Score: {-res.fun:<.5f}\")\n",
        "\n",
        "            else:\n",
        "                raise f\"Invalid config.border parameter: {config.border}\"\n",
        "\n",
        "            borders.append(b)\n",
        "            class_cols.append(f\"class_preds{n}\")\n",
        "            train[f\"class_preds{n}\"] = np.where(train[f\"preds{n}\"].values < b, 0, 1)\n",
        "\n",
        "        train[\"voting\"] = train[class_cols].sum(axis=1)\n",
        "        train[\"preds\"] = np.where(train[\"voting\"].values < len(config.inference_runs) / 2, 0, 1)\n",
        "\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(train)\n",
        "\n",
        "        # save result\n",
        "        train.to_csv(OUTPUT_DIR + \"validation_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"validation_df.csv\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Inference\n",
        "    # ====================================================\n",
        "    if Config.inference:\n",
        "        prediction_df = inference()\n",
        "\n",
        "        probs = []\n",
        "        for n in range(len(config.inference_runs)):\n",
        "            probs.append(prediction_df[f\"preds{n}\"].values)\n",
        "\n",
        "            prediction_df[f\"class_preds{n}\"] = np.where(prediction_df[f\"preds{n}\"].values < borders[n], 0, 1)\n",
        "\n",
        "        prediction_df[\"voting\"] = prediction_df[class_cols].sum(axis=1)\n",
        "        prediction_df[\"preds\"] = np.where(prediction_df[\"voting\"].values < len(config.inference_runs) / 2, 0, 1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = prediction_df[\"preds\"]  # .argmax(1)\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n",
        "\n",
        "        prediction_df.to_csv(OUTPUT_DIR + \"prediction_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"prediction_df.csv\")\n",
        "        \n",
        "    # ====================================================\n",
        "    # Stack\n",
        "    # ====================================================\n",
        "    if Config.stack:\n",
        "        # Training\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df = stack_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "\n",
        "        # CV result\n",
        "        if config.n_class > 1 or config.border == \"fixed\":\n",
        "            # CV result\n",
        "            LOGGER.info(f\"========== CV ==========\")\n",
        "            get_result(oof_df)\n",
        "            b = border\n",
        "\n",
        "        elif config.border == \"minimize\":\n",
        "            res = sp.optimize.minimize_scalar(determine_border, method='bounded', bounds=(0, 1), args=(oof_df[\"judgement\"].values, oof_df[\"preds\"].values))\n",
        "            LOGGER.info(f\"========== CV: Border Optimization ==========\")\n",
        "            LOGGER.info(f\"Border: {res.x:<.5f}, Score: {-res.fun:<.5f}\")\n",
        "            wandb.run.summary[f\"CV\"] = -res.fun\n",
        "            b = res.x\n",
        "\n",
        "        if config.n_class == 1:\n",
        "            wandb.run.summary[f\"border\"] = b\n",
        "\n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"stacking_oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"stacking_oof_df.csv\")\n",
        "\n",
        "        # Inference\n",
        "        preds = stacking_inference()\n",
        "\n",
        "        if config.n_class == 1:\n",
        "            predictions = np.where(preds < b, 0, 1)\n",
        "        else:\n",
        "            predictions = preds.argmax(1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = predictions\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n",
        "\n",
        "        if config.n_class == 1:\n",
        "            sub[\"preds\"] = preds\n",
        "        else:\n",
        "            sub[[str(c) for c in range(config.n_class)]] = preds\n",
        "            sub[\"preds\"] = preds.argmax(1)\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"stacking_prediction_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"stacking_prediction_df.csv\")\n",
        "                \n",
        "    # ====================================================\n",
        "    # Ensemble\n",
        "    # ====================================================\n",
        "    if Config.ensemble:\n",
        "        cols = [c for c in train.columns if c.startswith(\"preds\") and c != \"preds\"]\n",
        "\n",
        "        train[\"voting\"] = train[cols].sum(axis=1)\n",
        "        train[\"preds\"] = np.where(train[\"voting\"].values < len(cols) / 2, 0, 1)\n",
        "\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(train)\n",
        "\n",
        "        test[\"voting\"] = test[cols].sum(axis=1)\n",
        "        test[\"preds\"] = np.where(test[\"voting\"].values < len(cols) / 2, 0, 1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = test[\"preds\"]  # .argmax(1)\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n",
        "\n",
        "        test.to_csv(OUTPUT_DIR + \"prediction_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"prediction_df.csv\")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656,
          "referenced_widgets": [
            "3a8d50389dea45f7b94652df677d2a30",
            "4ab45bc32abb4110b7bffc8042a55648",
            "216bec62b1e74fea8bbddca167240fab",
            "2fb794b57ba8487d869d49e443362b22",
            "81a61033a796439c97cbdd7a37670f27",
            "05953a1501d044cf8037fa69366d11df",
            "7ace466f23ab45d48ae1f7a412f95416",
            "a30ac326d9d94c1298ad2f0b6a305d2f",
            "92a5c3fc458644579c7571ed95208d76",
            "9483f04f06c7419cae60ad4e85c26bb1",
            "402be2621625424fbf3b4cb08a32d459",
            "1f21d55281c84ad680d0d92701db4c99",
            "a84b48721a2146c680cd6cb07f5d87f8",
            "0f24eec12f6249b9975ba039bc1e1802",
            "185550b3401e466495a9a997e8a4de08",
            "1d2643b73c424e689bf18d80c9711315",
            "6f4a992c673e4f8298353155b21ac3ea",
            "23a1023882d640c593b9f235d442f643",
            "ba61cf57c0224b6e892c1a0c93ee4308",
            "d90490f83fae42d4bbbd16c1ee692cba",
            "fa46ef39cbbb4ea28b0766dd6f0baa66",
            "32697224365b4f17b89e6893d9416460",
            "810ce31e825545689d25d7560454805e",
            "5ea437e74cf646078eea34c31441b605",
            "557faa340e3f4577ada31dd183614bf2",
            "04a1c6ae27eb485ebb8c48a69f07f63f",
            "eec1a153f4c94a338e05120cfffe3ed0",
            "1c6eac2043634994b83fd92a5344e44c",
            "79f56ebd16e5448babf2c2e529463c98",
            "9f9a20b671954431892ce65ad33b5eb7",
            "1c140c5b2fa24ba3a0dc0227f5bb012b",
            "1f731650f31d40819a08dac9ebebafe2",
            "4f4b395c63d645659af04d01b498af9f",
            "f11fbbdca4b843bd9333f4bb9cfff551",
            "70dd66973ccf47f680bd67a12689cd8b",
            "1b6dfe5b0bb0469fa069a35af4e95173",
            "49ba582c6913449f923350bebadaedaf",
            "8f76c266aa2347f8a17f84bb38b7c924",
            "81c02dc5926b44b9bd21a776dd5355be",
            "f335418c9ad54743aac05d7bca55dfd6",
            "59af51e484854399bb51889cde0b827e",
            "96c32a8687f641ce952e5c22d0f874fe",
            "e2f9101587c34350b1133c938e00c917",
            "4bfbce35b4734b1db15f35cd26ed58b6",
            "3742439a25194100ad57c4403a640861",
            "bba4aeb9f64e4a4982114ca6df74cac8",
            "13abde03a1fc47dca838adac0eea7981",
            "dc55445b4ae7474687d27c1200ea4917",
            "d150a39610514740a37250bd931152f6",
            "80fcd8f206a643f398f5bbd2a216c5c0",
            "1a24945ff02b439c97f4f61e8824322f",
            "450e50ae650a487895a64191eb8b66d9",
            "9430e9e57b1b46f6980a7c76523ee8dc",
            "330137091550422e8ced598c1f48dcf1",
            "67cc3097e2e4401896f1e20464d6637c"
          ]
        },
        "id": "726e744f",
        "outputId": "c70a0d9d-f64b-4210-bdbc-c151304c25b2"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== Border Optimization ==========\n",
            "Border: 0.01270, Score: 0.90368\n",
            "========== CV ==========\n",
            "Score: 0.90368\n",
            "========== ID: 1ostvjfa model: dmis-lab/biobert-base-cased-v1.1-squad fold: 0 inference ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a8d50389dea45f7b94652df677d2a30",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3403 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== ID: 1ostvjfa model: dmis-lab/biobert-base-cased-v1.1-squad fold: 1 inference ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f21d55281c84ad680d0d92701db4c99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3403 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== ID: 1ostvjfa model: dmis-lab/biobert-base-cased-v1.1-squad fold: 2 inference ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "810ce31e825545689d25d7560454805e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3403 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== ID: 1ostvjfa model: dmis-lab/biobert-base-cased-v1.1-squad fold: 3 inference ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f11fbbdca4b843bd9333f4bb9cfff551",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3403 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== ID: 1ostvjfa model: dmis-lab/biobert-base-cased-v1.1-squad fold: 4 inference ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3742439a25194100ad57c4403a640861",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3403 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    38073\n",
            "1     2761\n",
            "Name: judgement, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "ba4e10a3e7f54f8798b2ded6051497ec",
            "50c79b914cd24e0a9b53d2cf5588cff5",
            "e947eb7ca8594698b67559323e3d13c0",
            "4c9cb27b6b0e4fe18082f7fa3a3929f0",
            "52bf12190fef4733bf66d320951b4de9",
            "6c8a29529e7b424cbe422574c39e1f98",
            "dd10742a8e8b4b6c855dcfc9bf205d34",
            "1f98e0cf04fa4ef19c62be6802568f40"
          ]
        },
        "id": "CPHezhr_NHYR",
        "outputId": "a596b597-e828-408f-cda4-16379eb93ad3"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 7126<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba4e10a3e7f54f8798b2ded6051497ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 78.66MB of 78.66MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210905_160034-1zwt0m0n/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210905_160034-1zwt0m0n/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>CV</td><td>0.90368</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 47 artifact file(s) and 4 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">fanciful-rain-76</strong>: <a href=\"https://wandb.ai/ponkots/signate-471/runs/1zwt0m0n\" target=\"_blank\">https://wandb.ai/ponkots/signate-471/runs/1zwt0m0n</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-scfhV4ueW4K"
      },
      "source": [
        "## Public LB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNsH2CvA1He"
      },
      "source": [
        "RUN_PATH = \"\"\n",
        "LB_SCORE = None"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS7aRYF_eh7z"
      },
      "source": [
        "if LB_SCORE is not None:\n",
        "    import wandb\n",
        "    api = wandb.Api()\n",
        "\n",
        "    run = api.run(RUN_PATH)\n",
        "    run.summary[\"LB\"] = LB_SCORE\n",
        "    run.summary.update()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANpuUeypNmLF"
      },
      "source": [
        ""
      ],
      "execution_count": 72,
      "outputs": []
    }
  ]
}