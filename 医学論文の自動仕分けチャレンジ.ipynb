{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "医学論文の自動仕分けチャレンジ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37db41e2b3814a1392392423a2ef00ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aeb8fd5b936c46349e058cb3fcb21599",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b07849e163754725b968f6bd3009ac30",
              "IPY_MODEL_545a96d075664ed3a0fdf9047c6f1f70"
            ]
          }
        },
        "aeb8fd5b936c46349e058cb3fcb21599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b07849e163754725b968f6bd3009ac30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_65a1974553ae4195b7ac49b305779382",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 75.45MB of 75.45MB uploaded (0.16MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73896f8541d945e29c80f2dbdd1df4ae"
          }
        },
        "545a96d075664ed3a0fdf9047c6f1f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f632af6f00fc483596c40170abd78612",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fa1b6b7c0564ad49d41540222b1304f"
          }
        },
        "65a1974553ae4195b7ac49b305779382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73896f8541d945e29c80f2dbdd1df4ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f632af6f00fc483596c40170abd78612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fa1b6b7c0564ad49d41540222b1304f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/signate-471/blob/main/%E5%8C%BB%E5%AD%A6%E8%AB%96%E6%96%87%E3%81%AE%E8%87%AA%E5%8B%95%E4%BB%95%E5%88%86%E3%81%91%E3%83%81%E3%83%A3%E3%83%AC%E3%83%B3%E3%82%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e4660c1"
      },
      "source": [
        "# About this notebook ...\n",
        "\n",
        "competition site: https://signate.jp/competitions/471\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dhs2SIWJzKz"
      },
      "source": [
        "## ToDo\n",
        "\n",
        "### Idea\n",
        "\n",
        "- [ ] 分類で推論、回帰で推論\n",
        "- [x] 回帰の場合の境界値の最適化\n",
        "    - [ ] second stage で学習べきかも\n",
        "- [ ] アブストで事前学習して、タイトルでメイン学習 https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n",
        "- [x] タイトルだけで学習・推論\n",
        "- [ ] タイトル + アブストで学習・推論\n",
        "    - [ ] タイトルだけで推論したのとアンサンブルができる\n",
        "- [ ] アブストが空 or not でモデルわける\n",
        "- [ ] アブストの max length 調整\n",
        "    - [ ] 途中で切る\n",
        "    - [ ] 要約する方法があるかなぁ\n",
        "- [ ] 出現する単語のクラスタリング\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68842c71"
      },
      "source": [
        "## Prepare for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14137a0f",
        "outputId": "8b897e10-d5be-42c4-edf8-2f6293945367"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul 30 06:37:27 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    37W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4871daf1",
        "outputId": "85f02ecd-e2d9-4e7b-b674-3df668480ede"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if os.path.exists('init.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    if 'google.colab' in sys.modules:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/gdrive')\n",
        "\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/train.csv .\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/test.csv .\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/sample_submit.csv .\n",
        "\n",
        "    # for StratifiedGroupKFold\n",
        "    # !pip uninstall -y scikit-learn\n",
        "    # !pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn\n",
        "\n",
        "    # for MultilabelStratifiedKFold\n",
        "    !pip install -q iterative-stratification\n",
        "\n",
        "    # !pip install -qU 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n",
        "\n",
        "    !pip install -q wandb\n",
        "    !pip install -q transformers\n",
        "    # !pip install textstat\n",
        "\n",
        "    !touch init.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already initialized.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c39b7222"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63096cb"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "# import textstat\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers as T\n",
        "import wandb\n",
        "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, fbeta_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold  # , StratifiedGroupKFold\n",
        "from torch.optim import SGD, Adam  # , AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c830faec"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16eb8ed5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc53e8c",
        "outputId": "d56d0771-b59d-4106-b6f6-097fdc867f3c"
      },
      "source": [
        "netrc = \"../input/wandbtoken/.netrc\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    netrc = \"/gdrive/MyDrive/.netrc\"\n",
        "\n",
        "!cp -f {netrc} ~/\n",
        "\n",
        "!wandb login"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB5QkUQJq_6U"
      },
      "source": [
        "wandb_job_type = \"\"\n",
        "wandb_notes = \"\"\n",
        "wandb_tags = []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71d9ccbd"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a62a05f"
      },
      "source": [
        "DATA_DIR = \"../input/commonlitreadabilityprize/\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_DIR = \"./\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26350797"
      },
      "source": [
        "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
        "sub = pd.read_csv(DATA_DIR + \"sample_submit.csv\", header=None)\n",
        "sub.columns = [\"id\", \"judgement\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4fTaf66DiXj"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1C7cU7ka70h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63de6273-d3a0-4a72-c95e-0e8a4b6b3722"
      },
      "source": [
        "# アブストが空っぽのが結構ある\n",
        "\n",
        "print(train.isnull().sum())\n",
        "train.fillna(\"\", inplace=True)\n",
        "\n",
        "print(test.isnull().sum())\n",
        "test.fillna(\"\", inplace=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id              0\n",
            "title           0\n",
            "abstract     4390\n",
            "judgement       0\n",
            "dtype: int64\n",
            "id             0\n",
            "title          0\n",
            "abstract    6546\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHfTQdU8Cezv",
        "outputId": "deb5f621-4636-4bd7-a633-f94b1cf1023b"
      },
      "source": [
        "# title の単語数\n",
        "\n",
        "train[\"len_title\"] = train[\"title\"].apply(lambda x: len(x.split()))\n",
        "test[\"len_title\"] = test[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "print(train[\"len_title\"].max())\n",
        "print(test[\"len_title\"].max())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n",
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx2M2402NSOU",
        "outputId": "139bbea8-79a2-4a5c-8d06-07cf1b7bfad7"
      },
      "source": [
        "# abstract の単語数\n",
        "\n",
        "train[\"len_abstract\"] = train[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "test[\"len_abstract\"] = test[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "print(train[\"len_abstract\"].max())\n",
        "print(test[\"len_abstract\"].max())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1535\n",
            "1445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRjWzXcYOYNn"
      },
      "source": [
        "# abstract のあるなしを StratifiedKFold に使う\n",
        "\n",
        "train[\"nan_abstract\"] = np.where(train[\"len_abstract\"] == 0, 1, 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1WviNuCdGec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7107abf6-2946-4bce-c959-9471a0f61959"
      },
      "source": [
        "# title と abstract を結合\n",
        "\n",
        "train[\"title_abstract\"] = train[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "test[\"title_abstract\"] = test[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "train[\"len_title_abstract\"] = train[\"title_abstract\"].apply(lambda x: len(x.split()))\n",
        "test[\"len_title_abstract\"] = test[\"title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "print(train[\"len_title_abstract\"].max())\n",
        "print(test[\"len_title_abstract\"].max())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1537\n",
            "1457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "18097672",
        "outputId": "a32dc069-3761-419d-fe8d-e6b0d793b26e"
      },
      "source": [
        "for ds in [train, test, sub]:\n",
        "    print(f\"=\" * 80)\n",
        "    ds.info()\n",
        "    display(ds.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27145 entries, 0 to 27144\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   id                  27145 non-null  int64 \n",
            " 1   title               27145 non-null  object\n",
            " 2   abstract            27145 non-null  object\n",
            " 3   judgement           27145 non-null  int64 \n",
            " 4   len_title           27145 non-null  int64 \n",
            " 5   len_abstract        27145 non-null  int64 \n",
            " 6   nan_abstract        27145 non-null  int64 \n",
            " 7   title_abstract      27145 non-null  object\n",
            " 8   len_title_abstract  27145 non-null  int64 \n",
            "dtypes: int64(6), object(3)\n",
            "memory usage: 1.9+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>judgement</th>\n",
              "      <th>len_title</th>\n",
              "      <th>len_abstract</th>\n",
              "      <th>nan_abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>len_title_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>Longitudinal studies indicate that declines in...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>193</td>\n",
              "      <td>0</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>The present study was undertaken to validate t...</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>Objective: To report a case series in which ba...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>133</td>\n",
              "      <td>0</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>374</td>\n",
              "      <td>0</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... len_title_abstract\n",
              "0   0  ...                203\n",
              "1   1  ...                237\n",
              "2   2  ...                143\n",
              "3   3  ...                387\n",
              "4   4  ...                 16\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   id                  40834 non-null  int64 \n",
            " 1   title               40834 non-null  object\n",
            " 2   abstract            40834 non-null  object\n",
            " 3   len_title           40834 non-null  int64 \n",
            " 4   len_abstract        40834 non-null  int64 \n",
            " 5   title_abstract      40834 non-null  object\n",
            " 6   len_title_abstract  40834 non-null  int64 \n",
            "dtypes: int64(4), object(3)\n",
            "memory usage: 2.2+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>len_title</th>\n",
              "      <th>len_abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>len_title_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27145</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>The objective of the paper is to analyse chang...</td>\n",
              "      <td>16</td>\n",
              "      <td>245</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27146</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td></td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27147</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
              "      <td>14</td>\n",
              "      <td>315</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27148</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>We present a method that significantly improve...</td>\n",
              "      <td>11</td>\n",
              "      <td>119</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27149</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>The objective of this study is to compare the ...</td>\n",
              "      <td>13</td>\n",
              "      <td>224</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ... len_title_abstract\n",
              "0  27145  ...                261\n",
              "1  27146  ...                  8\n",
              "2  27147  ...                329\n",
              "3  27148  ...                130\n",
              "4  27149  ...                237\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype\n",
            "---  ------     --------------  -----\n",
            " 0   id         40834 non-null  int64\n",
            " 1   judgement  40834 non-null  int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 638.2 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>judgement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27146</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27147</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  judgement\n",
              "0  27145          0\n",
              "1  27146          1\n",
              "2  27147          1\n",
              "3  27148          0\n",
              "4  27149          1"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9L3nMYzDMqJ"
      },
      "source": [
        "### 目的変数 judgement の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "3f5772d0",
        "outputId": "fd744930-fb66-49d9-f187-136b8d5881a8"
      },
      "source": [
        "sns.distplot(train[\"judgement\"], kde=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24b94fda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuZVvlM8Xy91",
        "outputId": "f7632f53-2104-4d16-e293-fe879f367ad9"
      },
      "source": [
        "train[\"judgement\"].value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    26513\n",
              "1      632\n",
              "Name: judgement, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E-56356_L3T",
        "outputId": "1dc1e0a0-4e0a-4b49-bf78-680d2fbcda8e"
      },
      "source": [
        "border = len(train[train[\"judgement\"] == 1]) / len(train[\"judgement\"])\n",
        "print(border)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.023282372444280715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZNrZoksDSMb"
      },
      "source": [
        "### title の単語数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "ixixzShVH80j",
        "outputId": "fd080e67-a0cd-484c-e33e-00bd50d24845"
      },
      "source": [
        "g = sns.FacetGrid(train[[\"judgement\", \"len_title\"]], hue='judgement')\n",
        "g.map(sns.distplot, 'len_title', label='judgement', hist=True, rug=False)\n",
        "g.add_legend()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f24b8947ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 278.125x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W_kt9XDpGTm2",
        "outputId": "71eb2fc3-071d-4396-8766-badb5e4c4b3a"
      },
      "source": [
        "sns.distplot(test[\"len_title\"], hist=True, rug=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24b72c42d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6gm9NCpDZ6V"
      },
      "source": [
        "### title + abstract の単語数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "EqwDn4hUImd6",
        "outputId": "334f98bb-bff7-4251-a958-41abc33875cb"
      },
      "source": [
        "g = sns.FacetGrid(train[[\"judgement\", \"len_title_abstract\"]], hue='judgement')\n",
        "g.map(sns.distplot, 'len_title_abstract', label='judgement', hist=True, rug=False)\n",
        "g.add_legend()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f24b7933e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 278.125x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "xHnKSMahIqI7",
        "outputId": "385563bb-598e-4927-d578-19a5deded819"
      },
      "source": [
        "sns.distplot(test[\"len_title_abstract\"], hist=True, rug=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24b793c2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7ef06f8"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0177571"
      },
      "source": [
        "class Config:\n",
        "    wandb_entity = \"imokuri\"\n",
        "    wandb_project = \"signate-471\"\n",
        "    print_freq = 100\n",
        "\n",
        "    train = False\n",
        "    validate = True\n",
        "    inference = True\n",
        "\n",
        "    debug = False\n",
        "    multi_gpu = False\n",
        "    apex = False\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a195fe0"
      },
      "source": [
        "if Config.train:\n",
        "    wandb_job_type = \"training\"\n",
        "\n",
        "elif Config.inference:\n",
        "    wandb_job_type = \"inference\"\n",
        "\n",
        "elif Config.validate:\n",
        "    wandb_job_type = \"validation\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccb61787"
      },
      "source": [
        "if Config.apex:\n",
        "    from apex import amp"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWDHvHvNxoD3",
        "outputId": "97d23c45-79e1-4c63-f875-4fcd69e48cef"
      },
      "source": [
        "# seed = random.randrange(10000)\n",
        "seed = 440\n",
        "\n",
        "print(seed)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daf057a9"
      },
      "source": [
        "config_defaults = {\n",
        "    \"seed\": seed,\n",
        "    \"input\": \"title\", # \"title_abstract\",\n",
        "    \"max_len\": 72,\n",
        "    \"border\": \"minimize\", # \"fixed\", \"minimize\",\n",
        "    \"n_class\": 1,\n",
        "    \"n_fold\": 5,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"max_grad_norm\": 1000,\n",
        "    \"num_workers\": 4,\n",
        "    \"batch_size\": 16,\n",
        "    \"epochs\": 3,\n",
        "    \"optimizer\": \"BertAdamW\",\n",
        "    \"scheduler\": \"get_cosine_schedule_with_warmup\",\n",
        "    \"criterion\": \"BCEWithLogitsLoss\",\n",
        "    \"lr\": 2e-5,\n",
        "    \"min_lr\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"model_name\": \"bert-base-uncased\",  # \"roberta-base\", \n",
        "    \"inference_runs\": [\n",
        "        \"11pgifed\", # 13\n",
        "    ],\n",
        "}\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R1iTgjB7N7-"
      },
      "source": [
        "tokenizer = T.AutoTokenizer.from_pretrained(config_defaults[\"model_name\"])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUQbknvvbZR5"
      },
      "source": [
        "if not Config.validate and not Config.inference:\n",
        "    config_defaults[\"inference_runs\"] = []"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd440361"
      },
      "source": [
        "if Config.debug:\n",
        "    config_defaults[\"epochs\"] = 1\n",
        "    Config.print_freq = 10"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgjHEBuwETmp"
      },
      "source": [
        "if config_defaults[\"optimizer\"] == \"BertAdamW\":\n",
        "    config_defaults[\"lr_69\"] = 5e-5\n",
        "    config_defaults[\"lr_133\"] = 1e-4\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a710ed",
        "outputId": "f8ae0a9e-3031-4534-bc9a-a1c7b461461b"
      },
      "source": [
        "# Update by epoch\n",
        "# num_steps = config_defaults[\"epochs\"]\n",
        "\n",
        "# Update by batch\n",
        "num_data = 1000 if Config.debug else len(train)\n",
        "num_steps = num_data // config_defaults[\"n_fold\"] * (config_defaults[\"n_fold\"] - 1) // config_defaults[\"batch_size\"] // config_defaults[\"gradient_accumulation_steps\"] * config_defaults[\"epochs\"]\n",
        "\n",
        "print(num_steps)\n",
        "\n",
        "if config_defaults[\"scheduler\"] == \"CosineAnnealingWarmRestarts\":\n",
        "    config_defaults[\"T_0\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingLR\":\n",
        "    config_defaults[\"T_max\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
        "    config_defaults[\"factor\"] = 0.2\n",
        "    config_defaults[\"patience\"] = 4\n",
        "    config_defaults[\"eps\"] = 1e-6\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingWarmupRestarts\":\n",
        "    config_defaults[\"first_cycle_steps\"] = num_steps\n",
        "    config_defaults[\"warmup_steps\"] = num_steps // 10\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"get_cosine_schedule_with_warmup\":\n",
        "    config_defaults[\"num_training_steps\"] = num_steps\n",
        "    config_defaults[\"num_warmup_steps\"] = max(50, num_steps // 10)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6a78770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5c0c2e25-8f27-45b1-bf20-7432ff14c46d"
      },
      "source": [
        "if Config.debug:\n",
        "    wandb.init(project=Config.wandb_project, config=config_defaults, mode=\"disabled\")\n",
        "else:\n",
        "    wandb.init(project=Config.wandb_project, config=config_defaults, notes=wandb_notes, tags=wandb_tags, job_type=wandb_job_type, save_code=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.11.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">firm-shadow-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/imokuri/signate-471\" target=\"_blank\">https://wandb.ai/imokuri/signate-471</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/imokuri/signate-471/runs/c8y0phpv\" target=\"_blank\">https://wandb.ai/imokuri/signate-471/runs/c8y0phpv</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210730_063750-c8y0phpv</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2408ee43"
      },
      "source": [
        "config = wandb.config"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeZesLBHnfl5"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOdN4h2grTzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aead4f8-b168-42e4-8c87-db972652b329"
      },
      "source": [
        "if Config.validate:\n",
        "    api = wandb.Api()\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        try:\n",
        "            run.file(\"oof_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        oof = pd.read_csv(f\"{run_id}/oof_df.csv\")[[\"id\", \"preds\"]]\n",
        "        oof.columns = [\"id\", f\"preds{n}\"]\n",
        "        train = pd.merge(train, oof, on=\"id\")\n",
        "    \n",
        "    print(train.columns)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['id', 'title', 'abstract', 'judgement', 'len_title', 'len_abstract',\n",
            "       'nan_abstract', 'title_abstract', 'len_title_abstract', 'preds0'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM2fDBrNi2_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf9e515-8370-4246-9867-d0e29c77125f"
      },
      "source": [
        "if Config.inference:\n",
        "    api = wandb.Api()\n",
        "    inference_models = []\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        inference_model = {}\n",
        "        inference_model[\"run_id\"] = run_id\n",
        "        inference_model[\"model_name\"] = run.config[\"model_name\"]\n",
        "\n",
        "        for fold in range(config.n_fold):\n",
        "            try:\n",
        "                run.file(f\"{inference_model['model_name']}_fold{fold}_best.pth\").download(run_id)\n",
        "            except wandb.CommError:\n",
        "                # Already downloaded.\n",
        "                pass\n",
        "\n",
        "            model_preds = torch.load(f\"{run_id}/{inference_model['model_name']}_fold{fold}_best.pth\")\n",
        "            inference_model[f\"state_fold{fold}\"] = model_preds[\"model\"]\n",
        "            inference_model[f\"preds_fold{fold}\"] = model_preds[\"preds\"]\n",
        "\n",
        "        inference_models.append(inference_model)\n",
        "    \n",
        "    print({m['run_id']: m['model_name'] for m in inference_models})"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'11pgifed': 'bert-base-uncased'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba31d893"
      },
      "source": [
        "if Config.debug:\n",
        "    train = train.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    test = test.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    sub = sub.sample(n=1000, random_state=config.seed).reset_index(drop=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d423ea8"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5985d91d"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=config.seed)\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d35d3bc"
      },
      "source": [
        "## CV Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a604e6e",
        "outputId": "2fd1c13a-cef9-4487-bfdf-21615564d2d1"
      },
      "source": [
        "folds = train.copy()\n",
        "Fold = MultilabelStratifiedKFold(n_splits=config.n_fold, shuffle=True, random_state=config.seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[[\"judgement\", \"nan_abstract\"]])):\n",
        "    folds.loc[val_index, \"fold\"] = int(n)\n",
        "folds[\"fold\"] = folds[\"fold\"].astype(np.uint8)\n",
        "print(folds.groupby([\"fold\", \"judgement\", \"nan_abstract\"]).size())\n",
        "# print(folds.groupby([\"fold\"]).size())\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold  judgement  nan_abstract\n",
            "0     0          0               4456\n",
            "                 1                847\n",
            "      1          0                 95\n",
            "                 1                 31\n",
            "1     0          0               4444\n",
            "                 1                858\n",
            "      1          0                107\n",
            "                 1                 20\n",
            "2     0          0               4456\n",
            "                 1                847\n",
            "      1          0                 95\n",
            "                 1                 31\n",
            "3     0          0               4441\n",
            "                 1                862\n",
            "      1          0                110\n",
            "                 1                 16\n",
            "4     0          0               4448\n",
            "                 1                854\n",
            "      1          0                103\n",
            "                 1                 24\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596efb85"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2721636"
      },
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, df, include_labels=True):\n",
        "        self.df = df\n",
        "        self.include_labels = include_labels\n",
        "\n",
        "        self.title = df[config.input].tolist()\n",
        "        self.encoded = tokenizer.batch_encode_plus(\n",
        "            self.title,\n",
        "            padding = 'max_length',            \n",
        "            max_length = config.max_len,\n",
        "            truncation = True,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        \n",
        "        if self.include_labels:\n",
        "            self.labels = df[\"judgement\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = torch.tensor(self.encoded['input_ids'][idx])\n",
        "        attention_mask = torch.tensor(self.encoded['attention_mask'][idx])\n",
        "\n",
        "        if self.include_labels:\n",
        "            label = torch.tensor(self.labels[idx]).float()\n",
        "            return input_ids, attention_mask, label\n",
        "\n",
        "        return input_ids, attention_mask\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e56a1c49",
        "outputId": "dfe278f3-c92c-4022-887d-4e5fcb8ebce8"
      },
      "source": [
        "# Test\n",
        "\n",
        "train_ds = BaseDataset(train)\n",
        "\n",
        "for i in range(1):\n",
        "    input_ids, attention_mask, label = train_ds[i]\n",
        "    print(input_ids)\n",
        "    print(attention_mask)\n",
        "    print(f\"label: {label}\")\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,  2028,  1011,  2095,  2287,  3431,  1999, 27011,  4167,  6702,\n",
            "         1999,  3080,  6001,  1012,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "label: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d681dabf"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHPwf3JzPmjI",
        "outputId": "9b32c1c8-7a41-42e5-d339-5eb76738fc74"
      },
      "source": [
        "T.AutoConfig.from_pretrained(config.model_name)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.9.1\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "229d18e7"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        if config.model_name in [\"roberta-base\", \"bert-base-uncased\"]:\n",
        "            out_dim = 768\n",
        "        elif config.model_name == \"roberta-large\":\n",
        "            out_dim = 1024\n",
        "\n",
        "        auto_config = T.AutoConfig.from_pretrained(config.model_name)\n",
        "        auto_config.update({\n",
        "            \"output_hidden_states\": True,\n",
        "            # \"hidden_dropout_prob\": 0.1,\n",
        "            # \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "        \n",
        "        self.auto_model = T.AutoModel.from_pretrained(config.model_name, config=auto_config)  \n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(out_dim, 512),            \n",
        "            nn.Tanh(),                       \n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )        \n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(out_dim, 1)                        \n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.auto_model(input_ids=input_ids, attention_mask=attention_mask)        \n",
        "\n",
        "        # There are a total of 13 layers of hidden states.\n",
        "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
        "        # We take the hidden states from the last Roberta layer.\n",
        "        last_layer_hidden_states = bert_output.hidden_states[-1]\n",
        "\n",
        "        # The number of cells is config.max_len.\n",
        "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
        "        # In order to condense hidden states of all cells to a context vector,\n",
        "        # we compute a weighted average of the hidden states of all cells.\n",
        "        # We compute the weight of each cell, using the attention neural network.\n",
        "        weights = self.attention(last_layer_hidden_states)\n",
        "                \n",
        "        # weights.shape is config.batch_size x config.max_len x 1\n",
        "        # last_layer_hidden_states.shape is config.batch_size x config.max_len x 768        \n",
        "        # Now we compute context_vector as the weighted average.\n",
        "        # context_vector.shape is config.batch_size x 768\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
        "        \n",
        "        # Now we reduce the context vector to the prediction score.\n",
        "        out = self.regressor(context_vector).squeeze()\n",
        "\n",
        "        return out"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a3978b1",
        "outputId": "b34b7510-0213-43a2-f80f-156cad9f128b"
      },
      "source": [
        "# Test\n",
        "\n",
        "model = BaseModel()\n",
        "print(model)\n",
        "\n",
        "train_dataset = BaseDataset(train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "for input_ids, attention_mask, labels in train_loader:\n",
        "    output = model(input_ids, attention_mask)\n",
        "    print(output)\n",
        "    break\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BaseModel(\n",
            "  (auto_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (attention): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (3): Softmax(dim=1)\n",
            "  )\n",
            "  (regressor): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "tensor([0.0620, 0.1001, 0.1924, 0.0736], grad_fn=<SqueezeBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlpHUm-SrcLV",
        "outputId": "43c31714-c354-4f88-a174-be00c8b4dd89"
      },
      "source": [
        "# Test\n",
        "\n",
        "for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
        "    print(f\"{n}: {name}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: auto_model.embeddings.word_embeddings.weight\n",
            "1: auto_model.embeddings.position_embeddings.weight\n",
            "2: auto_model.embeddings.token_type_embeddings.weight\n",
            "3: auto_model.embeddings.LayerNorm.weight\n",
            "4: auto_model.embeddings.LayerNorm.bias\n",
            "5: auto_model.encoder.layer.0.attention.self.query.weight\n",
            "6: auto_model.encoder.layer.0.attention.self.query.bias\n",
            "7: auto_model.encoder.layer.0.attention.self.key.weight\n",
            "8: auto_model.encoder.layer.0.attention.self.key.bias\n",
            "9: auto_model.encoder.layer.0.attention.self.value.weight\n",
            "10: auto_model.encoder.layer.0.attention.self.value.bias\n",
            "11: auto_model.encoder.layer.0.attention.output.dense.weight\n",
            "12: auto_model.encoder.layer.0.attention.output.dense.bias\n",
            "13: auto_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "14: auto_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "15: auto_model.encoder.layer.0.intermediate.dense.weight\n",
            "16: auto_model.encoder.layer.0.intermediate.dense.bias\n",
            "17: auto_model.encoder.layer.0.output.dense.weight\n",
            "18: auto_model.encoder.layer.0.output.dense.bias\n",
            "19: auto_model.encoder.layer.0.output.LayerNorm.weight\n",
            "20: auto_model.encoder.layer.0.output.LayerNorm.bias\n",
            "21: auto_model.encoder.layer.1.attention.self.query.weight\n",
            "22: auto_model.encoder.layer.1.attention.self.query.bias\n",
            "23: auto_model.encoder.layer.1.attention.self.key.weight\n",
            "24: auto_model.encoder.layer.1.attention.self.key.bias\n",
            "25: auto_model.encoder.layer.1.attention.self.value.weight\n",
            "26: auto_model.encoder.layer.1.attention.self.value.bias\n",
            "27: auto_model.encoder.layer.1.attention.output.dense.weight\n",
            "28: auto_model.encoder.layer.1.attention.output.dense.bias\n",
            "29: auto_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "30: auto_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "31: auto_model.encoder.layer.1.intermediate.dense.weight\n",
            "32: auto_model.encoder.layer.1.intermediate.dense.bias\n",
            "33: auto_model.encoder.layer.1.output.dense.weight\n",
            "34: auto_model.encoder.layer.1.output.dense.bias\n",
            "35: auto_model.encoder.layer.1.output.LayerNorm.weight\n",
            "36: auto_model.encoder.layer.1.output.LayerNorm.bias\n",
            "37: auto_model.encoder.layer.2.attention.self.query.weight\n",
            "38: auto_model.encoder.layer.2.attention.self.query.bias\n",
            "39: auto_model.encoder.layer.2.attention.self.key.weight\n",
            "40: auto_model.encoder.layer.2.attention.self.key.bias\n",
            "41: auto_model.encoder.layer.2.attention.self.value.weight\n",
            "42: auto_model.encoder.layer.2.attention.self.value.bias\n",
            "43: auto_model.encoder.layer.2.attention.output.dense.weight\n",
            "44: auto_model.encoder.layer.2.attention.output.dense.bias\n",
            "45: auto_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "46: auto_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "47: auto_model.encoder.layer.2.intermediate.dense.weight\n",
            "48: auto_model.encoder.layer.2.intermediate.dense.bias\n",
            "49: auto_model.encoder.layer.2.output.dense.weight\n",
            "50: auto_model.encoder.layer.2.output.dense.bias\n",
            "51: auto_model.encoder.layer.2.output.LayerNorm.weight\n",
            "52: auto_model.encoder.layer.2.output.LayerNorm.bias\n",
            "53: auto_model.encoder.layer.3.attention.self.query.weight\n",
            "54: auto_model.encoder.layer.3.attention.self.query.bias\n",
            "55: auto_model.encoder.layer.3.attention.self.key.weight\n",
            "56: auto_model.encoder.layer.3.attention.self.key.bias\n",
            "57: auto_model.encoder.layer.3.attention.self.value.weight\n",
            "58: auto_model.encoder.layer.3.attention.self.value.bias\n",
            "59: auto_model.encoder.layer.3.attention.output.dense.weight\n",
            "60: auto_model.encoder.layer.3.attention.output.dense.bias\n",
            "61: auto_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "62: auto_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "63: auto_model.encoder.layer.3.intermediate.dense.weight\n",
            "64: auto_model.encoder.layer.3.intermediate.dense.bias\n",
            "65: auto_model.encoder.layer.3.output.dense.weight\n",
            "66: auto_model.encoder.layer.3.output.dense.bias\n",
            "67: auto_model.encoder.layer.3.output.LayerNorm.weight\n",
            "68: auto_model.encoder.layer.3.output.LayerNorm.bias\n",
            "69: auto_model.encoder.layer.4.attention.self.query.weight\n",
            "70: auto_model.encoder.layer.4.attention.self.query.bias\n",
            "71: auto_model.encoder.layer.4.attention.self.key.weight\n",
            "72: auto_model.encoder.layer.4.attention.self.key.bias\n",
            "73: auto_model.encoder.layer.4.attention.self.value.weight\n",
            "74: auto_model.encoder.layer.4.attention.self.value.bias\n",
            "75: auto_model.encoder.layer.4.attention.output.dense.weight\n",
            "76: auto_model.encoder.layer.4.attention.output.dense.bias\n",
            "77: auto_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "78: auto_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "79: auto_model.encoder.layer.4.intermediate.dense.weight\n",
            "80: auto_model.encoder.layer.4.intermediate.dense.bias\n",
            "81: auto_model.encoder.layer.4.output.dense.weight\n",
            "82: auto_model.encoder.layer.4.output.dense.bias\n",
            "83: auto_model.encoder.layer.4.output.LayerNorm.weight\n",
            "84: auto_model.encoder.layer.4.output.LayerNorm.bias\n",
            "85: auto_model.encoder.layer.5.attention.self.query.weight\n",
            "86: auto_model.encoder.layer.5.attention.self.query.bias\n",
            "87: auto_model.encoder.layer.5.attention.self.key.weight\n",
            "88: auto_model.encoder.layer.5.attention.self.key.bias\n",
            "89: auto_model.encoder.layer.5.attention.self.value.weight\n",
            "90: auto_model.encoder.layer.5.attention.self.value.bias\n",
            "91: auto_model.encoder.layer.5.attention.output.dense.weight\n",
            "92: auto_model.encoder.layer.5.attention.output.dense.bias\n",
            "93: auto_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "94: auto_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "95: auto_model.encoder.layer.5.intermediate.dense.weight\n",
            "96: auto_model.encoder.layer.5.intermediate.dense.bias\n",
            "97: auto_model.encoder.layer.5.output.dense.weight\n",
            "98: auto_model.encoder.layer.5.output.dense.bias\n",
            "99: auto_model.encoder.layer.5.output.LayerNorm.weight\n",
            "100: auto_model.encoder.layer.5.output.LayerNorm.bias\n",
            "101: auto_model.encoder.layer.6.attention.self.query.weight\n",
            "102: auto_model.encoder.layer.6.attention.self.query.bias\n",
            "103: auto_model.encoder.layer.6.attention.self.key.weight\n",
            "104: auto_model.encoder.layer.6.attention.self.key.bias\n",
            "105: auto_model.encoder.layer.6.attention.self.value.weight\n",
            "106: auto_model.encoder.layer.6.attention.self.value.bias\n",
            "107: auto_model.encoder.layer.6.attention.output.dense.weight\n",
            "108: auto_model.encoder.layer.6.attention.output.dense.bias\n",
            "109: auto_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "110: auto_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "111: auto_model.encoder.layer.6.intermediate.dense.weight\n",
            "112: auto_model.encoder.layer.6.intermediate.dense.bias\n",
            "113: auto_model.encoder.layer.6.output.dense.weight\n",
            "114: auto_model.encoder.layer.6.output.dense.bias\n",
            "115: auto_model.encoder.layer.6.output.LayerNorm.weight\n",
            "116: auto_model.encoder.layer.6.output.LayerNorm.bias\n",
            "117: auto_model.encoder.layer.7.attention.self.query.weight\n",
            "118: auto_model.encoder.layer.7.attention.self.query.bias\n",
            "119: auto_model.encoder.layer.7.attention.self.key.weight\n",
            "120: auto_model.encoder.layer.7.attention.self.key.bias\n",
            "121: auto_model.encoder.layer.7.attention.self.value.weight\n",
            "122: auto_model.encoder.layer.7.attention.self.value.bias\n",
            "123: auto_model.encoder.layer.7.attention.output.dense.weight\n",
            "124: auto_model.encoder.layer.7.attention.output.dense.bias\n",
            "125: auto_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "126: auto_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "127: auto_model.encoder.layer.7.intermediate.dense.weight\n",
            "128: auto_model.encoder.layer.7.intermediate.dense.bias\n",
            "129: auto_model.encoder.layer.7.output.dense.weight\n",
            "130: auto_model.encoder.layer.7.output.dense.bias\n",
            "131: auto_model.encoder.layer.7.output.LayerNorm.weight\n",
            "132: auto_model.encoder.layer.7.output.LayerNorm.bias\n",
            "133: auto_model.encoder.layer.8.attention.self.query.weight\n",
            "134: auto_model.encoder.layer.8.attention.self.query.bias\n",
            "135: auto_model.encoder.layer.8.attention.self.key.weight\n",
            "136: auto_model.encoder.layer.8.attention.self.key.bias\n",
            "137: auto_model.encoder.layer.8.attention.self.value.weight\n",
            "138: auto_model.encoder.layer.8.attention.self.value.bias\n",
            "139: auto_model.encoder.layer.8.attention.output.dense.weight\n",
            "140: auto_model.encoder.layer.8.attention.output.dense.bias\n",
            "141: auto_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "142: auto_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "143: auto_model.encoder.layer.8.intermediate.dense.weight\n",
            "144: auto_model.encoder.layer.8.intermediate.dense.bias\n",
            "145: auto_model.encoder.layer.8.output.dense.weight\n",
            "146: auto_model.encoder.layer.8.output.dense.bias\n",
            "147: auto_model.encoder.layer.8.output.LayerNorm.weight\n",
            "148: auto_model.encoder.layer.8.output.LayerNorm.bias\n",
            "149: auto_model.encoder.layer.9.attention.self.query.weight\n",
            "150: auto_model.encoder.layer.9.attention.self.query.bias\n",
            "151: auto_model.encoder.layer.9.attention.self.key.weight\n",
            "152: auto_model.encoder.layer.9.attention.self.key.bias\n",
            "153: auto_model.encoder.layer.9.attention.self.value.weight\n",
            "154: auto_model.encoder.layer.9.attention.self.value.bias\n",
            "155: auto_model.encoder.layer.9.attention.output.dense.weight\n",
            "156: auto_model.encoder.layer.9.attention.output.dense.bias\n",
            "157: auto_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "158: auto_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "159: auto_model.encoder.layer.9.intermediate.dense.weight\n",
            "160: auto_model.encoder.layer.9.intermediate.dense.bias\n",
            "161: auto_model.encoder.layer.9.output.dense.weight\n",
            "162: auto_model.encoder.layer.9.output.dense.bias\n",
            "163: auto_model.encoder.layer.9.output.LayerNorm.weight\n",
            "164: auto_model.encoder.layer.9.output.LayerNorm.bias\n",
            "165: auto_model.encoder.layer.10.attention.self.query.weight\n",
            "166: auto_model.encoder.layer.10.attention.self.query.bias\n",
            "167: auto_model.encoder.layer.10.attention.self.key.weight\n",
            "168: auto_model.encoder.layer.10.attention.self.key.bias\n",
            "169: auto_model.encoder.layer.10.attention.self.value.weight\n",
            "170: auto_model.encoder.layer.10.attention.self.value.bias\n",
            "171: auto_model.encoder.layer.10.attention.output.dense.weight\n",
            "172: auto_model.encoder.layer.10.attention.output.dense.bias\n",
            "173: auto_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "174: auto_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "175: auto_model.encoder.layer.10.intermediate.dense.weight\n",
            "176: auto_model.encoder.layer.10.intermediate.dense.bias\n",
            "177: auto_model.encoder.layer.10.output.dense.weight\n",
            "178: auto_model.encoder.layer.10.output.dense.bias\n",
            "179: auto_model.encoder.layer.10.output.LayerNorm.weight\n",
            "180: auto_model.encoder.layer.10.output.LayerNorm.bias\n",
            "181: auto_model.encoder.layer.11.attention.self.query.weight\n",
            "182: auto_model.encoder.layer.11.attention.self.query.bias\n",
            "183: auto_model.encoder.layer.11.attention.self.key.weight\n",
            "184: auto_model.encoder.layer.11.attention.self.key.bias\n",
            "185: auto_model.encoder.layer.11.attention.self.value.weight\n",
            "186: auto_model.encoder.layer.11.attention.self.value.bias\n",
            "187: auto_model.encoder.layer.11.attention.output.dense.weight\n",
            "188: auto_model.encoder.layer.11.attention.output.dense.bias\n",
            "189: auto_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "190: auto_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "191: auto_model.encoder.layer.11.intermediate.dense.weight\n",
            "192: auto_model.encoder.layer.11.intermediate.dense.bias\n",
            "193: auto_model.encoder.layer.11.output.dense.weight\n",
            "194: auto_model.encoder.layer.11.output.dense.bias\n",
            "195: auto_model.encoder.layer.11.output.LayerNorm.weight\n",
            "196: auto_model.encoder.layer.11.output.LayerNorm.bias\n",
            "197: auto_model.pooler.dense.weight\n",
            "198: auto_model.pooler.dense.bias\n",
            "199: attention.0.weight\n",
            "200: attention.0.bias\n",
            "201: attention.2.weight\n",
            "202: attention.2.bias\n",
            "203: regressor.0.weight\n",
            "204: regressor.0.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PcTNCYuDeuC"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzoJMxr3DeVG"
      },
      "source": [
        "def bert_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "    \n",
        "    if config.model_name in [\"roberta-base\", \"bert-base-uncased\"]:\n",
        "        bert_parameters = named_parameters[:197]    \n",
        "        attention_parameters = named_parameters[199:203]\n",
        "        regressor_parameters = named_parameters[203:]\n",
        "        second_block = 69\n",
        "        third_block = 133\n",
        "\n",
        "    elif config.model_name == \"roberta-large\":\n",
        "        bert_parameters = named_parameters[:388]    \n",
        "        attention_parameters = named_parameters[391:395]\n",
        "        regressor_parameters = named_parameters[395:]\n",
        "        second_block = 133\n",
        "        third_block = 261\n",
        "        \n",
        "    attention_group = [params for (name, params) in attention_parameters]\n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": attention_group})\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(bert_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else config.weight_decay\n",
        "\n",
        "        lr = config.lr\n",
        "\n",
        "        if layer_num >= second_block:        \n",
        "            lr = config.lr_69\n",
        "\n",
        "        if layer_num >= third_block:\n",
        "            lr = config.lr_133\n",
        "\n",
        "        parameters.append({\"params\": params, \"weight_decay\": weight_decay, \"lr\": lr})\n",
        "\n",
        "    return T.AdamW(parameters)\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de50761e"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47fcae06"
      },
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-7):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self, yhat, y):\n",
        "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
        "        return loss"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93661540"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19d9d03c"
      },
      "source": [
        "def get_score(y_true, y_pred, b=border):\n",
        "    y_pred = np.where(y_pred < b, 0, 1)\n",
        "    return fbeta_score(y_true, y_pred, beta=7.0)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1b92d4f"
      },
      "source": [
        "def get_result(result_df, fold=config.n_fold):\n",
        "    preds = result_df[\"preds\"].values\n",
        "    labels = result_df[\"judgement\"].values\n",
        "    score = get_score(labels, preds)\n",
        "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "    # wandb.log({\"fold\": fold, \"CV\": score})\n",
        "    if fold == config.n_fold:\n",
        "        wandb.run.summary[f\"CV\"] = score\n",
        "    else:\n",
        "        wandb.run.summary[f\"CV_fold{fold}\"] = score\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJUo-Mjlv_2"
      },
      "source": [
        "def determine_border(b, y_true, y_pred):\n",
        "    return -1 * get_score(y_true, y_pred, b)\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf498df"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5b0e152"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99a3bfb5"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "        if Config.apex:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "\n",
        "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(scheduler, ReduceLROnPlateau):\n",
        "                scheduler.step(avg_val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "            \n",
        "            global_step += 1\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                # f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
        "                f\"LR: {scheduler.get_lr()[0]:.6f}  \"\n",
        "            )\n",
        "\n",
        "    return losses.avg"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "186c441d"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # record score\n",
        "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        preds.append(y_preds.to(\"cpu\").numpy())\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "            )\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7cdfc9"
      },
      "source": [
        "def inference(test_loader):\n",
        "    predictions = []\n",
        "    for model_item in inference_models:\n",
        "        for fold in range(config.n_fold):\n",
        "            LOGGER.info(f\"========== ID: {model_item['run_id']} model: {model_item['model_name']} fold: {fold} inference ==========\")\n",
        "            model = BaseModel()\n",
        "            model.to(device)\n",
        "            model.load_state_dict(model_item[f\"state_fold{fold}\"])\n",
        "            model.eval()\n",
        "            preds = []\n",
        "            for i, (input_ids, attention_mask) in enumerate(test_loader):\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                with torch.no_grad():\n",
        "                    y_preds = model(input_ids, attention_mask)\n",
        "                # avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "                preds.append(y_preds.to(\"cpu\").numpy())\n",
        "            preds = np.concatenate(preds)\n",
        "            predictions.append(preds)\n",
        "    predictions = np.mean(predictions, axis=0)\n",
        "\n",
        "    if config.criterion == \"BCEWithLogitsLoss\":\n",
        "        predictions = 1 / (1 + np.exp(-predictions))\n",
        "\n",
        "    return predictions\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9663c1"
      },
      "source": [
        "## Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357969e6"
      },
      "source": [
        "def train_loop(folds, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    trn_idx = folds[folds[\"fold\"] != fold].index\n",
        "    val_idx = folds[folds[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BaseDataset(train_folds)\n",
        "    valid_dataset = BaseDataset(valid_folds)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Optimizer\n",
        "    # ====================================================\n",
        "    def get_optimizer(model):\n",
        "        if config.optimizer == \"Adam\":\n",
        "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay, amsgrad=False)\n",
        "        elif config.optimizer == \"AdamW\":\n",
        "            optimizer = T.AdamW(model.parameters(), lr=config.lr)  # , weight_decay=config.weight_decay, amsgrad=False\n",
        "        elif config.optimizer == \"BertAdamW\":\n",
        "            optimizer = bert_optimizer(model)\n",
        "        return optimizer\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        if config.scheduler == \"ReduceLROnPlateau\":\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=config.factor, patience=config.patience, verbose=True, eps=config.eps\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=config.T_max, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(\n",
        "                optimizer, T_0=config.T_0, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
        "            scheduler = CosineAnnealingWarmupRestarts(\n",
        "                optimizer, first_cycle_steps=config.first_cycle_steps, max_lr=config.lr, min_lr=config.min_lr, warmup_steps=config.warmup_steps\n",
        "            )\n",
        "        elif config.scheduler == \"get_cosine_schedule_with_warmup\":\n",
        "            scheduler = T.get_cosine_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_training_steps=config.num_training_steps, \n",
        "                num_warmup_steps=config.num_warmup_steps\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # Model\n",
        "    # ====================================================\n",
        "    model = BaseModel()\n",
        "    model.to(device)\n",
        "\n",
        "    # Use multi GPU\n",
        "    if device == torch.device(\"cuda\") and not Config.apex and Config.multi_gpu:\n",
        "        model = torch.nn.DataParallel(model)  # make parallel\n",
        "        # torch.backends.cudnn.benchmark=True\n",
        "\n",
        "    optimizer = get_optimizer(model)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # Apex\n",
        "    # ====================================================\n",
        "    if Config.apex:\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "        elif config.criterion == \"MSELoss\":\n",
        "            criterion = nn.MSELoss()\n",
        "        elif config.criterion == \"RMSELoss\":\n",
        "            criterion = RMSELoss()\n",
        "\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "    best_score = -1\n",
        "    best_loss = np.inf\n",
        "\n",
        "    # if not Config.multi_gpu:\n",
        "    #     wandb.watch(model, log_freq=Config.print_freq)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
        "        valid_labels = valid_folds[\"judgement\"].values\n",
        "\n",
        "        # if isinstance(scheduler, ReduceLROnPlateau):\n",
        "        #     scheduler.step(avg_val_loss)\n",
        "        # else:\n",
        "        #     scheduler.step()\n",
        "\n",
        "        if config.criterion == \"BCEWithLogitsLoss\":\n",
        "            preds = 1 / (1 + np.exp(-preds))\n",
        "\n",
        "        # scoring\n",
        "        # score = get_score(valid_labels, preds.argmax(1))\n",
        "        score = get_score(valid_labels, preds)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(\n",
        "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
        "        )\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
        "\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                f\"loss/train_fold{fold}\": avg_loss,\n",
        "                f\"loss/val_fold{fold}\": avg_val_loss,\n",
        "                f\"score/fold{fold}\": score,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name}_fold{fold}_best.pth\"\n",
        "            )\n",
        "            wandb.save(OUTPUT_DIR + f\"{config.model_name}_fold{fold}_best.pth\")\n",
        "\n",
        "        # if epoch == config.epochs - 1:\n",
        "        #     LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
        "        #     torch.save(\n",
        "        #         {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name}_fold{fold}_final.pth\"\n",
        "        #     )\n",
        "\n",
        "    check_point = torch.load(OUTPUT_DIR + f\"{config.model_name}_fold{fold}_best.pth\")\n",
        "\n",
        "    valid_folds[[str(c) for c in range(config.n_class)]] = check_point[\"preds\"]\n",
        "    valid_folds[\"preds\"] = check_point[\"preds\"]  # .argmax(1)\n",
        "\n",
        "    return valid_folds"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97b42fa3"
      },
      "source": [
        "## Main\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5baf150d"
      },
      "source": [
        "def main():\n",
        "    if Config.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df = train_loop(folds, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "            \n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        \n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
        "        \n",
        "    if Config.validate:\n",
        "        probs = []\n",
        "\n",
        "        for n in range(len(config.inference_runs)):\n",
        "            probs.append(train[f\"preds{n}\"].values)\n",
        "        preds = np.mean(probs, axis=0)\n",
        "        train[\"preds\"] = preds\n",
        "\n",
        "        # Post process\n",
        "        if config.border == \"minimize\":\n",
        "            res = sp.optimize.minimize_scalar(determine_border, method='bounded', bounds=(0, 1), args=(train[\"judgement\"].values, preds))\n",
        "            LOGGER.info(f\"========== Border Optimization ==========\")\n",
        "            LOGGER.info(f\"Border: {res.x:<.5f}, Score: {-res.fun:<.5f}\")\n",
        "            wandb.run.summary[f\"CV\"] = -res.fun\n",
        "\n",
        "        elif config.border == \"fixed\":\n",
        "            # CV result\n",
        "            LOGGER.info(f\"========== CV ==========\")\n",
        "            get_result(train)\n",
        "\n",
        "        # save result\n",
        "        train.to_csv(OUTPUT_DIR + \"validation_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"validation_df.csv\")\n",
        "\n",
        "    if Config.inference:\n",
        "        test_dataset = BaseDataset(test, include_labels=False)\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True\n",
        "        )\n",
        "        predictions = inference(test_loader)\n",
        "\n",
        "        # Post process\n",
        "        try:\n",
        "            b = res.x\n",
        "        except Exception:\n",
        "            b = border\n",
        "        wandb.run.summary[f\"border\"] = b\n",
        "\n",
        "        predictions = np.where(predictions < b, 0, 1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = predictions  # .argmax(1)\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "726e744f",
        "outputId": "036c4bfd-16f0-4636-c960-51a7fa2fcc43"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========== Border Optimization ==========\n",
            "Border: 0.00872, Score: 0.84791\n",
            "========== ID: 11pgifed model: bert-base-uncased fold: 0 inference ==========\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "========== ID: 11pgifed model: bert-base-uncased fold: 1 inference ==========\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "========== ID: 11pgifed model: bert-base-uncased fold: 2 inference ==========\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "========== ID: 11pgifed model: bert-base-uncased fold: 3 inference ==========\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "========== ID: 11pgifed model: bert-base-uncased fold: 4 inference ==========\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0    37420\n",
            "1     3414\n",
            "Name: judgement, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "37db41e2b3814a1392392423a2ef00ea",
            "aeb8fd5b936c46349e058cb3fcb21599",
            "b07849e163754725b968f6bd3009ac30",
            "545a96d075664ed3a0fdf9047c6f1f70",
            "65a1974553ae4195b7ac49b305779382",
            "73896f8541d945e29c80f2dbdd1df4ae",
            "f632af6f00fc483596c40170abd78612",
            "4fa1b6b7c0564ad49d41540222b1304f"
          ]
        },
        "id": "CPHezhr_NHYR",
        "outputId": "e0a140f0-48d3-40cd-aaa8-bbe364d2dc08"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 12092<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37db41e2b3814a1392392423a2ef00ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 75.36MB of 75.36MB uploaded (0.16MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210730_063750-c8y0phpv/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210730_063750-c8y0phpv/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>CV</td><td>0.84791</td></tr><tr><td>border</td><td>0.00872</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 24 artifact file(s) and 3 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">firm-shadow-15</strong>: <a href=\"https://wandb.ai/imokuri/signate-471/runs/c8y0phpv\" target=\"_blank\">https://wandb.ai/imokuri/signate-471/runs/c8y0phpv</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-scfhV4ueW4K"
      },
      "source": [
        "## Public LB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNsH2CvA1He"
      },
      "source": [
        "RUN_ID = \"None\"\n",
        "LB_SCORE = None\n",
        "\n",
        "WANDB_ENTITY = \"imokuri\"\n",
        "WANDB_PROJECT = \"signate-471\""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS7aRYF_eh7z"
      },
      "source": [
        "if RUN_ID is not None and LB_SCORE is not None:\n",
        "    import wandb\n",
        "    api = wandb.Api()\n",
        "\n",
        "    run = api.run(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/{RUN_ID}\")\n",
        "    run.summary[\"LB\"] = LB_SCORE\n",
        "    run.summary.update()\n"
      ],
      "execution_count": 60,
      "outputs": []
    }
  ]
}