{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "医学論文の自動仕分けチャレンジ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d33dfc73f6c4733be732faff6e01a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a9a0f5394844457ba1f079f9c85c520",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e0ecda9236c4952aa2bfba6042d0f5f",
              "IPY_MODEL_4e25535ab95545899cf670bdd6b19ed1"
            ]
          }
        },
        "9a9a0f5394844457ba1f079f9c85c520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e0ecda9236c4952aa2bfba6042d0f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_ba52b4f8f49b4b5b98db59913c4a4e30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2186.58MB of 2186.58MB uploaded (0.23MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a43021596c44736937410edf7bc7018"
          }
        },
        "4e25535ab95545899cf670bdd6b19ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10f83e4e6f094a14b62e50832a7bdad5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b3196e8512b4e4faa2a6f99cb90140a"
          }
        },
        "ba52b4f8f49b4b5b98db59913c4a4e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a43021596c44736937410edf7bc7018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10f83e4e6f094a14b62e50832a7bdad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b3196e8512b4e4faa2a6f99cb90140a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IMOKURI/signate-471/blob/main/%E5%8C%BB%E5%AD%A6%E8%AB%96%E6%96%87%E3%81%AE%E8%87%AA%E5%8B%95%E4%BB%95%E5%88%86%E3%81%91%E3%83%81%E3%83%A3%E3%83%AC%E3%83%B3%E3%82%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e4660c1"
      },
      "source": [
        "# About this notebook ...\n",
        "\n",
        "competition site: https://signate.jp/competitions/471\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dhs2SIWJzKz"
      },
      "source": [
        "## ToDo\n",
        "\n",
        "- [ ] pre train のモデルの save と load\n",
        "- [ ] preprocess したデータの save と load (wandb)\n",
        "\n",
        "### Idea\n",
        "\n",
        "- [ ] 分類で推論、回帰で推論\n",
        "- [x] 回帰の場合の境界値の最適化\n",
        "    - [ ] second stage で学習べきかも\n",
        "        - [ ] heamy という stacking のライブラリがある\n",
        "    - [ ] Nelder-Mead 法 という最適化手法を調べる\n",
        "- [ ] 最適な境界値はモデルによって異なるので、アンサンブルの時は、 vote ensemble がいいかもしれない\n",
        "- [x] アブストで事前学習して、タイトルでメイン学習 https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n",
        "    - 事前学習は、Masked LM\n",
        "- [x] タイトルだけで学習・推論\n",
        "- [ ] タイトル + アブストで学習・推論\n",
        "    - [ ] タイトルだけで推論したのとアンサンブルができる\n",
        "    - [ ] Longformer がいいかもしれない `allenai/longformer-base-4096`\n",
        "    - [ ] large モデルためす\n",
        "- [ ] アブスト + タイトル で学習・推論\n",
        "- [ ] アブストが空 or not でモデルわける\n",
        "- [ ] アブストの max length 調整\n",
        "    - [ ] 途中で切る。デフォルトの 512 はありそう。ほとんどのアブストがその長さで収まる\n",
        "    - [ ] 要約する方法があるかなぁ\n",
        "- [x] dropout を 0 にする\n",
        "- [x] gradient cripping を 0.2 or 0.5 で試す\n",
        "- [ ] re-initialization\n",
        "    - This paper (https://arxiv.org/pdf/2006.05987.pdf) shows that fine-tuning with reinitialization last N layers works well.\n",
        "    - Different models have different optimal N. Almost models set N=4~5, gpt2-models set N=6.\n",
        "    - https://github.com/kurupical/commonlit/blob/8781139c8ed4cc59f7c7ac9d97c72c351ee91377/exp/exp502.py#L497\n",
        "- [ ] Pre trained なレイヤーのfreeze https://raphaelb.org/posts/freezing-bert/\n",
        "- [ ] Recall を伸ばすための loss function は考えられるか。 https://openreview.net/pdf?id=SlprFTIQP3\n",
        "    - [x] f1 score を微分可能にして、 loss 関数に使うアプローチ https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354 https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d\n",
        "    - [ ] epoch ごとに beta の値を増やしていく epoch * 2 とか\n",
        "- [ ] 出現する単語のクラスタリング\n",
        "- [x] TF-IDF して、 リッジ回帰 → ベースライン2 でやった\n",
        "    - IF-IDF の結果もBERTの特徴量にできないだろうか\n",
        "    - https://www.kaggle.com/semyonkoshkarov/tf-idf-linearsvr-baseline も参考になるかも\n",
        "- [ ] 医療用語で事前学習されたモデルを使ってみる\n",
        "    - [x] BioBERT https://github.com/dmis-lab/biobert `dmis-lab/biobert-base-cased-v1.1` 286k downloads\n",
        "        - [ ] large モデル試す\n",
        "    - [ ] Med-BERT https://github.com/ZhiGroup/Med-BERT\n",
        "        - 診断精度に貢献しているかもしれない(いや、一般的な話だったｗ) https://www.nature.com/articles/s41746-021-00455-y\n",
        "    - [x] `microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext` 30.8k downloads https://www.axion.zone/microsoft-researchers-claim-state-of-the-art-biomedical-nlp-model/\n",
        "    - [x] `bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12` 4.3k downloads https://github.com/ncbi-nlp/bluebert\n",
        "        - [ ] large モデル試す\n",
        "    - [x] `emilyalsentzer/Bio_ClinicalBERT` https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n",
        "    - [ ] `emilyalsentzer/Bio_Discharge_Summary_BERT` https://huggingface.co/emilyalsentzer/Bio_Discharge_Summary_BERT\n",
        "    - [x] `lordtt13/COVID-SciBERT` https://huggingface.co/lordtt13/COVID-SciBERT\n",
        "    - [ ] `allenai/scibert_scivocab_uncased` https://huggingface.co/allenai/scibert_scivocab_uncased\n",
        "- [ ] Augmentation https://neptune.ai/blog/data-augmentation-nlp\n",
        "    - [ ] Back translation: 他言語に翻訳して、もう一回翻訳する（英語→フランス語→英語） https://qiita.com/nena0undefined/items/c2926bad07039e5540ab\n",
        "    - [ ] Synonym Replacement: 単語のいくつかを、同じ意味の別の単語に置き換える\n",
        "        - [ ] 自然言語の augmentation ができるライブラリ https://github.com/makcedward/nlpaug\n",
        "- [ ] TTA\n",
        "- [ ] ベースラインのシンプルさを取り戻す。(思ったよりベースラインのスコアが良かったので、それを取り込む・・・）\n",
        "    - [ ] weight decay を調整 0.01 or 0\n",
        "\n",
        "\n",
        "### Experiments\n",
        "\n",
        "- BERT でアブストの　pre train をしてもスコアは上がっていない（学習の方法を工夫した方がよいかも）\n",
        "- BERT Large は title の学習には大きすぎて？ loss が Base モデルに及ばない。\n",
        "- epoch 3 で val loss が下がらないので、 epoch 3 で aug かけるとかありかもしれない\n",
        "- `dmis-lab/biobert-base-cased-v1.1` と `bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12` の成績がよい\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68842c71"
      },
      "source": [
        "## Prepare for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14137a0f",
        "outputId": "f309302c-e292-437f-9d04-4888a91744a4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug  7 04:16:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    53W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4871daf1",
        "outputId": "05d7b274-29cf-493d-c905-dbc1c473483e"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if os.path.exists('init.txt'):\n",
        "    print(\"Already initialized.\")\n",
        "\n",
        "else:\n",
        "    if 'google.colab' in sys.modules:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/gdrive')\n",
        "\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/train.csv .\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/test.csv .\n",
        "        !cp /gdrive/MyDrive/Datasets/signate-471/sample_submit.csv .\n",
        "\n",
        "    # for StratifiedGroupKFold\n",
        "    # !pip uninstall -y scikit-learn\n",
        "    # !pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn\n",
        "\n",
        "    # for MultilabelStratifiedKFold\n",
        "    !pip install -q iterative-stratification\n",
        "\n",
        "    # !pip install -qU 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'\n",
        "\n",
        "    !pip install -q wandb\n",
        "    !pip install -q transformers\n",
        "    !pip install -q textstat\n",
        "\n",
        "    !touch init.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already initialized.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c39b7222"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63096cb"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import warnings\n",
        "from contextlib import contextmanager\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "import textstat\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers as T\n",
        "import wandb\n",
        "# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, fbeta_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold  # , StratifiedGroupKFold\n",
        "from torch.optim import SGD, Adam  # , AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c830faec"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16eb8ed5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cZeQJ7Xw7d8",
        "outputId": "c373fbb4-f3ef-43b4-dbc9-42b9d8742ae2"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc53e8c",
        "outputId": "718ef9ca-8d46-4029-dd65-97c011b0b564"
      },
      "source": [
        "netrc = \"../input/wandbtoken/.netrc\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    netrc = \"/gdrive/MyDrive/.netrc\"\n",
        "\n",
        "!cp -f {netrc} ~/\n",
        "\n",
        "!wandb login"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB5QkUQJq_6U"
      },
      "source": [
        "wandb_job_type = \"\"\n",
        "wandb_notes = \"\"\n",
        "wandb_tags = []"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71d9ccbd"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a62a05f"
      },
      "source": [
        "DATA_DIR = \"../input/signate-471/\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_DIR = \"./\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26350797"
      },
      "source": [
        "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
        "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
        "sub = pd.read_csv(DATA_DIR + \"sample_submit.csv\", header=None)\n",
        "sub.columns = [\"id\", \"judgement\"]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7ef06f8"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0177571"
      },
      "source": [
        "class Config:\n",
        "    wandb_entity = \"imokuri\"\n",
        "    wandb_project = \"signate-471\"\n",
        "    print_freq = 100\n",
        "\n",
        "    pre_train = False\n",
        "    train = True\n",
        "    validate = False\n",
        "    inference = False\n",
        "\n",
        "    debug = False\n",
        "    multi_gpu = False\n",
        "    apex = False\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a195fe0"
      },
      "source": [
        "if Config.pre_train:\n",
        "    wandb_job_type = \"pre_training\"\n",
        "\n",
        "elif Config.train:\n",
        "    wandb_job_type = \"training\"\n",
        "\n",
        "elif Config.inference:\n",
        "    wandb_job_type = \"inference\"\n",
        "\n",
        "elif Config.validate:\n",
        "    wandb_job_type = \"validation\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccb61787"
      },
      "source": [
        "if Config.apex:\n",
        "    from apex import amp"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWDHvHvNxoD3",
        "outputId": "d6fba338-be14-4e39-922d-e230d8c70baf"
      },
      "source": [
        "# seed = random.randrange(10000)\n",
        "seed = 440\n",
        "\n",
        "print(seed)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daf057a9"
      },
      "source": [
        "config_defaults = {\n",
        "    \"seed\": seed,\n",
        "    \"input\": \"abstract_title\",  # \"preprocessed_title_abstract\",  # \"title\", # \"title_abstract\",\n",
        "    \"max_len\": 512,\n",
        "    \"border\": \"minimize\", # \"fixed\", \"minimize\",\n",
        "    \"n_class\": 1,\n",
        "    \"n_fold\": 5,\n",
        "    \"gradient_accumulation_steps\": 2,\n",
        "    \"max_grad_norm\": 1000,\n",
        "    \"num_workers\": 4,\n",
        "    \"batch_size\": 12,\n",
        "    \"epochs\": 3,\n",
        "    \"optimizer\": \"BertAdamW\",\n",
        "    \"scheduler\": \"get_cosine_schedule_with_warmup\",\n",
        "    \"criterion\": \"BCEWithLogitsLoss\",  # \"FBetaLoss\",  # \"BCEWithLogitsLoss\",\n",
        "    \"lr\": 2e-5,\n",
        "    \"min_lr\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"dropout\": 0.1,\n",
        "    \"model_name\": \"dmis-lab/biobert-base-cased-v1.1-squad\",\n",
        "    # \"bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12\",\n",
        "    # \"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\",\n",
        "    # \"bionlp/bluebert_pubmed_uncased_L-24_H-1024_A-16\",\n",
        "    # \"bionlp/bluebert_pubmed_mimic_uncased_L-24_H-1024_A-16\",\n",
        "    # \"dmis-lab/biobert-base-cased-v1.1\",\n",
        "    # \"dmis-lab/biobert-base-cased-v1.1-squad\",\n",
        "    # \"dmis-lab/biobert-large-cased-v1.1\",\n",
        "    # \"dmis-lab/biobert-large-cased-v1.1-squad\",\n",
        "    \"reinit_layers\": 0,\n",
        "    \"freeze_layers\": 0,\n",
        "    \"inference_runs\": [\n",
        "        \"1kxyqvm2\",  # 53\n",
        "    ],\n",
        "}\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUQbknvvbZR5"
      },
      "source": [
        "if not Config.validate and not Config.inference:\n",
        "    config_defaults[\"inference_runs\"] = []"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd440361"
      },
      "source": [
        "if Config.debug:\n",
        "    config_defaults[\"epochs\"] = 1\n",
        "    Config.print_freq = 10"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgjHEBuwETmp"
      },
      "source": [
        "if config_defaults[\"optimizer\"] == \"BertAdamW\":\n",
        "    config_defaults[\"lr_69\"] = 5e-5\n",
        "    config_defaults[\"lr_133\"] = 1e-4\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a710ed",
        "outputId": "ebfd07b8-d04b-4f59-fed7-6c1306c9c6c8"
      },
      "source": [
        "# Update by epoch\n",
        "# num_steps = config_defaults[\"epochs\"]\n",
        "\n",
        "# Update by batch\n",
        "num_data = 1000 if Config.debug else len(train)\n",
        "num_steps = num_data // config_defaults[\"n_fold\"] * (config_defaults[\"n_fold\"] - 1) // config_defaults[\"batch_size\"] // config_defaults[\"gradient_accumulation_steps\"] * config_defaults[\"epochs\"]\n",
        "\n",
        "print(num_steps)\n",
        "\n",
        "if config_defaults[\"scheduler\"] == \"CosineAnnealingWarmRestarts\":\n",
        "    config_defaults[\"T_0\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingLR\":\n",
        "    config_defaults[\"T_max\"] = num_steps\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
        "    config_defaults[\"factor\"] = 0.2\n",
        "    config_defaults[\"patience\"] = 4\n",
        "    config_defaults[\"eps\"] = 1e-6\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"CosineAnnealingWarmupRestarts\":\n",
        "    config_defaults[\"first_cycle_steps\"] = num_steps\n",
        "    config_defaults[\"warmup_steps\"] = num_steps // 10\n",
        "\n",
        "elif config_defaults[\"scheduler\"] == \"get_cosine_schedule_with_warmup\":\n",
        "    config_defaults[\"num_training_steps\"] = num_steps\n",
        "    config_defaults[\"num_warmup_steps\"] = max(50, num_steps // 10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6a78770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "32a5dc8e-b041-4486-f4c8-1c8179b22287"
      },
      "source": [
        "if Config.debug:\n",
        "    run = wandb.init(project=Config.wandb_project, config=config_defaults, mode=\"disabled\")\n",
        "else:\n",
        "    run = wandb.init(project=Config.wandb_project, config=config_defaults, notes=wandb_notes, tags=wandb_tags, job_type=wandb_job_type, save_code=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimokuri\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.11.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">still-sponge-64</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/imokuri/signate-471\" target=\"_blank\">https://wandb.ai/imokuri/signate-471</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/imokuri/signate-471/runs/mxe0tzxa\" target=\"_blank\">https://wandb.ai/imokuri/signate-471/runs/mxe0tzxa</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210807_041631-mxe0tzxa</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2408ee43"
      },
      "source": [
        "config = wandb.config"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezOfV_OKnV2I"
      },
      "source": [
        "## EDA-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1C7cU7ka70h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675e7db9-0814-407d-ed0d-8ecc7b52aa7a"
      },
      "source": [
        "# アブストが空っぽのが結構ある\n",
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id              0\n",
            "title           0\n",
            "abstract     4390\n",
            "judgement       0\n",
            "dtype: int64\n",
            "id             0\n",
            "title          0\n",
            "abstract    6546\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4fTaf66DiXj"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuuU17phnFMz"
      },
      "source": [
        "def preprocess(data):\n",
        "    \n",
        "    title_abstract = []\n",
        "    for e in data:\n",
        "\n",
        "        # アルファベット以外は空白に置換します。\n",
        "        e = re.sub(\"[^a-zA-Z]\", \" \", e)\n",
        "\n",
        "        # 小文字に変換します。\n",
        "        e = e.lower()\n",
        "\n",
        "        # token に分割します。\n",
        "        e = nltk.word_tokenize(e)\n",
        "\n",
        "        # stop word を削除します。\n",
        "        e = [word for word in e if not word in set(nltk.corpus.stopwords.words(\"english\"))]\n",
        "\n",
        "        # 見出し語化します。\n",
        "        lemma = nltk.WordNetLemmatizer()\n",
        "        e = [lemma.lemmatize(word) for word in e]\n",
        "        e = \" \".join(e)\n",
        "\n",
        "        title_abstract.append(e)\n",
        "\n",
        "    return title_abstract"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylcVBT02nIGZ"
      },
      "source": [
        "def get_train_data(train):\n",
        "\n",
        "    # NaN を空白で埋めます。\n",
        "    train = train.fillna(\"\")\n",
        "\n",
        "    # abstract の有無を Stratified KFold で使います。\n",
        "    train[\"nan_abstract\"] = np.where(train[\"abstract\"] == \"\", 1, 0)\n",
        "\n",
        "    # title の単語数\n",
        "    train[\"len_title\"] = train[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # abstract の単語数\n",
        "    train[\"len_abstract\"] = train[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # title と abstract を接続します。\n",
        "    train[\"title_abstract\"] = train[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "    train[\"abstract_title\"] = train[[\"abstract\", \"title\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "    # train[\"preprocessed_title_abstract\"] = preprocess(train[\"title_abstract\"])\n",
        "\n",
        "    # 前処理した文の単語数\n",
        "    # train[\"len_preprocessed_title_abstract\"] = train[\"preprocessed_title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return train"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YskezxynKkm"
      },
      "source": [
        "def get_test_data(test):\n",
        "\n",
        "    # NaN を空白で埋めます。\n",
        "    test = test.fillna(\"\")\n",
        "\n",
        "    # title の単語数\n",
        "    test[\"len_title\"] = test[\"title\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # abstract の単語数\n",
        "    test[\"len_abstract\"] = test[\"abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # title と abstract を接続します。\n",
        "    test[\"title_abstract\"] = test[[\"title\", \"abstract\"]].agg(\" \".join, axis=1)\n",
        "    test[\"abstract_title\"] = test[[\"abstract\", \"title\"]].agg(\" \".join, axis=1)\n",
        "\n",
        "    # test[\"preprocessed_title_abstract\"] = preprocess(test[\"title_abstract\"])\n",
        "\n",
        "    # 前処理した文の単語数\n",
        "    # test[\"len_preprocessed_title_abstract\"] = test[\"preprocessed_title_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return test"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0CPmvZnQFP"
      },
      "source": [
        "if False:  # os.path.exists(\"/gdrive/MyDrive/Datasets/signate-471/preprocessed_train.csv\"):\n",
        "    !cp -f /gdrive/MyDrive/Datasets/signate-471/preprocessed_train.csv .\n",
        "    train = pd.read_csv(\"preprocessed_train.csv\")\n",
        "\n",
        "    # csv を再読み込みすると NaN に戻ってしまうので、再度変換します。\n",
        "    train = train.fillna(\"\")\n",
        "\n",
        "else:\n",
        "    # 一度、前処理したものは保存しておきます。\n",
        "    train = get_train_data(train)\n",
        "    # train.to_csv(\"preprocessed_train.csv\")\n",
        "\n",
        "    # artifact = wandb.Artifact('preprocessed_train', type='dataset')\n",
        "    # artifact.add_file(\"preprocessed_train.csv\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    # !cp -f preprocessed_train.csv /gdrive/MyDrive/Datasets/signate-471/"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A248D057nSd6"
      },
      "source": [
        "if False:  # os.path.exists(\"/gdrive/MyDrive/Datasets/signate-471/preprocessed_test.csv\"):\n",
        "    !cp -f /gdrive/MyDrive/Datasets/signate-471/preprocessed_test.csv .\n",
        "    test = pd.read_csv(\"preprocessed_test.csv\")\n",
        "\n",
        "    # csv を再読み込みすると NaN に戻ってしまうので、再度変換します。\n",
        "    test = test.fillna(\"\")\n",
        "\n",
        "else:\n",
        "    # 一度、前処理したものは保存しておきます。\n",
        "    test = get_test_data(test)\n",
        "    # test.to_csv(\"preprocessed_test.csv\")\n",
        "\n",
        "    # artifact = wandb.Artifact('preprocessed_test', type='dataset')\n",
        "    # artifact.add_file(\"preprocessed_test.csv\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    # !cp -f preprocessed_test.csv /gdrive/MyDrive/Datasets/signate-471/"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UPOk9WroUmX"
      },
      "source": [
        "## EDA-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BloR0mcceTWK",
        "outputId": "2253ce7f-5042-4594-b920-9a843a259249"
      },
      "source": [
        "# abstract に改行は含まれていない\n",
        "print(len(train[train[\"abstract\"].str.contains(\"\\n\")]))\n",
        "print(len(test[test[\"abstract\"].str.contains(\"\\n\")]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHfTQdU8Cezv",
        "outputId": "b3914486-7f1f-4b60-b7d9-cb75646408de"
      },
      "source": [
        "# title の単語数\n",
        "print(train[\"len_title\"].max())\n",
        "print(test[\"len_title\"].max())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53\n",
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx2M2402NSOU",
        "outputId": "2e6c84b6-f6f1-4370-dece-89709deea4be"
      },
      "source": [
        "# abstract の単語数\n",
        "print(train[\"len_abstract\"].max())\n",
        "print(test[\"len_abstract\"].max())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1535\n",
            "1445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1WviNuCdGec"
      },
      "source": [
        "# 前処理した文の単語数\n",
        "# print(train[\"len_preprocessed_title_abstract\"].max())\n",
        "# print(test[\"len_preprocessed_title_abstract\"].max())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "18097672",
        "outputId": "ad15add3-39d9-491d-e040-d2f3af5fdb1e"
      },
      "source": [
        "for ds in [train, test, sub]:\n",
        "    print(f\"=\" * 80)\n",
        "    ds.info()\n",
        "    display(ds.head())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27145 entries, 0 to 27144\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   id              27145 non-null  int64 \n",
            " 1   title           27145 non-null  object\n",
            " 2   abstract        27145 non-null  object\n",
            " 3   judgement       27145 non-null  int64 \n",
            " 4   nan_abstract    27145 non-null  int64 \n",
            " 5   len_title       27145 non-null  int64 \n",
            " 6   len_abstract    27145 non-null  int64 \n",
            " 7   title_abstract  27145 non-null  object\n",
            " 8   abstract_title  27145 non-null  object\n",
            "dtypes: int64(5), object(4)\n",
            "memory usage: 1.9+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>judgement</th>\n",
              "      <th>nan_abstract</th>\n",
              "      <th>len_title</th>\n",
              "      <th>len_abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>abstract_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>Longitudinal studies indicate that declines in...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>193</td>\n",
              "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
              "      <td>Longitudinal studies indicate that declines in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>The present study was undertaken to validate t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>214</td>\n",
              "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
              "      <td>The present study was undertaken to validate t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>Objective: To report a case series in which ba...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>133</td>\n",
              "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
              "      <td>Objective: To report a case series in which ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>374</td>\n",
              "      <td>New developments in diagnosis and therapy of C...</td>\n",
              "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
              "      <td>Prolonged shedding of SARS-CoV-2 in an elderl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                     abstract_title\n",
              "0   0  ...  Longitudinal studies indicate that declines in...\n",
              "1   1  ...  The present study was undertaken to validate t...\n",
              "2   2  ...  Objective: To report a case series in which ba...\n",
              "3   3  ...  The etiology and pathogenesis of idiopathic ch...\n",
              "4   4  ...   Prolonged shedding of SARS-CoV-2 in an elderl...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   id              40834 non-null  int64 \n",
            " 1   title           40834 non-null  object\n",
            " 2   abstract        40834 non-null  object\n",
            " 3   len_title       40834 non-null  int64 \n",
            " 4   len_abstract    40834 non-null  int64 \n",
            " 5   title_abstract  40834 non-null  object\n",
            " 6   abstract_title  40834 non-null  object\n",
            "dtypes: int64(3), object(4)\n",
            "memory usage: 2.2+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>len_title</th>\n",
              "      <th>len_abstract</th>\n",
              "      <th>title_abstract</th>\n",
              "      <th>abstract_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27145</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>The objective of the paper is to analyse chang...</td>\n",
              "      <td>16</td>\n",
              "      <td>245</td>\n",
              "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
              "      <td>The objective of the paper is to analyse chang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27146</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td></td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
              "      <td>Leukoerythroblastic reaction in a patient wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27147</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
              "      <td>14</td>\n",
              "      <td>315</td>\n",
              "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
              "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27148</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>We present a method that significantly improve...</td>\n",
              "      <td>11</td>\n",
              "      <td>119</td>\n",
              "      <td>Adaptive image segmentation for robust measure...</td>\n",
              "      <td>We present a method that significantly improve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27149</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>The objective of this study is to compare the ...</td>\n",
              "      <td>13</td>\n",
              "      <td>224</td>\n",
              "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
              "      <td>The objective of this study is to compare the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                     abstract_title\n",
              "0  27145  ...  The objective of the paper is to analyse chang...\n",
              "1  27146  ...   Leukoerythroblastic reaction in a patient wit...\n",
              "2  27147  ...  [15O]-water PET was performed on 12 patients w...\n",
              "3  27148  ...  We present a method that significantly improve...\n",
              "4  27149  ...  The objective of this study is to compare the ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40834 entries, 0 to 40833\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype\n",
            "---  ------     --------------  -----\n",
            " 0   id         40834 non-null  int64\n",
            " 1   judgement  40834 non-null  int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 638.2 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>judgement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27146</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27147</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  judgement\n",
              "0  27145          0\n",
              "1  27146          1\n",
              "2  27147          1\n",
              "3  27148          0\n",
              "4  27149          1"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9L3nMYzDMqJ"
      },
      "source": [
        "### 目的変数 judgement の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "3f5772d0",
        "outputId": "7fb91596-8f70-46a9-8f0d-cc9fbe66a0ba"
      },
      "source": [
        "sns.distplot(train[\"judgement\"], kde=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ef2893a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuZVvlM8Xy91",
        "outputId": "7e6f826c-8c8e-4dbb-e85d-d460728d0d6b"
      },
      "source": [
        "train[\"judgement\"].value_counts()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    26513\n",
              "1      632\n",
              "Name: judgement, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E-56356_L3T",
        "outputId": "6f1899c9-cd8f-43da-b827-8d7fa7c2a352"
      },
      "source": [
        "border = len(train[train[\"judgement\"] == 1]) / len(train[\"judgement\"])\n",
        "print(border)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.023282372444280715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZNrZoksDSMb"
      },
      "source": [
        "### title の単語数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "ixixzShVH80j",
        "outputId": "943fd345-e8b7-4ef6-bb90-cf448723f4a7"
      },
      "source": [
        "g = sns.FacetGrid(train[[\"judgement\", \"len_title\"]], hue='judgement')\n",
        "g.map(sns.distplot, 'len_title', label='judgement', hist=True, rug=False)\n",
        "g.add_legend()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f1ef2f7d150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 278.125x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W_kt9XDpGTm2",
        "outputId": "c3623fda-e529-4216-98e7-b6983cfad832"
      },
      "source": [
        "sns.distplot(test[\"len_title\"], hist=True, rug=False)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ef21062d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6gm9NCpDZ6V"
      },
      "source": [
        "### abstract の単語数の分布"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "EqwDn4hUImd6",
        "outputId": "1c0558e6-c0c9-4372-9a05-cf891841999c"
      },
      "source": [
        "g = sns.FacetGrid(train[[\"judgement\", \"len_abstract\"]], hue='judgement')\n",
        "g.map(sns.distplot, 'len_abstract', label='judgement', hist=True, rug=False)\n",
        "g.add_legend()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f1ef30d3490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 278.125x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "xHnKSMahIqI7",
        "outputId": "7bc03a92-0438-4797-a04b-e9357e578557"
      },
      "source": [
        "sns.distplot(test[\"len_abstract\"], hist=True, rug=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ef2fa5290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeZesLBHnfl5"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOdN4h2grTzx"
      },
      "source": [
        "if Config.validate:\n",
        "    api = wandb.Api()\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        try:\n",
        "            run.file(\"oof_df.csv\").download(run_id)\n",
        "        except wandb.CommError:\n",
        "            # Already downloaded.\n",
        "            pass\n",
        "\n",
        "        oof = pd.read_csv(f\"{run_id}/oof_df.csv\")[[\"id\", \"preds\"]]\n",
        "        oof.columns = [\"id\", f\"preds{n}\"]\n",
        "        train = pd.merge(train, oof, on=\"id\")\n",
        "    \n",
        "    print(train.columns)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM2fDBrNi2_K"
      },
      "source": [
        "if Config.inference:\n",
        "    api = wandb.Api()\n",
        "    inference_models = []\n",
        "\n",
        "    for n, run_id in enumerate(config.inference_runs):\n",
        "        if not os.path.exists(run_id):\n",
        "            os.makedirs(run_id)\n",
        "\n",
        "        run_path = f\"{Config.wandb_entity}/{Config.wandb_project}/{run_id}\"\n",
        "        run = api.run(run_path)\n",
        "\n",
        "        inference_model = {}\n",
        "        inference_model[\"run_id\"] = run_id\n",
        "        inference_model[\"model_name\"] = run.config[\"model_name\"]\n",
        "\n",
        "        for fold in range(config.n_fold):\n",
        "            try:\n",
        "                run.file(f\"{inference_model['model_name'].replace('/', '-')}_fold{fold}_best.pth\").download(run_id)\n",
        "            except wandb.CommError:\n",
        "                # Already downloaded.\n",
        "                pass\n",
        "\n",
        "            model_preds = torch.load(f\"{run_id}/{inference_model['model_name'].replace('/', '-')}_fold{fold}_best.pth\")\n",
        "            inference_model[f\"state_fold{fold}\"] = model_preds[\"model\"]\n",
        "            inference_model[f\"preds_fold{fold}\"] = model_preds[\"preds\"]\n",
        "\n",
        "        inference_models.append(inference_model)\n",
        "    \n",
        "    print({m['run_id']: m['model_name'] for m in inference_models})"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba31d893"
      },
      "source": [
        "if Config.debug:\n",
        "    train = train.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    test = test.sample(n=1000, random_state=config.seed).reset_index(drop=True)\n",
        "    sub = sub.sample(n=1000, random_state=config.seed).reset_index(drop=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQ7fKQ2IC6i"
      },
      "source": [
        "## CV Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Lt-ZLtIHCG",
        "outputId": "0737ab6c-bc36-411d-ae3f-e4ce4a33a1f4"
      },
      "source": [
        "Fold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train[[\"judgement\", \"nan_abstract\"]])):\n",
        "    train.loc[val_index, \"fold\"] = int(n)\n",
        "train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n",
        "print(train.groupby([\"fold\", \"judgement\", \"nan_abstract\"]).size())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold  judgement  nan_abstract\n",
            "0     0          0               4456\n",
            "                 1                847\n",
            "      1          0                 95\n",
            "                 1                 31\n",
            "1     0          0               4444\n",
            "                 1                858\n",
            "      1          0                107\n",
            "                 1                 20\n",
            "2     0          0               4456\n",
            "                 1                847\n",
            "      1          0                 95\n",
            "                 1                 31\n",
            "3     0          0               4441\n",
            "                 1                862\n",
            "      1          0                110\n",
            "                 1                 16\n",
            "4     0          0               4448\n",
            "                 1                854\n",
            "      1          0                103\n",
            "                 1                 24\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d423ea8"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5985d91d"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f\"[{name}] start\")\n",
        "    yield\n",
        "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR + \"train.log\"):\n",
        "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
        "\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_torch(seed=config.seed)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596efb85"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2721636"
      },
      "source": [
        "class BaseDataset(Dataset):\n",
        "    def __init__(self, df, model_name, include_labels=True):\n",
        "        tokenizer = T.AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        self.df = df\n",
        "        self.include_labels = include_labels\n",
        "\n",
        "        self.title = df[config.input].tolist()\n",
        "        self.encoded = tokenizer.batch_encode_plus(\n",
        "            self.title,\n",
        "            padding = 'max_length',            \n",
        "            max_length = config.max_len,\n",
        "            truncation = True,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        \n",
        "        if self.include_labels:\n",
        "            self.labels = df[\"judgement\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = torch.tensor(self.encoded['input_ids'][idx])\n",
        "        attention_mask = torch.tensor(self.encoded['attention_mask'][idx])\n",
        "\n",
        "        if self.include_labels:\n",
        "            label = torch.tensor(self.labels[idx]).float()\n",
        "            return input_ids, attention_mask, label\n",
        "\n",
        "        return input_ids, attention_mask\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e56a1c49",
        "outputId": "6d16d26a-9122-46db-d1a0-2f23b2a3f3f5"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "\n",
        "    train_ds = BaseDataset(train, config.model_name)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_ids, attention_mask, label = train_ds[i]\n",
        "        print(input_ids)\n",
        "        print(attention_mask)\n",
        "        print(f\"label: {label}\")\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101, 23191,  2527,  5057,  1115,  6246,  1116,  1107,  1884, 25763,\n",
            "         1105,  2962, 26872,  1170,  1425,  3102,  1201,   119,  1103, 24928,\n",
            "        11955,  3906, 18778,  1596,  1105, 24928, 11955, 22192, 23652, 13791,\n",
            "         1596,  1223,  6709,  3381,  1116,  1104, 12176,  1849,  1132, 10527,\n",
            "         1112,  1175,  1110,  1376,  1869,  1113, 23191,  3575,  2607,   119,\n",
            "         1195,  1132,  9239,   170, 23191, 24928, 11955,  8628,  3375,  2025,\n",
            "         1104,  1664,  2007, 24674,  2214,  6635,  1107,  1103,   171,  1348,\n",
            "         3121,  4982, 23191,  2025,  1104, 14195,   119,  1142,  2592,  7203,\n",
            "         1113,  1425,  1105,  2673,  5408,  1107,  3575,  2401,  7140,  1118,\n",
            "         8364, 20370, 14377,  1219,  1103,  1148,  1160,  2683, 10540,  1116,\n",
            "          119,  2771,   118,  2237,  1348,  2686,  1121, 13096,  6635,  4079,\n",
            "         4589,   118,  4859,  1201,  7063,  5409,  2610, 21828,  4907,  5552,\n",
            "         6357,  1105,  2964,  5021,  1105,  1653,  2187,  6357,  1107,  2214,\n",
            "         3402,  1114,  3247,  6635,  1105,  1107,  1441,  3402,  1114,  1535,\n",
            "          119,  2918,  3575,  6357,  1437,  1115,  1103,  3154,  1104,  1425,\n",
            "         1105,  2673,  1132,  1136,  6029,  1506,  3575,  4001,   119,  1425,\n",
            "         5408,  1132,  4459,  1111,  1103, 14247, 22331,  1348,  1805,   119,\n",
            "         2673,  5408,  6613,  1106,  1129,  2610,  1111, 22172,  1105, 18107,\n",
            "         1190, 14247, 22331,  1348,  1105,   184, 19557, 18965,  1348,  4001,\n",
            "          119, 23191,  3622, 17798,  1126,  2773,  1104, 15722,  1545,  2608,\n",
            "          113,   124,   114,  1107, 21828,  4907,  5552,  3884,  1166,   122,\n",
            "         1214,  1133,  1185, 11552,  1895,  1849,  1107,  1703,  1137,  2918,\n",
            "         3575,  6357,   119,  5754,  1104,  1103,  4844,  1105,  2603,  1104,\n",
            "        23191,  3575,  2607,  1209, 11000,  1103, 11432,  1104,  3507,  7542,\n",
            "         3575,  2607,  1134,  1336,  1129, 17163,  3864,  1104, 26707,  3452,\n",
            "         1465,   119,  1141,   118,  1214,  1425,  2607,  1107,   182,  2047,\n",
            "         3575,  6357,  1107,  2214,  6323,   119,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "label: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d681dabf"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHPwf3JzPmjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3325a092-3460-4be1-a084-11690520a21b"
      },
      "source": [
        "if config.model_name != \"\":\n",
        "    print(T.AutoConfig.from_pretrained(config.model_name))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.9.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "229d18e7"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "\n",
        "        if \"base\" in model_name or \"L-12\" in model_name:\n",
        "            out_dim = 768\n",
        "        elif \"large\" in model_name or \"L-24\" in model_name:\n",
        "            out_dim = 1024\n",
        "\n",
        "        auto_config = T.AutoConfig.from_pretrained(model_name)\n",
        "        auto_config.update({\n",
        "            \"output_hidden_states\": True,\n",
        "            \"hidden_dropout_prob\": config.dropout,\n",
        "            # \"layer_norm_eps\": 1e-7,\n",
        "        })\n",
        "        \n",
        "        self.auto_model = T.AutoModel.from_pretrained(model_name, config=auto_config)  \n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(out_dim, 512),            \n",
        "            nn.Tanh(),                       \n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )        \n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(out_dim, 1)                        \n",
        "        )\n",
        "\n",
        "        if config.reinit_layers > 0:\n",
        "            self.re_init()\n",
        "\n",
        "        if config.freeze_layers > 0:\n",
        "            self.freeze()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.auto_model(input_ids=input_ids, attention_mask=attention_mask)        \n",
        "\n",
        "        # There are a total of 13 layers of hidden states.\n",
        "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
        "        # We take the hidden states from the last Roberta layer.\n",
        "        last_layer_hidden_states = bert_output.hidden_states[-1]\n",
        "\n",
        "        # The number of cells is config.max_len.\n",
        "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
        "        # In order to condense hidden states of all cells to a context vector,\n",
        "        # we compute a weighted average of the hidden states of all cells.\n",
        "        # We compute the weight of each cell, using the attention neural network.\n",
        "        weights = self.attention(last_layer_hidden_states)\n",
        "                \n",
        "        # weights.shape is config.batch_size x config.max_len x 1\n",
        "        # last_layer_hidden_states.shape is config.batch_size x config.max_len x 768        \n",
        "        # Now we compute context_vector as the weighted average.\n",
        "        # context_vector.shape is config.batch_size x 768\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
        "        \n",
        "        # Now we reduce the context vector to the prediction score.\n",
        "        out = self.regressor(context_vector).squeeze()\n",
        "\n",
        "        return out\n",
        "\n",
        "    def re_init(self):\n",
        "        # re-init pooler\n",
        "        self.auto_model.pooler.dense.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "        self.auto_model.pooler.dense.bias.data.zero_()\n",
        "        for p in self.auto_model.pooler.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        # re-init encoder\n",
        "        layers = self.auto_model.encoder.layer[-config.reinit_layers:]\n",
        "        for layer in layers:\n",
        "            for module in layer.modules():\n",
        "                if isinstance(module, nn.Linear):\n",
        "                    # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "                    # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.bias is not None:\n",
        "                        module.bias.data.zero_()\n",
        "                elif isinstance(module, nn.Embedding):\n",
        "                    module.weight.data.normal_(mean=0.0, std=self.auto_model.config.initializer_range)\n",
        "                    if module.padding_idx is not None:\n",
        "                        module.weight.data[module.padding_idx].zero_()\n",
        "                elif isinstance(module, nn.LayerNorm):\n",
        "                    module.bias.data.zero_()\n",
        "                    module.weight.data.fill_(1.0)\n",
        "\n",
        "    def freeze(self):\n",
        "        # freeze embedding\n",
        "        for param in self.auto_model.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # freeze encoder\n",
        "        layers = self.auto_model.encoder.layer[:config.freeze_layers]\n",
        "        for layer in layers:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a3978b1",
        "outputId": "53a1e890-e27b-4935-ca0a-c75768c6d986"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "\n",
        "    model = BaseModel(config.model_name)\n",
        "    print(model)\n",
        "\n",
        "    train_dataset = BaseDataset(train, config.model_name)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "    for input_ids, attention_mask, labels in train_loader:\n",
        "        output = model(input_ids, attention_mask)\n",
        "        print(output)\n",
        "        break\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BaseModel(\n",
            "  (auto_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (attention): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (3): Softmax(dim=1)\n",
            "  )\n",
            "  (regressor): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "tensor([-5.2276e-01, -6.5785e-01, -4.6085e-01,  2.1973e-04],\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlpHUm-SrcLV",
        "outputId": "b39e0782-6fe7-4bce-bd11-73e505f97f96"
      },
      "source": [
        "# Test\n",
        "\n",
        "if config.model_name != \"\":\n",
        "    for n, (name, tensor) in enumerate(list(model.named_parameters())):\n",
        "        print(f\"{n:>4}: {tensor.requires_grad}, {name}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0: True, auto_model.embeddings.word_embeddings.weight\n",
            "   1: True, auto_model.embeddings.position_embeddings.weight\n",
            "   2: True, auto_model.embeddings.token_type_embeddings.weight\n",
            "   3: True, auto_model.embeddings.LayerNorm.weight\n",
            "   4: True, auto_model.embeddings.LayerNorm.bias\n",
            "   5: True, auto_model.encoder.layer.0.attention.self.query.weight\n",
            "   6: True, auto_model.encoder.layer.0.attention.self.query.bias\n",
            "   7: True, auto_model.encoder.layer.0.attention.self.key.weight\n",
            "   8: True, auto_model.encoder.layer.0.attention.self.key.bias\n",
            "   9: True, auto_model.encoder.layer.0.attention.self.value.weight\n",
            "  10: True, auto_model.encoder.layer.0.attention.self.value.bias\n",
            "  11: True, auto_model.encoder.layer.0.attention.output.dense.weight\n",
            "  12: True, auto_model.encoder.layer.0.attention.output.dense.bias\n",
            "  13: True, auto_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "  14: True, auto_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "  15: True, auto_model.encoder.layer.0.intermediate.dense.weight\n",
            "  16: True, auto_model.encoder.layer.0.intermediate.dense.bias\n",
            "  17: True, auto_model.encoder.layer.0.output.dense.weight\n",
            "  18: True, auto_model.encoder.layer.0.output.dense.bias\n",
            "  19: True, auto_model.encoder.layer.0.output.LayerNorm.weight\n",
            "  20: True, auto_model.encoder.layer.0.output.LayerNorm.bias\n",
            "  21: True, auto_model.encoder.layer.1.attention.self.query.weight\n",
            "  22: True, auto_model.encoder.layer.1.attention.self.query.bias\n",
            "  23: True, auto_model.encoder.layer.1.attention.self.key.weight\n",
            "  24: True, auto_model.encoder.layer.1.attention.self.key.bias\n",
            "  25: True, auto_model.encoder.layer.1.attention.self.value.weight\n",
            "  26: True, auto_model.encoder.layer.1.attention.self.value.bias\n",
            "  27: True, auto_model.encoder.layer.1.attention.output.dense.weight\n",
            "  28: True, auto_model.encoder.layer.1.attention.output.dense.bias\n",
            "  29: True, auto_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "  30: True, auto_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "  31: True, auto_model.encoder.layer.1.intermediate.dense.weight\n",
            "  32: True, auto_model.encoder.layer.1.intermediate.dense.bias\n",
            "  33: True, auto_model.encoder.layer.1.output.dense.weight\n",
            "  34: True, auto_model.encoder.layer.1.output.dense.bias\n",
            "  35: True, auto_model.encoder.layer.1.output.LayerNorm.weight\n",
            "  36: True, auto_model.encoder.layer.1.output.LayerNorm.bias\n",
            "  37: True, auto_model.encoder.layer.2.attention.self.query.weight\n",
            "  38: True, auto_model.encoder.layer.2.attention.self.query.bias\n",
            "  39: True, auto_model.encoder.layer.2.attention.self.key.weight\n",
            "  40: True, auto_model.encoder.layer.2.attention.self.key.bias\n",
            "  41: True, auto_model.encoder.layer.2.attention.self.value.weight\n",
            "  42: True, auto_model.encoder.layer.2.attention.self.value.bias\n",
            "  43: True, auto_model.encoder.layer.2.attention.output.dense.weight\n",
            "  44: True, auto_model.encoder.layer.2.attention.output.dense.bias\n",
            "  45: True, auto_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "  46: True, auto_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "  47: True, auto_model.encoder.layer.2.intermediate.dense.weight\n",
            "  48: True, auto_model.encoder.layer.2.intermediate.dense.bias\n",
            "  49: True, auto_model.encoder.layer.2.output.dense.weight\n",
            "  50: True, auto_model.encoder.layer.2.output.dense.bias\n",
            "  51: True, auto_model.encoder.layer.2.output.LayerNorm.weight\n",
            "  52: True, auto_model.encoder.layer.2.output.LayerNorm.bias\n",
            "  53: True, auto_model.encoder.layer.3.attention.self.query.weight\n",
            "  54: True, auto_model.encoder.layer.3.attention.self.query.bias\n",
            "  55: True, auto_model.encoder.layer.3.attention.self.key.weight\n",
            "  56: True, auto_model.encoder.layer.3.attention.self.key.bias\n",
            "  57: True, auto_model.encoder.layer.3.attention.self.value.weight\n",
            "  58: True, auto_model.encoder.layer.3.attention.self.value.bias\n",
            "  59: True, auto_model.encoder.layer.3.attention.output.dense.weight\n",
            "  60: True, auto_model.encoder.layer.3.attention.output.dense.bias\n",
            "  61: True, auto_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "  62: True, auto_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "  63: True, auto_model.encoder.layer.3.intermediate.dense.weight\n",
            "  64: True, auto_model.encoder.layer.3.intermediate.dense.bias\n",
            "  65: True, auto_model.encoder.layer.3.output.dense.weight\n",
            "  66: True, auto_model.encoder.layer.3.output.dense.bias\n",
            "  67: True, auto_model.encoder.layer.3.output.LayerNorm.weight\n",
            "  68: True, auto_model.encoder.layer.3.output.LayerNorm.bias\n",
            "  69: True, auto_model.encoder.layer.4.attention.self.query.weight\n",
            "  70: True, auto_model.encoder.layer.4.attention.self.query.bias\n",
            "  71: True, auto_model.encoder.layer.4.attention.self.key.weight\n",
            "  72: True, auto_model.encoder.layer.4.attention.self.key.bias\n",
            "  73: True, auto_model.encoder.layer.4.attention.self.value.weight\n",
            "  74: True, auto_model.encoder.layer.4.attention.self.value.bias\n",
            "  75: True, auto_model.encoder.layer.4.attention.output.dense.weight\n",
            "  76: True, auto_model.encoder.layer.4.attention.output.dense.bias\n",
            "  77: True, auto_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "  78: True, auto_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "  79: True, auto_model.encoder.layer.4.intermediate.dense.weight\n",
            "  80: True, auto_model.encoder.layer.4.intermediate.dense.bias\n",
            "  81: True, auto_model.encoder.layer.4.output.dense.weight\n",
            "  82: True, auto_model.encoder.layer.4.output.dense.bias\n",
            "  83: True, auto_model.encoder.layer.4.output.LayerNorm.weight\n",
            "  84: True, auto_model.encoder.layer.4.output.LayerNorm.bias\n",
            "  85: True, auto_model.encoder.layer.5.attention.self.query.weight\n",
            "  86: True, auto_model.encoder.layer.5.attention.self.query.bias\n",
            "  87: True, auto_model.encoder.layer.5.attention.self.key.weight\n",
            "  88: True, auto_model.encoder.layer.5.attention.self.key.bias\n",
            "  89: True, auto_model.encoder.layer.5.attention.self.value.weight\n",
            "  90: True, auto_model.encoder.layer.5.attention.self.value.bias\n",
            "  91: True, auto_model.encoder.layer.5.attention.output.dense.weight\n",
            "  92: True, auto_model.encoder.layer.5.attention.output.dense.bias\n",
            "  93: True, auto_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "  94: True, auto_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "  95: True, auto_model.encoder.layer.5.intermediate.dense.weight\n",
            "  96: True, auto_model.encoder.layer.5.intermediate.dense.bias\n",
            "  97: True, auto_model.encoder.layer.5.output.dense.weight\n",
            "  98: True, auto_model.encoder.layer.5.output.dense.bias\n",
            "  99: True, auto_model.encoder.layer.5.output.LayerNorm.weight\n",
            " 100: True, auto_model.encoder.layer.5.output.LayerNorm.bias\n",
            " 101: True, auto_model.encoder.layer.6.attention.self.query.weight\n",
            " 102: True, auto_model.encoder.layer.6.attention.self.query.bias\n",
            " 103: True, auto_model.encoder.layer.6.attention.self.key.weight\n",
            " 104: True, auto_model.encoder.layer.6.attention.self.key.bias\n",
            " 105: True, auto_model.encoder.layer.6.attention.self.value.weight\n",
            " 106: True, auto_model.encoder.layer.6.attention.self.value.bias\n",
            " 107: True, auto_model.encoder.layer.6.attention.output.dense.weight\n",
            " 108: True, auto_model.encoder.layer.6.attention.output.dense.bias\n",
            " 109: True, auto_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            " 110: True, auto_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            " 111: True, auto_model.encoder.layer.6.intermediate.dense.weight\n",
            " 112: True, auto_model.encoder.layer.6.intermediate.dense.bias\n",
            " 113: True, auto_model.encoder.layer.6.output.dense.weight\n",
            " 114: True, auto_model.encoder.layer.6.output.dense.bias\n",
            " 115: True, auto_model.encoder.layer.6.output.LayerNorm.weight\n",
            " 116: True, auto_model.encoder.layer.6.output.LayerNorm.bias\n",
            " 117: True, auto_model.encoder.layer.7.attention.self.query.weight\n",
            " 118: True, auto_model.encoder.layer.7.attention.self.query.bias\n",
            " 119: True, auto_model.encoder.layer.7.attention.self.key.weight\n",
            " 120: True, auto_model.encoder.layer.7.attention.self.key.bias\n",
            " 121: True, auto_model.encoder.layer.7.attention.self.value.weight\n",
            " 122: True, auto_model.encoder.layer.7.attention.self.value.bias\n",
            " 123: True, auto_model.encoder.layer.7.attention.output.dense.weight\n",
            " 124: True, auto_model.encoder.layer.7.attention.output.dense.bias\n",
            " 125: True, auto_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            " 126: True, auto_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            " 127: True, auto_model.encoder.layer.7.intermediate.dense.weight\n",
            " 128: True, auto_model.encoder.layer.7.intermediate.dense.bias\n",
            " 129: True, auto_model.encoder.layer.7.output.dense.weight\n",
            " 130: True, auto_model.encoder.layer.7.output.dense.bias\n",
            " 131: True, auto_model.encoder.layer.7.output.LayerNorm.weight\n",
            " 132: True, auto_model.encoder.layer.7.output.LayerNorm.bias\n",
            " 133: True, auto_model.encoder.layer.8.attention.self.query.weight\n",
            " 134: True, auto_model.encoder.layer.8.attention.self.query.bias\n",
            " 135: True, auto_model.encoder.layer.8.attention.self.key.weight\n",
            " 136: True, auto_model.encoder.layer.8.attention.self.key.bias\n",
            " 137: True, auto_model.encoder.layer.8.attention.self.value.weight\n",
            " 138: True, auto_model.encoder.layer.8.attention.self.value.bias\n",
            " 139: True, auto_model.encoder.layer.8.attention.output.dense.weight\n",
            " 140: True, auto_model.encoder.layer.8.attention.output.dense.bias\n",
            " 141: True, auto_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            " 142: True, auto_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            " 143: True, auto_model.encoder.layer.8.intermediate.dense.weight\n",
            " 144: True, auto_model.encoder.layer.8.intermediate.dense.bias\n",
            " 145: True, auto_model.encoder.layer.8.output.dense.weight\n",
            " 146: True, auto_model.encoder.layer.8.output.dense.bias\n",
            " 147: True, auto_model.encoder.layer.8.output.LayerNorm.weight\n",
            " 148: True, auto_model.encoder.layer.8.output.LayerNorm.bias\n",
            " 149: True, auto_model.encoder.layer.9.attention.self.query.weight\n",
            " 150: True, auto_model.encoder.layer.9.attention.self.query.bias\n",
            " 151: True, auto_model.encoder.layer.9.attention.self.key.weight\n",
            " 152: True, auto_model.encoder.layer.9.attention.self.key.bias\n",
            " 153: True, auto_model.encoder.layer.9.attention.self.value.weight\n",
            " 154: True, auto_model.encoder.layer.9.attention.self.value.bias\n",
            " 155: True, auto_model.encoder.layer.9.attention.output.dense.weight\n",
            " 156: True, auto_model.encoder.layer.9.attention.output.dense.bias\n",
            " 157: True, auto_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            " 158: True, auto_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            " 159: True, auto_model.encoder.layer.9.intermediate.dense.weight\n",
            " 160: True, auto_model.encoder.layer.9.intermediate.dense.bias\n",
            " 161: True, auto_model.encoder.layer.9.output.dense.weight\n",
            " 162: True, auto_model.encoder.layer.9.output.dense.bias\n",
            " 163: True, auto_model.encoder.layer.9.output.LayerNorm.weight\n",
            " 164: True, auto_model.encoder.layer.9.output.LayerNorm.bias\n",
            " 165: True, auto_model.encoder.layer.10.attention.self.query.weight\n",
            " 166: True, auto_model.encoder.layer.10.attention.self.query.bias\n",
            " 167: True, auto_model.encoder.layer.10.attention.self.key.weight\n",
            " 168: True, auto_model.encoder.layer.10.attention.self.key.bias\n",
            " 169: True, auto_model.encoder.layer.10.attention.self.value.weight\n",
            " 170: True, auto_model.encoder.layer.10.attention.self.value.bias\n",
            " 171: True, auto_model.encoder.layer.10.attention.output.dense.weight\n",
            " 172: True, auto_model.encoder.layer.10.attention.output.dense.bias\n",
            " 173: True, auto_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            " 174: True, auto_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            " 175: True, auto_model.encoder.layer.10.intermediate.dense.weight\n",
            " 176: True, auto_model.encoder.layer.10.intermediate.dense.bias\n",
            " 177: True, auto_model.encoder.layer.10.output.dense.weight\n",
            " 178: True, auto_model.encoder.layer.10.output.dense.bias\n",
            " 179: True, auto_model.encoder.layer.10.output.LayerNorm.weight\n",
            " 180: True, auto_model.encoder.layer.10.output.LayerNorm.bias\n",
            " 181: True, auto_model.encoder.layer.11.attention.self.query.weight\n",
            " 182: True, auto_model.encoder.layer.11.attention.self.query.bias\n",
            " 183: True, auto_model.encoder.layer.11.attention.self.key.weight\n",
            " 184: True, auto_model.encoder.layer.11.attention.self.key.bias\n",
            " 185: True, auto_model.encoder.layer.11.attention.self.value.weight\n",
            " 186: True, auto_model.encoder.layer.11.attention.self.value.bias\n",
            " 187: True, auto_model.encoder.layer.11.attention.output.dense.weight\n",
            " 188: True, auto_model.encoder.layer.11.attention.output.dense.bias\n",
            " 189: True, auto_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            " 190: True, auto_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            " 191: True, auto_model.encoder.layer.11.intermediate.dense.weight\n",
            " 192: True, auto_model.encoder.layer.11.intermediate.dense.bias\n",
            " 193: True, auto_model.encoder.layer.11.output.dense.weight\n",
            " 194: True, auto_model.encoder.layer.11.output.dense.bias\n",
            " 195: True, auto_model.encoder.layer.11.output.LayerNorm.weight\n",
            " 196: True, auto_model.encoder.layer.11.output.LayerNorm.bias\n",
            " 197: True, auto_model.pooler.dense.weight\n",
            " 198: True, auto_model.pooler.dense.bias\n",
            " 199: True, attention.0.weight\n",
            " 200: True, attention.0.bias\n",
            " 201: True, attention.2.weight\n",
            " 202: True, attention.2.bias\n",
            " 203: True, regressor.0.weight\n",
            " 204: True, regressor.0.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PcTNCYuDeuC"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzoJMxr3DeVG"
      },
      "source": [
        "def bert_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "    \n",
        "    if \"albert-base\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:23]    \n",
        "        attention_parameters = named_parameters[25:29]\n",
        "        regressor_parameters = named_parameters[29:]\n",
        "        second_block = 999\n",
        "        third_block = 999\n",
        "\n",
        "    elif \"base\" in config.model_name or \"L-12\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:197]    \n",
        "        attention_parameters = named_parameters[199:203]\n",
        "        regressor_parameters = named_parameters[203:]\n",
        "        second_block = 69\n",
        "        third_block = 133\n",
        "\n",
        "    elif \"large\" in config.model_name or \"L-24\" in config.model_name:\n",
        "        bert_parameters = named_parameters[:388]    \n",
        "        attention_parameters = named_parameters[391:395]\n",
        "        regressor_parameters = named_parameters[395:]\n",
        "        second_block = 133\n",
        "        third_block = 261\n",
        "        \n",
        "    attention_group = [params for (name, params) in attention_parameters]\n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": attention_group})\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(bert_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else config.weight_decay\n",
        "\n",
        "        lr = config.lr\n",
        "\n",
        "        if layer_num >= second_block:        \n",
        "            lr = config.lr_69\n",
        "\n",
        "        if layer_num >= third_block:\n",
        "            lr = config.lr_133\n",
        "\n",
        "        parameters.append({\"params\": params, \"weight_decay\": weight_decay, \"lr\": lr})\n",
        "\n",
        "    return T.AdamW(parameters)\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de50761e"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47fcae06"
      },
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-7):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self, yhat, y):\n",
        "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
        "        return loss"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjpp5Rh-4jKW"
      },
      "source": [
        "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
        "class FBetaLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, beta=1.0, epsilon=1e-7):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
        "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
        "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "\n",
        "        beta_squared = self.beta ** 2\n",
        "        fbeta = (1 + beta_squared) * precision * recall / (beta_squared * precision + recall + self.epsilon)\n",
        "        fbeta = fbeta.clamp(min=self.epsilon, max=1-self.epsilon)\n",
        "        return 1 - fbeta.mean()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93661540"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19d9d03c"
      },
      "source": [
        "def get_score(y_true, y_pred, b=border):\n",
        "    y_pred = np.where(y_pred < b, 0, 1)\n",
        "    return fbeta_score(y_true, y_pred, beta=7.0)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1b92d4f"
      },
      "source": [
        "def get_result(result_df, fold=config.n_fold):\n",
        "    preds = result_df[\"preds\"].values\n",
        "    labels = result_df[\"judgement\"].values\n",
        "    score = get_score(labels, preds)\n",
        "    LOGGER.info(f\"Score: {score:<.5f}\")\n",
        "    # wandb.log({\"fold\": fold, \"CV\": score})\n",
        "    if fold == config.n_fold:\n",
        "        wandb.run.summary[f\"CV\"] = score\n",
        "    else:\n",
        "        wandb.run.summary[f\"CV_fold{fold}\"] = score\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJUo-Mjlv_2"
      },
      "source": [
        "def determine_border(b, y_true, y_pred):\n",
        "    return -1 * get_score(y_true, y_pred, b)\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf498df"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5b0e152"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return \"%dm %ds\" % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNxJNSgwg-0E"
      },
      "source": [
        "def pre_train_fn():\n",
        "    tokenizer = T.AutoTokenizer.from_pretrained(config.model_name)\n",
        "    model = T.AutoModelForMaskedLM.from_pretrained(config.model_name)\n",
        "\n",
        "    tokenizer.save_pretrained(f\"./pretrained_{config.model_name}\")\n",
        "\n",
        "    train_dataset = T.LineByLineTextDataset(tokenizer=tokenizer, file_path=\"abstracts.txt\", block_size=512)\n",
        "    valid_dataset = T.LineByLineTextDataset(tokenizer=tokenizer, file_path=\"abstracts.txt\", block_size=512)\n",
        "\n",
        "    data_collator = T.DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        "    )\n",
        "\n",
        "    training_args = T.TrainingArguments(\n",
        "        output_dir = f\"./pretrained_{config.model_name}_chk\",\n",
        "        overwrite_output_dir = True,\n",
        "        num_train_epochs = 5,\n",
        "        per_device_train_batch_size = 4,\n",
        "        per_device_eval_batch_size = 4,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        evaluation_strategy = 'steps',\n",
        "        save_total_limit = 2,\n",
        "        eval_steps = 105,\n",
        "        save_steps = 105,\n",
        "        metric_for_best_model = 'eval_loss',\n",
        "        greater_is_better = False,\n",
        "        load_best_model_at_end = True,\n",
        "        prediction_loss_only = True,\n",
        "        report_to = \"wandb\",\n",
        "    )\n",
        "\n",
        "    trainer = T.Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=valid_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    trainer.save_model(f\"./pretrained_{config.model_name}\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99a3bfb5"
      },
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "        if Config.apex:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "\n",
        "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if isinstance(scheduler, ReduceLROnPlateau):\n",
        "                scheduler.step(avg_val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "            \n",
        "            global_step += 1\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(train_loader) - 1):\n",
        "            print(\n",
        "                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "                f\"Grad: {grad_norm:.4f} \"\n",
        "                # f\"LR: {scheduler.get_last_lr()[0]:.6f}  \"\n",
        "                f\"LR: {scheduler.get_lr()[0]:.6f}  \"\n",
        "            )\n",
        "\n",
        "    return losses.avg"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "186c441d"
      },
      "source": [
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    scores = AverageMeter()\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "\n",
        "    for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        # compute loss\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(y_preds, labels)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # record score\n",
        "        # preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "        preds.append(y_preds.to(\"cpu\").numpy())\n",
        "        if config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / config.gradient_accumulation_steps\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if step % Config.print_freq == 0 or step == (len(valid_loader) - 1):\n",
        "            print(\n",
        "                f\"EVAL: [{step}/{len(valid_loader)}] \"\n",
        "                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n",
        "                f\"Loss: {losses.avg:.4f} \"\n",
        "            )\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7cdfc9"
      },
      "source": [
        "def inference():\n",
        "    predictions = []\n",
        "\n",
        "    for model_item in inference_models:\n",
        "        test_dataset = BaseDataset(test, model_item['model_name'], include_labels=False)\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True\n",
        "        )\n",
        "\n",
        "        for fold in range(config.n_fold):\n",
        "            LOGGER.info(f\"========== ID: {model_item['run_id']} model: {model_item['model_name']} fold: {fold} inference ==========\")\n",
        "            model = BaseModel(model_item['model_name'])\n",
        "            model.to(device)\n",
        "            model.load_state_dict(model_item[f\"state_fold{fold}\"])\n",
        "            model.eval()\n",
        "            preds = []\n",
        "            for i, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                with torch.no_grad():\n",
        "                    y_preds = model(input_ids, attention_mask)\n",
        "                # avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
        "                preds.append(y_preds.to(\"cpu\").numpy())\n",
        "            preds = np.concatenate(preds)\n",
        "            predictions.append(preds)\n",
        "    predictions = np.mean(predictions, axis=0)\n",
        "\n",
        "    if config.criterion == \"BCEWithLogitsLoss\":\n",
        "        predictions = 1 / (1 + np.exp(-predictions))\n",
        "\n",
        "    return predictions\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9663c1"
      },
      "source": [
        "## Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357969e6"
      },
      "source": [
        "def train_loop(df, fold):\n",
        "\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # Data Loader\n",
        "    # ====================================================\n",
        "    trn_idx = df[df[\"fold\"] != fold].index\n",
        "    val_idx = df[df[\"fold\"] == fold].index\n",
        "\n",
        "    train_folds = df.loc[trn_idx].reset_index(drop=True)\n",
        "    valid_folds = df.loc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BaseDataset(train_folds, config.model_name)\n",
        "    valid_dataset = BaseDataset(valid_folds, config.model_name)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    # ====================================================\n",
        "    # Optimizer\n",
        "    # ====================================================\n",
        "    def get_optimizer(model):\n",
        "        if config.optimizer == \"Adam\":\n",
        "            optimizer = Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay, amsgrad=False)\n",
        "        elif config.optimizer == \"AdamW\":\n",
        "            optimizer = T.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "        elif config.optimizer == \"BertAdamW\":\n",
        "            optimizer = bert_optimizer(model)\n",
        "        return optimizer\n",
        "\n",
        "    # ====================================================\n",
        "    # Scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(optimizer):\n",
        "        if config.scheduler == \"ReduceLROnPlateau\":\n",
        "            scheduler = ReduceLROnPlateau(\n",
        "                optimizer, mode=\"min\", factor=config.factor, patience=config.patience, verbose=True, eps=config.eps\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingLR\":\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=config.T_max, eta_min=config.min_lr, last_epoch=-1)\n",
        "        elif config.scheduler == \"CosineAnnealingWarmRestarts\":\n",
        "            scheduler = CosineAnnealingWarmRestarts(\n",
        "                optimizer, T_0=config.T_0, T_mult=1, eta_min=config.min_lr, last_epoch=-1\n",
        "            )\n",
        "        elif config.scheduler == \"CosineAnnealingWarmupRestarts\":\n",
        "            scheduler = CosineAnnealingWarmupRestarts(\n",
        "                optimizer, first_cycle_steps=config.first_cycle_steps, max_lr=config.lr, min_lr=config.min_lr, warmup_steps=config.warmup_steps\n",
        "            )\n",
        "        elif config.scheduler == \"get_cosine_schedule_with_warmup\":\n",
        "            scheduler = T.get_cosine_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_training_steps=config.num_training_steps, \n",
        "                num_warmup_steps=config.num_warmup_steps\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    # ====================================================\n",
        "    # Model\n",
        "    # ====================================================\n",
        "    model = BaseModel(config.model_name)\n",
        "    model.to(device)\n",
        "\n",
        "    # Use multi GPU\n",
        "    if device == torch.device(\"cuda\") and not Config.apex and Config.multi_gpu:\n",
        "        model = torch.nn.DataParallel(model)  # make parallel\n",
        "        # torch.backends.cudnn.benchmark=True\n",
        "\n",
        "    optimizer = get_optimizer(model)\n",
        "    scheduler = get_scheduler(optimizer)\n",
        "\n",
        "    # ====================================================\n",
        "    # Apex\n",
        "    # ====================================================\n",
        "    if Config.apex:\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity=0)\n",
        "\n",
        "    # ====================================================\n",
        "    # Criterion\n",
        "    # ====================================================\n",
        "    def get_criterion():\n",
        "        if config.criterion == \"CrossEntropyLoss\":\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "        elif config.criterion == \"BCEWithLogitsLoss\":\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "        elif config.criterion == \"MSELoss\":\n",
        "            criterion = nn.MSELoss()\n",
        "        elif config.criterion == \"RMSELoss\":\n",
        "            criterion = RMSELoss()\n",
        "        elif config.criterion == \"FBetaLoss\":\n",
        "            criterion = FBetaLoss(7.0)\n",
        "\n",
        "        return criterion\n",
        "\n",
        "    criterion = get_criterion()\n",
        "\n",
        "    # ====================================================\n",
        "    # Loop\n",
        "    # ====================================================\n",
        "    best_score = -1\n",
        "    best_loss = np.inf\n",
        "\n",
        "    # if not Config.multi_gpu:\n",
        "    #     wandb.watch(model, log_freq=Config.print_freq)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
        "        valid_labels = valid_folds[\"judgement\"].values\n",
        "\n",
        "        # if isinstance(scheduler, ReduceLROnPlateau):\n",
        "        #     scheduler.step(avg_val_loss)\n",
        "        # else:\n",
        "        #     scheduler.step()\n",
        "\n",
        "        if config.criterion == \"BCEWithLogitsLoss\":\n",
        "            preds = 1 / (1 + np.exp(-preds))\n",
        "\n",
        "        # scoring\n",
        "        # score = get_score(valid_labels, preds.argmax(1))\n",
        "        score = get_score(valid_labels, preds)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(\n",
        "            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
        "        )\n",
        "        LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n",
        "\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"epoch\": epoch + 1,\n",
        "                f\"loss/train_fold{fold}\": avg_loss,\n",
        "                f\"loss/val_fold{fold}\": avg_val_loss,\n",
        "                f\"score/fold{fold}\": score,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model\")\n",
        "            torch.save(\n",
        "                {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\"\n",
        "            )\n",
        "            wandb.save(OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "        # if epoch == config.epochs - 1:\n",
        "        #     LOGGER.info(f\"Epoch {epoch+1} - Save final model\")\n",
        "        #     torch.save(\n",
        "        #         {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"{config.model_name}_fold{fold}_final.pth\"\n",
        "        #     )\n",
        "\n",
        "    check_point = torch.load(OUTPUT_DIR + f\"{config.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "    valid_folds[[str(c) for c in range(config.n_class)]] = check_point[\"preds\"]\n",
        "    valid_folds[\"preds\"] = check_point[\"preds\"]  # .argmax(1)\n",
        "\n",
        "    return valid_folds"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97b42fa3"
      },
      "source": [
        "## Main\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5baf150d"
      },
      "source": [
        "def main():\n",
        "    if Config.pre_train:\n",
        "        abstract_df = pd.concat([train[\"abstract\"], test[\"abstract\"]])\n",
        "        abstracts  = '\\n'.join(abstract_df.tolist())\n",
        "        with open(\"abstracts.txt\", \"w\") as f:\n",
        "            f.write(abstracts)\n",
        "\n",
        "        pre_train_fn()\n",
        "\n",
        "    if Config.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(config.n_fold):\n",
        "            seed_torch(seed + fold)\n",
        "\n",
        "            _oof_df = train_loop(train, fold)\n",
        "            oof_df = pd.concat([oof_df, _oof_df])\n",
        "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "            get_result(_oof_df, fold)\n",
        "            \n",
        "        # CV result\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        \n",
        "        # save result\n",
        "        oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"oof_df.csv\")\n",
        "        \n",
        "    if Config.validate:\n",
        "        probs = []\n",
        "\n",
        "        for n in range(len(config.inference_runs)):\n",
        "            probs.append(train[f\"preds{n}\"].values)\n",
        "        preds = np.mean(probs, axis=0)\n",
        "        train[\"preds\"] = preds\n",
        "\n",
        "        # Post process\n",
        "        if config.border == \"minimize\":\n",
        "            res = sp.optimize.minimize_scalar(determine_border, method='bounded', bounds=(0, 1), args=(train[\"judgement\"].values, preds))\n",
        "            LOGGER.info(f\"========== Border Optimization ==========\")\n",
        "            LOGGER.info(f\"Border: {res.x:<.5f}, Score: {-res.fun:<.5f}\")\n",
        "            wandb.run.summary[f\"CV\"] = -res.fun\n",
        "\n",
        "        elif config.border == \"fixed\":\n",
        "            # CV result\n",
        "            LOGGER.info(f\"========== CV ==========\")\n",
        "            get_result(train)\n",
        "\n",
        "        # save result\n",
        "        train.to_csv(OUTPUT_DIR + \"validation_df.csv\", index=False)\n",
        "        wandb.save(OUTPUT_DIR + \"validation_df.csv\")\n",
        "\n",
        "    if Config.inference:\n",
        "        predictions = inference()\n",
        "\n",
        "        # Post process\n",
        "        try:\n",
        "            b = res.x\n",
        "        except Exception:\n",
        "            b = border\n",
        "        wandb.run.summary[f\"border\"] = b\n",
        "\n",
        "        predictions = np.where(predictions < b, 0, 1)\n",
        "\n",
        "        # submission\n",
        "        sub[\"judgement\"] = predictions  # .argmax(1)\n",
        "        print(sub[\"judgement\"].value_counts())\n",
        "\n",
        "        sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n",
        "        wandb.save(OUTPUT_DIR + \"submission.csv\")\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "726e744f",
        "outputId": "e98c559a-acba-4c3c-f237-7b3f9a45739d"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========== fold: 0 training ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/1809] Elapsed 0m 1s (remain 31m 39s) Loss: 0.4759 Grad: 3.7578 LR: 0.000000  \n",
            "Epoch: [1][100/1809] Elapsed 0m 37s (remain 10m 32s) Loss: 0.2216 Grad: 0.2570 LR: 0.000185  \n",
            "Epoch: [1][200/1809] Elapsed 1m 13s (remain 9m 50s) Loss: 0.1582 Grad: 0.1371 LR: 0.000369  \n",
            "Epoch: [1][300/1809] Elapsed 1m 50s (remain 9m 13s) Loss: 0.1356 Grad: 0.1279 LR: 0.000554  \n",
            "Epoch: [1][400/1809] Elapsed 2m 26s (remain 8m 35s) Loss: 0.1210 Grad: 0.1662 LR: 0.000738  \n",
            "Epoch: [1][500/1809] Elapsed 3m 3s (remain 7m 59s) Loss: 0.1177 Grad: 0.1690 LR: 0.000923  \n",
            "Epoch: [1][600/1809] Elapsed 3m 40s (remain 7m 22s) Loss: 0.1114 Grad: 0.0593 LR: 0.001000  \n",
            "Epoch: [1][700/1809] Elapsed 4m 16s (remain 6m 45s) Loss: 0.1054 Grad: 0.0944 LR: 0.000997  \n",
            "Epoch: [1][800/1809] Elapsed 4m 53s (remain 6m 8s) Loss: 0.1031 Grad: 0.0087 LR: 0.000993  \n",
            "Epoch: [1][900/1809] Elapsed 5m 29s (remain 5m 32s) Loss: 0.1029 Grad: 0.5357 LR: 0.000987  \n",
            "Epoch: [1][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.1005 Grad: 1.4018 LR: 0.000978  \n",
            "Epoch: [1][1100/1809] Elapsed 6m 42s (remain 4m 19s) Loss: 0.0969 Grad: 0.1805 LR: 0.000968  \n",
            "Epoch: [1][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0926 Grad: 0.4318 LR: 0.000956  \n",
            "Epoch: [1][1300/1809] Elapsed 7m 55s (remain 3m 5s) Loss: 0.0905 Grad: 0.0323 LR: 0.000942  \n",
            "Epoch: [1][1400/1809] Elapsed 8m 32s (remain 2m 29s) Loss: 0.0878 Grad: 0.0731 LR: 0.000926  \n",
            "Epoch: [1][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0846 Grad: 0.1115 LR: 0.000908  \n",
            "Epoch: [1][1600/1809] Elapsed 9m 45s (remain 1m 16s) Loss: 0.0826 Grad: 0.8210 LR: 0.000889  \n",
            "Epoch: [1][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0810 Grad: 0.0529 LR: 0.000867  \n",
            "Epoch: [1][1800/1809] Elapsed 10m 58s (remain 0m 2s) Loss: 0.0793 Grad: 0.0618 LR: 0.000845  \n",
            "Epoch: [1][1808/1809] Elapsed 11m 1s (remain 0m 0s) Loss: 0.0792 Grad: 0.7217 LR: 0.000843  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 29s) Loss: 0.0111 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0479 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0439 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0447 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0442 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0452 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0792  avg_val_loss: 0.0452  time: 717s\n",
            "Epoch 1 - Score: 0.8849557522123894\n",
            "Epoch 1 - Save Best Score: 0.8850 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/1809] Elapsed 0m 1s (remain 55m 54s) Loss: 0.0181 Grad: 0.1483 LR: 0.000843  \n",
            "Epoch: [2][100/1809] Elapsed 0m 38s (remain 10m 50s) Loss: 0.0366 Grad: 0.2815 LR: 0.000819  \n",
            "Epoch: [2][200/1809] Elapsed 1m 15s (remain 10m 0s) Loss: 0.0358 Grad: 0.0118 LR: 0.000794  \n",
            "Epoch: [2][300/1809] Elapsed 1m 51s (remain 9m 18s) Loss: 0.0369 Grad: 0.0076 LR: 0.000767  \n",
            "Epoch: [2][400/1809] Elapsed 2m 28s (remain 8m 40s) Loss: 0.0366 Grad: 0.0036 LR: 0.000739  \n",
            "Epoch: [2][500/1809] Elapsed 3m 4s (remain 8m 2s) Loss: 0.0372 Grad: 0.5696 LR: 0.000710  \n",
            "Epoch: [2][600/1809] Elapsed 3m 41s (remain 7m 24s) Loss: 0.0389 Grad: 0.1164 LR: 0.000681  \n",
            "Epoch: [2][700/1809] Elapsed 4m 17s (remain 6m 47s) Loss: 0.0391 Grad: 0.0054 LR: 0.000650  \n",
            "Epoch: [2][800/1809] Elapsed 4m 54s (remain 6m 10s) Loss: 0.0374 Grad: 0.0880 LR: 0.000619  \n",
            "Epoch: [2][900/1809] Elapsed 5m 30s (remain 5m 33s) Loss: 0.0364 Grad: 0.3575 LR: 0.000588  \n",
            "Epoch: [2][1000/1809] Elapsed 6m 7s (remain 4m 56s) Loss: 0.0361 Grad: 0.6677 LR: 0.000556  \n",
            "Epoch: [2][1100/1809] Elapsed 6m 44s (remain 4m 19s) Loss: 0.0364 Grad: 0.0854 LR: 0.000524  \n",
            "Epoch: [2][1200/1809] Elapsed 7m 20s (remain 3m 43s) Loss: 0.0358 Grad: 0.1970 LR: 0.000492  \n",
            "Epoch: [2][1300/1809] Elapsed 7m 57s (remain 3m 6s) Loss: 0.0351 Grad: 0.0622 LR: 0.000460  \n",
            "Epoch: [2][1400/1809] Elapsed 8m 33s (remain 2m 29s) Loss: 0.0346 Grad: 0.0411 LR: 0.000428  \n",
            "Epoch: [2][1500/1809] Elapsed 9m 10s (remain 1m 52s) Loss: 0.0342 Grad: 0.0024 LR: 0.000396  \n",
            "Epoch: [2][1600/1809] Elapsed 9m 46s (remain 1m 16s) Loss: 0.0336 Grad: 0.3570 LR: 0.000365  \n",
            "Epoch: [2][1700/1809] Elapsed 10m 23s (remain 0m 39s) Loss: 0.0331 Grad: 0.0079 LR: 0.000334  \n",
            "Epoch: [2][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0327 Grad: 1.4291 LR: 0.000304  \n",
            "Epoch: [2][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0326 Grad: 0.0021 LR: 0.000302  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 36s) Loss: 0.0003 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0490 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0403 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0420 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0406 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0427 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0326  avg_val_loss: 0.0427  time: 718s\n",
            "Epoch 2 - Score: 0.8396827865028766\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/1809] Elapsed 0m 0s (remain 29m 57s) Loss: 0.0052 Grad: 0.3182 LR: 0.000302  \n",
            "Epoch: [3][100/1809] Elapsed 0m 37s (remain 10m 34s) Loss: 0.0190 Grad: 0.0013 LR: 0.000273  \n",
            "Epoch: [3][200/1809] Elapsed 1m 14s (remain 9m 52s) Loss: 0.0163 Grad: 0.0975 LR: 0.000245  \n",
            "Epoch: [3][300/1809] Elapsed 1m 50s (remain 9m 14s) Loss: 0.0164 Grad: 0.0022 LR: 0.000218  \n",
            "Epoch: [3][400/1809] Elapsed 2m 27s (remain 8m 37s) Loss: 0.0179 Grad: 0.0092 LR: 0.000192  \n",
            "Epoch: [3][500/1809] Elapsed 3m 3s (remain 7m 59s) Loss: 0.0177 Grad: 0.0851 LR: 0.000167  \n",
            "Epoch: [3][600/1809] Elapsed 3m 40s (remain 7m 22s) Loss: 0.0174 Grad: 0.0215 LR: 0.000144  \n",
            "Epoch: [3][700/1809] Elapsed 4m 16s (remain 6m 45s) Loss: 0.0173 Grad: 0.0015 LR: 0.000122  \n",
            "Epoch: [3][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0169 Grad: 0.0018 LR: 0.000102  \n",
            "Epoch: [3][900/1809] Elapsed 5m 29s (remain 5m 32s) Loss: 0.0159 Grad: 0.0024 LR: 0.000083  \n",
            "Epoch: [3][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.0162 Grad: 0.0037 LR: 0.000066  \n",
            "Epoch: [3][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0160 Grad: 6.4276 LR: 0.000051  \n",
            "Epoch: [3][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0158 Grad: 3.8333 LR: 0.000038  \n",
            "Epoch: [3][1300/1809] Elapsed 7m 56s (remain 3m 5s) Loss: 0.0155 Grad: 0.0029 LR: 0.000026  \n",
            "Epoch: [3][1400/1809] Elapsed 8m 32s (remain 2m 29s) Loss: 0.0150 Grad: 0.0010 LR: 0.000017  \n",
            "Epoch: [3][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0144 Grad: 0.0442 LR: 0.000010  \n",
            "Epoch: [3][1600/1809] Elapsed 9m 45s (remain 1m 16s) Loss: 0.0142 Grad: 0.0012 LR: 0.000004  \n",
            "Epoch: [3][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0140 Grad: 0.2627 LR: 0.000001  \n",
            "Epoch: [3][1800/1809] Elapsed 10m 58s (remain 0m 2s) Loss: 0.0141 Grad: 0.0683 LR: 0.000000  \n",
            "Epoch: [3][1808/1809] Elapsed 11m 1s (remain 0m 0s) Loss: 0.0141 Grad: 0.0018 LR: 0.000000  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 18s) Loss: 0.0001 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0563 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0420 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0444 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0439 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0450 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0141  avg_val_loss: 0.0450  time: 717s\n",
            "Epoch 3 - Score: 0.8377701221421859\n",
            "========== fold: 0 result ==========\n",
            "Score: 0.88496\n",
            "========== fold: 1 training ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/1809] Elapsed 0m 1s (remain 31m 55s) Loss: 0.6736 Grad: 4.3842 LR: 0.000000  \n",
            "Epoch: [1][100/1809] Elapsed 0m 37s (remain 10m 34s) Loss: 0.2707 Grad: 1.7780 LR: 0.000185  \n",
            "Epoch: [1][200/1809] Elapsed 1m 14s (remain 9m 52s) Loss: 0.1918 Grad: 0.4861 LR: 0.000369  \n",
            "Epoch: [1][300/1809] Elapsed 1m 50s (remain 9m 13s) Loss: 0.1533 Grad: 0.3596 LR: 0.000554  \n",
            "Epoch: [1][400/1809] Elapsed 2m 27s (remain 8m 36s) Loss: 0.1350 Grad: 1.6554 LR: 0.000738  \n",
            "Epoch: [1][500/1809] Elapsed 3m 3s (remain 7m 59s) Loss: 0.1217 Grad: 0.4074 LR: 0.000923  \n",
            "Epoch: [1][600/1809] Elapsed 3m 40s (remain 7m 22s) Loss: 0.1136 Grad: 0.3791 LR: 0.001000  \n",
            "Epoch: [1][700/1809] Elapsed 4m 16s (remain 6m 45s) Loss: 0.1092 Grad: 0.0866 LR: 0.000997  \n",
            "Epoch: [1][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.1049 Grad: 0.7590 LR: 0.000993  \n",
            "Epoch: [1][900/1809] Elapsed 5m 29s (remain 5m 32s) Loss: 0.0999 Grad: 0.3071 LR: 0.000987  \n",
            "Epoch: [1][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.0961 Grad: 0.5001 LR: 0.000978  \n",
            "Epoch: [1][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0932 Grad: 0.1152 LR: 0.000968  \n",
            "Epoch: [1][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0909 Grad: 0.0438 LR: 0.000956  \n",
            "Epoch: [1][1300/1809] Elapsed 7m 56s (remain 3m 5s) Loss: 0.0886 Grad: 0.3522 LR: 0.000942  \n",
            "Epoch: [1][1400/1809] Elapsed 8m 32s (remain 2m 29s) Loss: 0.0868 Grad: 6.8870 LR: 0.000926  \n",
            "Epoch: [1][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0841 Grad: 5.1177 LR: 0.000908  \n",
            "Epoch: [1][1600/1809] Elapsed 9m 45s (remain 1m 16s) Loss: 0.0820 Grad: 0.0179 LR: 0.000889  \n",
            "Epoch: [1][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0796 Grad: 3.7391 LR: 0.000867  \n",
            "Epoch: [1][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0786 Grad: 0.3175 LR: 0.000845  \n",
            "Epoch: [1][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0783 Grad: 0.0659 LR: 0.000843  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 44s) Loss: 0.0129 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0396 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0437 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0453 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0472 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0485 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0783  avg_val_loss: 0.0485  time: 717s\n",
            "Epoch 1 - Score: 0.8498188910560044\n",
            "Epoch 1 - Save Best Score: 0.8498 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/1809] Elapsed 0m 1s (remain 32m 52s) Loss: 0.2103 Grad: 1.9549 LR: 0.000843  \n",
            "Epoch: [2][100/1809] Elapsed 0m 37s (remain 10m 37s) Loss: 0.0436 Grad: 0.4424 LR: 0.000819  \n",
            "Epoch: [2][200/1809] Elapsed 1m 14s (remain 9m 53s) Loss: 0.0386 Grad: 0.1802 LR: 0.000794  \n",
            "Epoch: [2][300/1809] Elapsed 1m 50s (remain 9m 15s) Loss: 0.0335 Grad: 0.0064 LR: 0.000767  \n",
            "Epoch: [2][400/1809] Elapsed 2m 27s (remain 8m 37s) Loss: 0.0356 Grad: 0.0095 LR: 0.000739  \n",
            "Epoch: [2][500/1809] Elapsed 3m 4s (remain 8m 0s) Loss: 0.0355 Grad: 0.0028 LR: 0.000710  \n",
            "Epoch: [2][600/1809] Elapsed 3m 40s (remain 7m 23s) Loss: 0.0340 Grad: 0.8575 LR: 0.000681  \n",
            "Epoch: [2][700/1809] Elapsed 4m 17s (remain 6m 46s) Loss: 0.0327 Grad: 0.0054 LR: 0.000650  \n",
            "Epoch: [2][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0323 Grad: 0.3256 LR: 0.000619  \n",
            "Epoch: [2][900/1809] Elapsed 5m 30s (remain 5m 32s) Loss: 0.0340 Grad: 0.3541 LR: 0.000588  \n",
            "Epoch: [2][1000/1809] Elapsed 6m 6s (remain 4m 56s) Loss: 0.0336 Grad: 0.1525 LR: 0.000556  \n",
            "Epoch: [2][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0346 Grad: 0.0185 LR: 0.000524  \n",
            "Epoch: [2][1200/1809] Elapsed 7m 20s (remain 3m 42s) Loss: 0.0351 Grad: 0.7729 LR: 0.000492  \n",
            "Epoch: [2][1300/1809] Elapsed 7m 56s (remain 3m 6s) Loss: 0.0350 Grad: 0.0401 LR: 0.000460  \n",
            "Epoch: [2][1400/1809] Elapsed 8m 33s (remain 2m 29s) Loss: 0.0344 Grad: 1.6079 LR: 0.000428  \n",
            "Epoch: [2][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0349 Grad: 0.0133 LR: 0.000396  \n",
            "Epoch: [2][1600/1809] Elapsed 9m 46s (remain 1m 16s) Loss: 0.0347 Grad: 0.0088 LR: 0.000365  \n",
            "Epoch: [2][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0346 Grad: 0.0025 LR: 0.000334  \n",
            "Epoch: [2][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0336 Grad: 0.2348 LR: 0.000304  \n",
            "Epoch: [2][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0337 Grad: 0.7703 LR: 0.000302  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 28s) Loss: 0.0003 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0280 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0333 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0338 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0330 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0352 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0337  avg_val_loss: 0.0352  time: 718s\n",
            "Epoch 2 - Score: 0.8873456790123457\n",
            "Epoch 2 - Save Best Score: 0.8873 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/1809] Elapsed 0m 1s (remain 31m 21s) Loss: 0.0008 Grad: 0.0204 LR: 0.000302  \n",
            "Epoch: [3][100/1809] Elapsed 0m 37s (remain 10m 36s) Loss: 0.0159 Grad: 0.0606 LR: 0.000273  \n",
            "Epoch: [3][200/1809] Elapsed 1m 14s (remain 9m 54s) Loss: 0.0135 Grad: 0.0110 LR: 0.000245  \n",
            "Epoch: [3][300/1809] Elapsed 1m 50s (remain 9m 15s) Loss: 0.0144 Grad: 1.5716 LR: 0.000218  \n",
            "Epoch: [3][400/1809] Elapsed 2m 27s (remain 8m 37s) Loss: 0.0153 Grad: 0.0032 LR: 0.000192  \n",
            "Epoch: [3][500/1809] Elapsed 3m 4s (remain 8m 0s) Loss: 0.0156 Grad: 0.1465 LR: 0.000167  \n",
            "Epoch: [3][600/1809] Elapsed 3m 40s (remain 7m 23s) Loss: 0.0152 Grad: 0.0207 LR: 0.000144  \n",
            "Epoch: [3][700/1809] Elapsed 4m 17s (remain 6m 46s) Loss: 0.0157 Grad: 0.3690 LR: 0.000122  \n",
            "Epoch: [3][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0153 Grad: 0.0039 LR: 0.000102  \n",
            "Epoch: [3][900/1809] Elapsed 5m 30s (remain 5m 33s) Loss: 0.0155 Grad: 0.0025 LR: 0.000083  \n",
            "Epoch: [3][1000/1809] Elapsed 6m 7s (remain 4m 56s) Loss: 0.0157 Grad: 2.8940 LR: 0.000066  \n",
            "Epoch: [3][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0158 Grad: 0.0104 LR: 0.000051  \n",
            "Epoch: [3][1200/1809] Elapsed 7m 20s (remain 3m 42s) Loss: 0.0156 Grad: 2.6478 LR: 0.000038  \n",
            "Epoch: [3][1300/1809] Elapsed 7m 56s (remain 3m 6s) Loss: 0.0149 Grad: 0.0008 LR: 0.000026  \n",
            "Epoch: [3][1400/1809] Elapsed 8m 33s (remain 2m 29s) Loss: 0.0148 Grad: 0.0448 LR: 0.000017  \n",
            "Epoch: [3][1500/1809] Elapsed 9m 10s (remain 1m 52s) Loss: 0.0147 Grad: 0.1923 LR: 0.000010  \n",
            "Epoch: [3][1600/1809] Elapsed 9m 46s (remain 1m 16s) Loss: 0.0156 Grad: 0.0072 LR: 0.000004  \n",
            "Epoch: [3][1700/1809] Elapsed 10m 23s (remain 0m 39s) Loss: 0.0152 Grad: 0.0043 LR: 0.000001  \n",
            "Epoch: [3][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0153 Grad: 0.0422 LR: 0.000000  \n",
            "Epoch: [3][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0153 Grad: 0.0128 LR: 0.000000  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 24s) Loss: 0.0001 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0339 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0393 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0388 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0365 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0388 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0153  avg_val_loss: 0.0388  time: 718s\n",
            "Epoch 3 - Score: 0.8634100808960795\n",
            "========== fold: 1 result ==========\n",
            "Score: 0.88735\n",
            "========== fold: 2 training ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/1809] Elapsed 0m 1s (remain 30m 44s) Loss: 0.7004 Grad: 3.2719 LR: 0.000000  \n",
            "Epoch: [1][100/1809] Elapsed 0m 37s (remain 10m 34s) Loss: 0.2606 Grad: 0.8401 LR: 0.000185  \n",
            "Epoch: [1][200/1809] Elapsed 1m 14s (remain 9m 52s) Loss: 0.1793 Grad: 0.1962 LR: 0.000369  \n",
            "Epoch: [1][300/1809] Elapsed 1m 50s (remain 9m 14s) Loss: 0.1624 Grad: 0.6565 LR: 0.000554  \n",
            "Epoch: [1][400/1809] Elapsed 2m 27s (remain 8m 37s) Loss: 0.1409 Grad: 0.0538 LR: 0.000738  \n",
            "Epoch: [1][500/1809] Elapsed 3m 3s (remain 8m 0s) Loss: 0.1285 Grad: 0.1151 LR: 0.000923  \n",
            "Epoch: [1][600/1809] Elapsed 3m 40s (remain 7m 22s) Loss: 0.1202 Grad: 0.6531 LR: 0.001000  \n",
            "Epoch: [1][700/1809] Elapsed 4m 16s (remain 6m 46s) Loss: 0.1134 Grad: 0.7503 LR: 0.000997  \n",
            "Epoch: [1][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.1064 Grad: 0.1262 LR: 0.000993  \n",
            "Epoch: [1][900/1809] Elapsed 5m 30s (remain 5m 32s) Loss: 0.1015 Grad: 1.7964 LR: 0.000987  \n",
            "Epoch: [1][1000/1809] Elapsed 6m 6s (remain 4m 56s) Loss: 0.0971 Grad: 0.6376 LR: 0.000978  \n",
            "Epoch: [1][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0943 Grad: 0.0668 LR: 0.000968  \n",
            "Epoch: [1][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0905 Grad: 2.2638 LR: 0.000956  \n",
            "Epoch: [1][1300/1809] Elapsed 7m 56s (remain 3m 6s) Loss: 0.0866 Grad: 0.0210 LR: 0.000942  \n",
            "Epoch: [1][1400/1809] Elapsed 8m 33s (remain 2m 29s) Loss: 0.0843 Grad: 0.0204 LR: 0.000926  \n",
            "Epoch: [1][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0823 Grad: 0.0243 LR: 0.000908  \n",
            "Epoch: [1][1600/1809] Elapsed 9m 46s (remain 1m 16s) Loss: 0.0796 Grad: 0.3532 LR: 0.000889  \n",
            "Epoch: [1][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0781 Grad: 0.2158 LR: 0.000867  \n",
            "Epoch: [1][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0761 Grad: 0.0176 LR: 0.000845  \n",
            "Epoch: [1][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0760 Grad: 0.0744 LR: 0.000843  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 47s) Loss: 0.0021 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0415 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0381 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0394 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0437 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0427 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0760  avg_val_loss: 0.0427  time: 718s\n",
            "Epoch 1 - Score: 0.9090909090909092\n",
            "Epoch 1 - Save Best Score: 0.9091 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/1809] Elapsed 0m 1s (remain 33m 38s) Loss: 0.0023 Grad: 0.0657 LR: 0.000843  \n",
            "Epoch: [2][100/1809] Elapsed 0m 37s (remain 10m 36s) Loss: 0.0410 Grad: 0.0331 LR: 0.000819  \n",
            "Epoch: [2][200/1809] Elapsed 1m 14s (remain 9m 53s) Loss: 0.0429 Grad: 0.4638 LR: 0.000794  \n",
            "Epoch: [2][300/1809] Elapsed 1m 50s (remain 9m 14s) Loss: 0.0423 Grad: 0.6667 LR: 0.000767  \n",
            "Epoch: [2][400/1809] Elapsed 2m 27s (remain 8m 37s) Loss: 0.0381 Grad: 0.0369 LR: 0.000739  \n",
            "Epoch: [2][500/1809] Elapsed 3m 3s (remain 8m 0s) Loss: 0.0369 Grad: 0.0507 LR: 0.000710  \n",
            "Epoch: [2][600/1809] Elapsed 3m 40s (remain 7m 23s) Loss: 0.0355 Grad: 0.5031 LR: 0.000681  \n",
            "Epoch: [2][700/1809] Elapsed 4m 16s (remain 6m 46s) Loss: 0.0372 Grad: 0.5620 LR: 0.000650  \n",
            "Epoch: [2][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0379 Grad: 0.0874 LR: 0.000619  \n",
            "Epoch: [2][900/1809] Elapsed 5m 30s (remain 5m 32s) Loss: 0.0366 Grad: 0.0298 LR: 0.000588  \n",
            "Epoch: [2][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.0369 Grad: 0.9963 LR: 0.000556  \n",
            "Epoch: [2][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0372 Grad: 0.1644 LR: 0.000524  \n",
            "Epoch: [2][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0360 Grad: 0.2545 LR: 0.000492  \n",
            "Epoch: [2][1300/1809] Elapsed 7m 56s (remain 3m 6s) Loss: 0.0351 Grad: 0.0637 LR: 0.000460  \n",
            "Epoch: [2][1400/1809] Elapsed 8m 33s (remain 2m 29s) Loss: 0.0340 Grad: 0.0604 LR: 0.000428  \n",
            "Epoch: [2][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0332 Grad: 0.0065 LR: 0.000396  \n",
            "Epoch: [2][1600/1809] Elapsed 9m 46s (remain 1m 16s) Loss: 0.0336 Grad: 0.7808 LR: 0.000365  \n",
            "Epoch: [2][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0335 Grad: 1.2055 LR: 0.000334  \n",
            "Epoch: [2][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0331 Grad: 0.0071 LR: 0.000304  \n",
            "Epoch: [2][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0329 Grad: 0.0026 LR: 0.000302  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 39s) Loss: 0.0009 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0298 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0280 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0297 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0355 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0342 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0329  avg_val_loss: 0.0342  time: 718s\n",
            "Epoch 2 - Score: 0.9290540540540542\n",
            "Epoch 2 - Save Best Score: 0.9291 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/1809] Elapsed 0m 1s (remain 31m 36s) Loss: 0.0002 Grad: 0.0021 LR: 0.000302  \n",
            "Epoch: [3][100/1809] Elapsed 0m 37s (remain 10m 35s) Loss: 0.0121 Grad: 0.0651 LR: 0.000273  \n",
            "Epoch: [3][200/1809] Elapsed 1m 14s (remain 9m 53s) Loss: 0.0113 Grad: 0.0088 LR: 0.000245  \n",
            "Epoch: [3][300/1809] Elapsed 1m 50s (remain 9m 14s) Loss: 0.0119 Grad: 1.1448 LR: 0.000218  \n",
            "Epoch: [3][400/1809] Elapsed 2m 27s (remain 8m 37s) Loss: 0.0117 Grad: 0.0017 LR: 0.000192  \n",
            "Epoch: [3][500/1809] Elapsed 3m 3s (remain 8m 0s) Loss: 0.0131 Grad: 0.0050 LR: 0.000167  \n",
            "Epoch: [3][600/1809] Elapsed 3m 40s (remain 7m 23s) Loss: 0.0133 Grad: 0.0266 LR: 0.000144  \n",
            "Epoch: [3][700/1809] Elapsed 4m 17s (remain 6m 46s) Loss: 0.0135 Grad: 0.0069 LR: 0.000122  \n",
            "Epoch: [3][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0140 Grad: 0.0078 LR: 0.000102  \n",
            "Epoch: [3][900/1809] Elapsed 5m 30s (remain 5m 32s) Loss: 0.0140 Grad: 0.6760 LR: 0.000083  \n",
            "Epoch: [3][1000/1809] Elapsed 6m 6s (remain 4m 56s) Loss: 0.0148 Grad: 0.0013 LR: 0.000066  \n",
            "Epoch: [3][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0148 Grad: 0.3107 LR: 0.000051  \n",
            "Epoch: [3][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0145 Grad: 0.0144 LR: 0.000038  \n",
            "Epoch: [3][1300/1809] Elapsed 7m 56s (remain 3m 6s) Loss: 0.0137 Grad: 0.0167 LR: 0.000026  \n",
            "Epoch: [3][1400/1809] Elapsed 8m 33s (remain 2m 29s) Loss: 0.0138 Grad: 0.0009 LR: 0.000017  \n",
            "Epoch: [3][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0136 Grad: 0.0248 LR: 0.000010  \n",
            "Epoch: [3][1600/1809] Elapsed 9m 46s (remain 1m 16s) Loss: 0.0136 Grad: 3.1363 LR: 0.000004  \n",
            "Epoch: [3][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0136 Grad: 0.0223 LR: 0.000001  \n",
            "Epoch: [3][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0134 Grad: 0.0103 LR: 0.000000  \n",
            "Epoch: [3][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0139 Grad: 0.0074 LR: 0.000000  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 17s) Loss: 0.0002 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0360 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0304 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0313 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0380 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0366 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0139  avg_val_loss: 0.0366  time: 717s\n",
            "Epoch 3 - Score: 0.9105058365758755\n",
            "========== fold: 2 result ==========\n",
            "Score: 0.92905\n",
            "========== fold: 3 training ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/1809] Elapsed 0m 1s (remain 30m 26s) Loss: 0.4627 Grad: 3.6732 LR: 0.000000  \n",
            "Epoch: [1][100/1809] Elapsed 0m 37s (remain 10m 34s) Loss: 0.1952 Grad: 0.9052 LR: 0.000185  \n",
            "Epoch: [1][200/1809] Elapsed 1m 14s (remain 9m 52s) Loss: 0.1502 Grad: 0.1502 LR: 0.000369  \n",
            "Epoch: [1][300/1809] Elapsed 1m 50s (remain 9m 14s) Loss: 0.1355 Grad: 0.1088 LR: 0.000554  \n",
            "Epoch: [1][400/1809] Elapsed 2m 27s (remain 8m 36s) Loss: 0.1295 Grad: 1.0069 LR: 0.000738  \n",
            "Epoch: [1][500/1809] Elapsed 3m 3s (remain 7m 59s) Loss: 0.1187 Grad: 0.0680 LR: 0.000923  \n",
            "Epoch: [1][600/1809] Elapsed 3m 40s (remain 7m 22s) Loss: 0.1123 Grad: 0.0601 LR: 0.001000  \n",
            "Epoch: [1][700/1809] Elapsed 4m 16s (remain 6m 45s) Loss: 0.1055 Grad: 0.1576 LR: 0.000997  \n",
            "Epoch: [1][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.1027 Grad: 0.0123 LR: 0.000993  \n",
            "Epoch: [1][900/1809] Elapsed 5m 29s (remain 5m 32s) Loss: 0.0977 Grad: 0.1551 LR: 0.000987  \n",
            "Epoch: [1][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.0943 Grad: 0.4931 LR: 0.000978  \n",
            "Epoch: [1][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0915 Grad: 0.0858 LR: 0.000968  \n",
            "Epoch: [1][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0903 Grad: 0.0491 LR: 0.000956  \n",
            "Epoch: [1][1300/1809] Elapsed 7m 56s (remain 3m 5s) Loss: 0.0872 Grad: 0.9793 LR: 0.000942  \n",
            "Epoch: [1][1400/1809] Elapsed 8m 32s (remain 2m 29s) Loss: 0.0849 Grad: 0.3411 LR: 0.000926  \n",
            "Epoch: [1][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0828 Grad: 5.4892 LR: 0.000908  \n",
            "Epoch: [1][1600/1809] Elapsed 9m 45s (remain 1m 16s) Loss: 0.0833 Grad: 0.0278 LR: 0.000889  \n",
            "Epoch: [1][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0807 Grad: 0.0176 LR: 0.000867  \n",
            "Epoch: [1][1800/1809] Elapsed 10m 58s (remain 0m 2s) Loss: 0.0786 Grad: 0.2344 LR: 0.000845  \n",
            "Epoch: [1][1808/1809] Elapsed 11m 1s (remain 0m 0s) Loss: 0.0786 Grad: 0.0042 LR: 0.000843  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 22s) Loss: 0.0065 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0412 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0410 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0397 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0447 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0456 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0786  avg_val_loss: 0.0456  time: 717s\n",
            "Epoch 1 - Score: 0.8840115836000609\n",
            "Epoch 1 - Save Best Score: 0.8840 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/1809] Elapsed 0m 1s (remain 31m 55s) Loss: 0.0006 Grad: 0.0082 LR: 0.000843  \n",
            "Epoch: [2][100/1809] Elapsed 0m 37s (remain 10m 36s) Loss: 0.0338 Grad: 0.0103 LR: 0.000819  \n",
            "Epoch: [2][200/1809] Elapsed 1m 14s (remain 9m 52s) Loss: 0.0375 Grad: 0.0101 LR: 0.000794  \n",
            "Epoch: [2][300/1809] Elapsed 1m 50s (remain 9m 14s) Loss: 0.0337 Grad: 0.0046 LR: 0.000767  \n",
            "Epoch: [2][400/1809] Elapsed 2m 27s (remain 8m 36s) Loss: 0.0318 Grad: 0.0445 LR: 0.000739  \n",
            "Epoch: [2][500/1809] Elapsed 3m 3s (remain 7m 59s) Loss: 0.0322 Grad: 0.0032 LR: 0.000710  \n",
            "Epoch: [2][600/1809] Elapsed 3m 40s (remain 7m 22s) Loss: 0.0346 Grad: 1.8065 LR: 0.000681  \n",
            "Epoch: [2][700/1809] Elapsed 4m 16s (remain 6m 45s) Loss: 0.0354 Grad: 0.4543 LR: 0.000650  \n",
            "Epoch: [2][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0345 Grad: 2.9728 LR: 0.000619  \n",
            "Epoch: [2][900/1809] Elapsed 5m 29s (remain 5m 32s) Loss: 0.0338 Grad: 0.0265 LR: 0.000588  \n",
            "Epoch: [2][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.0337 Grad: 0.4533 LR: 0.000556  \n",
            "Epoch: [2][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0343 Grad: 0.2909 LR: 0.000524  \n",
            "Epoch: [2][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0340 Grad: 0.0124 LR: 0.000492  \n",
            "Epoch: [2][1300/1809] Elapsed 7m 56s (remain 3m 5s) Loss: 0.0341 Grad: 0.0074 LR: 0.000460  \n",
            "Epoch: [2][1400/1809] Elapsed 8m 32s (remain 2m 29s) Loss: 0.0345 Grad: 0.0388 LR: 0.000428  \n",
            "Epoch: [2][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0350 Grad: 0.1301 LR: 0.000396  \n",
            "Epoch: [2][1600/1809] Elapsed 9m 45s (remain 1m 16s) Loss: 0.0349 Grad: 1.4692 LR: 0.000365  \n",
            "Epoch: [2][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0346 Grad: 0.0019 LR: 0.000334  \n",
            "Epoch: [2][1800/1809] Elapsed 10m 58s (remain 0m 2s) Loss: 0.0347 Grad: 0.3618 LR: 0.000304  \n",
            "Epoch: [2][1808/1809] Elapsed 11m 1s (remain 0m 0s) Loss: 0.0348 Grad: 0.0201 LR: 0.000302  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 21s) Loss: 0.0006 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0408 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0388 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0383 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0419 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0425 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0348  avg_val_loss: 0.0425  time: 717s\n",
            "Epoch 2 - Score: 0.9047405413488858\n",
            "Epoch 2 - Save Best Score: 0.9047 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/1809] Elapsed 0m 1s (remain 31m 11s) Loss: 0.0272 Grad: 0.5433 LR: 0.000302  \n",
            "Epoch: [3][100/1809] Elapsed 0m 37s (remain 10m 35s) Loss: 0.0185 Grad: 0.0386 LR: 0.000273  \n",
            "Epoch: [3][200/1809] Elapsed 1m 14s (remain 9m 52s) Loss: 0.0199 Grad: 0.0015 LR: 0.000245  \n",
            "Epoch: [3][300/1809] Elapsed 1m 50s (remain 9m 14s) Loss: 0.0205 Grad: 2.8206 LR: 0.000218  \n",
            "Epoch: [3][400/1809] Elapsed 2m 27s (remain 8m 36s) Loss: 0.0192 Grad: 0.7539 LR: 0.000192  \n",
            "Epoch: [3][500/1809] Elapsed 3m 3s (remain 7m 59s) Loss: 0.0190 Grad: 0.0008 LR: 0.000167  \n",
            "Epoch: [3][600/1809] Elapsed 3m 40s (remain 7m 22s) Loss: 0.0183 Grad: 0.0372 LR: 0.000144  \n",
            "Epoch: [3][700/1809] Elapsed 4m 16s (remain 6m 46s) Loss: 0.0190 Grad: 0.0710 LR: 0.000122  \n",
            "Epoch: [3][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0186 Grad: 0.5238 LR: 0.000102  \n",
            "Epoch: [3][900/1809] Elapsed 5m 30s (remain 5m 32s) Loss: 0.0175 Grad: 0.0007 LR: 0.000083  \n",
            "Epoch: [3][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.0172 Grad: 0.0007 LR: 0.000066  \n",
            "Epoch: [3][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0174 Grad: 0.2764 LR: 0.000051  \n",
            "Epoch: [3][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0179 Grad: 0.1460 LR: 0.000038  \n",
            "Epoch: [3][1300/1809] Elapsed 7m 56s (remain 3m 5s) Loss: 0.0183 Grad: 0.2593 LR: 0.000026  \n",
            "Epoch: [3][1400/1809] Elapsed 8m 32s (remain 2m 29s) Loss: 0.0185 Grad: 0.0154 LR: 0.000017  \n",
            "Epoch: [3][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0188 Grad: 0.1152 LR: 0.000010  \n",
            "Epoch: [3][1600/1809] Elapsed 9m 45s (remain 1m 16s) Loss: 0.0185 Grad: 0.1526 LR: 0.000004  \n",
            "Epoch: [3][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0185 Grad: 0.0008 LR: 0.000001  \n",
            "Epoch: [3][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0183 Grad: 0.3499 LR: 0.000000  \n",
            "Epoch: [3][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0183 Grad: 0.5692 LR: 0.000000  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 29s) Loss: 0.0001 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0353 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0386 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0392 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0449 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0459 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0183  avg_val_loss: 0.0459  time: 717s\n",
            "Epoch 3 - Score: 0.852052672347018\n",
            "========== fold: 3 result ==========\n",
            "Score: 0.90474\n",
            "========== fold: 4 training ==========\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1-squad were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1][0/1809] Elapsed 0m 0s (remain 29m 38s) Loss: 0.7772 Grad: 5.2457 LR: 0.000000  \n",
            "Epoch: [1][100/1809] Elapsed 0m 37s (remain 10m 33s) Loss: 0.2785 Grad: 0.0915 LR: 0.000185  \n",
            "Epoch: [1][200/1809] Elapsed 1m 14s (remain 9m 52s) Loss: 0.1946 Grad: 0.7696 LR: 0.000369  \n",
            "Epoch: [1][300/1809] Elapsed 1m 50s (remain 9m 13s) Loss: 0.1696 Grad: 0.8224 LR: 0.000554  \n",
            "Epoch: [1][400/1809] Elapsed 2m 27s (remain 8m 36s) Loss: 0.1606 Grad: 0.3395 LR: 0.000738  \n",
            "Epoch: [1][500/1809] Elapsed 3m 3s (remain 7m 59s) Loss: 0.1496 Grad: 0.2190 LR: 0.000923  \n",
            "Epoch: [1][600/1809] Elapsed 3m 40s (remain 7m 22s) Loss: 0.1376 Grad: 1.2606 LR: 0.001000  \n",
            "Epoch: [1][700/1809] Elapsed 4m 16s (remain 6m 46s) Loss: 0.1298 Grad: 0.8783 LR: 0.000997  \n",
            "Epoch: [1][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.1207 Grad: 0.1334 LR: 0.000993  \n",
            "Epoch: [1][900/1809] Elapsed 5m 30s (remain 5m 32s) Loss: 0.1117 Grad: 0.3164 LR: 0.000987  \n",
            "Epoch: [1][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.1050 Grad: 1.5060 LR: 0.000978  \n",
            "Epoch: [1][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.1014 Grad: 0.0176 LR: 0.000968  \n",
            "Epoch: [1][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0981 Grad: 0.6208 LR: 0.000956  \n",
            "Epoch: [1][1300/1809] Elapsed 7m 56s (remain 3m 5s) Loss: 0.0960 Grad: 0.1218 LR: 0.000942  \n",
            "Epoch: [1][1400/1809] Elapsed 8m 32s (remain 2m 29s) Loss: 0.0947 Grad: 0.2205 LR: 0.000926  \n",
            "Epoch: [1][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0909 Grad: 0.0155 LR: 0.000908  \n",
            "Epoch: [1][1600/1809] Elapsed 9m 45s (remain 1m 16s) Loss: 0.0886 Grad: 0.1947 LR: 0.000889  \n",
            "Epoch: [1][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0871 Grad: 0.1880 LR: 0.000867  \n",
            "Epoch: [1][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0859 Grad: 0.1667 LR: 0.000845  \n",
            "Epoch: [1][1808/1809] Elapsed 11m 1s (remain 0m 0s) Loss: 0.0858 Grad: 0.0414 LR: 0.000843  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 48s) Loss: 0.2413 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0455 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0473 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0566 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0548 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0545 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0858  avg_val_loss: 0.0545  time: 717s\n",
            "Epoch 1 - Score: 0.82249140122626\n",
            "Epoch 1 - Save Best Score: 0.8225 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2][0/1809] Elapsed 0m 1s (remain 33m 6s) Loss: 0.0054 Grad: 0.0556 LR: 0.000843  \n",
            "Epoch: [2][100/1809] Elapsed 0m 37s (remain 10m 37s) Loss: 0.0513 Grad: 0.9532 LR: 0.000819  \n",
            "Epoch: [2][200/1809] Elapsed 1m 14s (remain 9m 53s) Loss: 0.0455 Grad: 0.2018 LR: 0.000794  \n",
            "Epoch: [2][300/1809] Elapsed 1m 50s (remain 9m 15s) Loss: 0.0445 Grad: 0.0455 LR: 0.000767  \n",
            "Epoch: [2][400/1809] Elapsed 2m 27s (remain 8m 37s) Loss: 0.0438 Grad: 1.4746 LR: 0.000739  \n",
            "Epoch: [2][500/1809] Elapsed 3m 3s (remain 8m 0s) Loss: 0.0401 Grad: 0.0640 LR: 0.000710  \n",
            "Epoch: [2][600/1809] Elapsed 3m 40s (remain 7m 23s) Loss: 0.0384 Grad: 0.0258 LR: 0.000681  \n",
            "Epoch: [2][700/1809] Elapsed 4m 17s (remain 6m 46s) Loss: 0.0375 Grad: 0.1717 LR: 0.000650  \n",
            "Epoch: [2][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0376 Grad: 3.7147 LR: 0.000619  \n",
            "Epoch: [2][900/1809] Elapsed 5m 30s (remain 5m 32s) Loss: 0.0383 Grad: 1.0721 LR: 0.000588  \n",
            "Epoch: [2][1000/1809] Elapsed 6m 6s (remain 4m 56s) Loss: 0.0375 Grad: 1.2797 LR: 0.000556  \n",
            "Epoch: [2][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0382 Grad: 0.1032 LR: 0.000524  \n",
            "Epoch: [2][1200/1809] Elapsed 7m 20s (remain 3m 42s) Loss: 0.0378 Grad: 1.6479 LR: 0.000492  \n",
            "Epoch: [2][1300/1809] Elapsed 7m 56s (remain 3m 6s) Loss: 0.0379 Grad: 0.3705 LR: 0.000460  \n",
            "Epoch: [2][1400/1809] Elapsed 8m 33s (remain 2m 29s) Loss: 0.0379 Grad: 0.0398 LR: 0.000428  \n",
            "Epoch: [2][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0368 Grad: 0.0042 LR: 0.000396  \n",
            "Epoch: [2][1600/1809] Elapsed 9m 46s (remain 1m 16s) Loss: 0.0359 Grad: 0.1807 LR: 0.000365  \n",
            "Epoch: [2][1700/1809] Elapsed 10m 23s (remain 0m 39s) Loss: 0.0356 Grad: 0.0248 LR: 0.000334  \n",
            "Epoch: [2][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0349 Grad: 0.0104 LR: 0.000304  \n",
            "Epoch: [2][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0348 Grad: 0.0040 LR: 0.000302  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 32s) Loss: 0.0334 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0439 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0425 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0463 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0443 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0434 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0348  avg_val_loss: 0.0434  time: 718s\n",
            "Epoch 2 - Score: 0.8632543926661572\n",
            "Epoch 2 - Save Best Score: 0.8633 Model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3][0/1809] Elapsed 0m 1s (remain 31m 44s) Loss: 0.0016 Grad: 0.0399 LR: 0.000302  \n",
            "Epoch: [3][100/1809] Elapsed 0m 37s (remain 10m 36s) Loss: 0.0241 Grad: 0.0431 LR: 0.000273  \n",
            "Epoch: [3][200/1809] Elapsed 1m 14s (remain 9m 53s) Loss: 0.0224 Grad: 0.0384 LR: 0.000245  \n",
            "Epoch: [3][300/1809] Elapsed 1m 50s (remain 9m 14s) Loss: 0.0207 Grad: 0.3564 LR: 0.000218  \n",
            "Epoch: [3][400/1809] Elapsed 2m 27s (remain 8m 37s) Loss: 0.0190 Grad: 0.0018 LR: 0.000192  \n",
            "Epoch: [3][500/1809] Elapsed 3m 3s (remain 8m 0s) Loss: 0.0187 Grad: 0.0023 LR: 0.000167  \n",
            "Epoch: [3][600/1809] Elapsed 3m 40s (remain 7m 23s) Loss: 0.0177 Grad: 0.0931 LR: 0.000144  \n",
            "Epoch: [3][700/1809] Elapsed 4m 17s (remain 6m 46s) Loss: 0.0166 Grad: 0.0013 LR: 0.000122  \n",
            "Epoch: [3][800/1809] Elapsed 4m 53s (remain 6m 9s) Loss: 0.0155 Grad: 0.0010 LR: 0.000102  \n",
            "Epoch: [3][900/1809] Elapsed 5m 30s (remain 5m 32s) Loss: 0.0155 Grad: 0.0167 LR: 0.000083  \n",
            "Epoch: [3][1000/1809] Elapsed 6m 6s (remain 4m 55s) Loss: 0.0150 Grad: 0.0764 LR: 0.000066  \n",
            "Epoch: [3][1100/1809] Elapsed 6m 43s (remain 4m 19s) Loss: 0.0148 Grad: 0.0029 LR: 0.000051  \n",
            "Epoch: [3][1200/1809] Elapsed 7m 19s (remain 3m 42s) Loss: 0.0147 Grad: 0.0165 LR: 0.000038  \n",
            "Epoch: [3][1300/1809] Elapsed 7m 56s (remain 3m 6s) Loss: 0.0152 Grad: 0.0049 LR: 0.000026  \n",
            "Epoch: [3][1400/1809] Elapsed 8m 32s (remain 2m 29s) Loss: 0.0149 Grad: 0.3353 LR: 0.000017  \n",
            "Epoch: [3][1500/1809] Elapsed 9m 9s (remain 1m 52s) Loss: 0.0148 Grad: 0.0282 LR: 0.000010  \n",
            "Epoch: [3][1600/1809] Elapsed 9m 46s (remain 1m 16s) Loss: 0.0146 Grad: 0.1702 LR: 0.000004  \n",
            "Epoch: [3][1700/1809] Elapsed 10m 22s (remain 0m 39s) Loss: 0.0143 Grad: 0.0012 LR: 0.000001  \n",
            "Epoch: [3][1800/1809] Elapsed 10m 59s (remain 0m 2s) Loss: 0.0143 Grad: 0.0020 LR: 0.000000  \n",
            "Epoch: [3][1808/1809] Elapsed 11m 2s (remain 0m 0s) Loss: 0.0144 Grad: 2.6340 LR: 0.000000  \n",
            "EVAL: [0/453] Elapsed 0m 0s (remain 5m 30s) Loss: 0.0189 \n",
            "EVAL: [100/453] Elapsed 0m 12s (remain 0m 44s) Loss: 0.0514 \n",
            "EVAL: [200/453] Elapsed 0m 24s (remain 0m 30s) Loss: 0.0502 \n",
            "EVAL: [300/453] Elapsed 0m 36s (remain 0m 18s) Loss: 0.0558 \n",
            "EVAL: [400/453] Elapsed 0m 48s (remain 0m 6s) Loss: 0.0531 \n",
            "EVAL: [452/453] Elapsed 0m 54s (remain 0m 0s) Loss: 0.0511 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0144  avg_val_loss: 0.0511  time: 717s\n",
            "Epoch 3 - Score: 0.8134490238611713\n",
            "========== fold: 4 result ==========\n",
            "Score: 0.86325\n",
            "========== CV ==========\n",
            "Score: 0.89377\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPHezhr_NHYR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7d33dfc73f6c4733be732faff6e01a5f",
            "9a9a0f5394844457ba1f079f9c85c520",
            "2e0ecda9236c4952aa2bfba6042d0f5f",
            "4e25535ab95545899cf670bdd6b19ed1",
            "ba52b4f8f49b4b5b98db59913c4a4e30",
            "1a43021596c44736937410edf7bc7018",
            "10f83e4e6f094a14b62e50832a7bdad5",
            "2b3196e8512b4e4faa2a6f99cb90140a"
          ]
        },
        "outputId": "d73ca9a2-38ba-487c-a0fe-ae0872710966"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 6559<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d33dfc73f6c4733be732faff6e01a5f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 2186.37MB of 2186.37MB uploaded (0.23MB deduped)\\r'), FloatProgress(value=1.0, ma…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210807_041631-mxe0tzxa/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210807_041631-mxe0tzxa/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>3</td></tr><tr><td>loss/train_fold0</td><td>0.01408</td></tr><tr><td>loss/val_fold0</td><td>0.04504</td></tr><tr><td>score/fold0</td><td>0.83777</td></tr><tr><td>_runtime</td><td>11014</td></tr><tr><td>_timestamp</td><td>1628320805</td></tr><tr><td>_step</td><td>14</td></tr><tr><td>CV_fold0</td><td>0.88496</td></tr><tr><td>loss/train_fold1</td><td>0.01528</td></tr><tr><td>loss/val_fold1</td><td>0.03879</td></tr><tr><td>score/fold1</td><td>0.86341</td></tr><tr><td>CV_fold1</td><td>0.88735</td></tr><tr><td>loss/train_fold2</td><td>0.01387</td></tr><tr><td>loss/val_fold2</td><td>0.03662</td></tr><tr><td>score/fold2</td><td>0.91051</td></tr><tr><td>CV_fold2</td><td>0.92905</td></tr><tr><td>loss/train_fold3</td><td>0.01826</td></tr><tr><td>loss/val_fold3</td><td>0.04587</td></tr><tr><td>score/fold3</td><td>0.85205</td></tr><tr><td>CV_fold3</td><td>0.90474</td></tr><tr><td>loss/train_fold4</td><td>0.01442</td></tr><tr><td>loss/val_fold4</td><td>0.05108</td></tr><tr><td>score/fold4</td><td>0.81345</td></tr><tr><td>CV_fold4</td><td>0.86325</td></tr><tr><td>CV</td><td>0.89377</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▅█▁▅█▁▅█▁▅█▁▅█</td></tr><tr><td>loss/train_fold0</td><td>█▃▁</td></tr><tr><td>loss/val_fold0</td><td>█▁█</td></tr><tr><td>score/fold0</td><td>█▁▁</td></tr><tr><td>_runtime</td><td>▁▁▂▃▃▃▄▄▅▆▆▆▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▃▃▃▄▄▅▆▆▆▇██</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss/train_fold1</td><td>█▃▁</td></tr><tr><td>loss/val_fold1</td><td>█▁▃</td></tr><tr><td>score/fold1</td><td>▁█▄</td></tr><tr><td>loss/train_fold2</td><td>█▃▁</td></tr><tr><td>loss/val_fold2</td><td>█▁▃</td></tr><tr><td>score/fold2</td><td>▁█▁</td></tr><tr><td>loss/train_fold3</td><td>█▃▁</td></tr><tr><td>loss/val_fold3</td><td>▇▁█</td></tr><tr><td>score/fold3</td><td>▅█▁</td></tr><tr><td>loss/train_fold4</td><td>█▃▁</td></tr><tr><td>loss/val_fold4</td><td>█▁▆</td></tr><tr><td>score/fold4</td><td>▂█▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 43 artifact file(s) and 7 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">still-sponge-64</strong>: <a href=\"https://wandb.ai/imokuri/signate-471/runs/mxe0tzxa\" target=\"_blank\">https://wandb.ai/imokuri/signate-471/runs/mxe0tzxa</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-scfhV4ueW4K"
      },
      "source": [
        "## Public LB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNsH2CvA1He"
      },
      "source": [
        "RUN_ID = \"\"\n",
        "LB_SCORE = None\n",
        "\n",
        "WANDB_ENTITY = \"imokuri\"\n",
        "WANDB_PROJECT = \"signate-471\""
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS7aRYF_eh7z"
      },
      "source": [
        "if RUN_ID is not None and LB_SCORE is not None:\n",
        "    import wandb\n",
        "    api = wandb.Api()\n",
        "\n",
        "    run = api.run(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/{RUN_ID}\")\n",
        "    run.summary[\"LB\"] = LB_SCORE\n",
        "    run.summary.update()\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANpuUeypNmLF"
      },
      "source": [
        ""
      ],
      "execution_count": 67,
      "outputs": []
    }
  ]
}